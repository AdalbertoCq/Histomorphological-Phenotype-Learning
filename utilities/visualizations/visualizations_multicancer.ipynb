{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lifelines.statistics    import logrank_test\n",
    "from lifelines.utils         import concordance_index\n",
    "from sksurv.metrics          import concordance_index_censored\n",
    "from matplotlib.colors       import LinearSegmentedColormap\n",
    "from matplotlib.colors       import TwoSlopeNorm\n",
    "from matplotlib.pyplot       import rc_context\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from skimage.transform       import resize\n",
    "from scipy.cluster           import hierarchy\n",
    "from plottify                import autosize\n",
    "from PIL                     import Image\n",
    "from scipy.stats             import combine_pvalues\n",
    "from collections             import OrderedDict\n",
    "from adjustText              import adjust_text\n",
    "from matplotlib              import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api   as sm\n",
    "import seaborn           as sns\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import scanpy            as sc\n",
    "import matplotlib\n",
    "import fastcluster\n",
    "import pickle\n",
    "import anndata\n",
    "import random\n",
    "import umap\n",
    "import h5py\n",
    "import copy\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/media/adalberto/Disk2/PhD_Workspace'\n",
    "sys.path.append(main_path)\n",
    "from models.clustering.cox_proportional_hazard_regression_leiden_clusters import *\n",
    "from models.clustering.logistic_regression_leiden_clusters                import *\n",
    "from models.visualization.survival                                        import save_fold_KMs\n",
    "from models.visualization.clusters                                        import cluster_circular, plot_confusion_matrix_lr\n",
    "from models.visualization.forest_plots                                    import report_forest_plot_lr\n",
    "from models.evaluation.folds                                              import load_existing_split\n",
    "from data_manipulation.data                                               import Data\n",
    "from models.clustering.correlations      import *\n",
    "from models.clustering.data_processing   import *\n",
    "from models.visualization.attention_maps import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Figure method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_institution_distribution(data_hpc_inst, field, title, figsize=(30,7), fontsize_labels=22, fontsize_legend=20, show_max_min=False):\n",
    "    def colors_from_values(values, palette_name, normalize=False):\n",
    "        # normalize the values to range [0, 1]\n",
    "        if normalize:\n",
    "            normalized = (values - min(values)) / (max(values) - min(values))\n",
    "        else:\n",
    "            normalized = values\n",
    "        # convert to indices\n",
    "        indices = np.round(normalized * (len(values) - 1)).astype(np.int32)\n",
    "        # use the indices to get the colors\n",
    "        palette = sns.color_palette(palette_name, int(1.5*len(values)))\n",
    "        return np.array(palette).take(indices, axis=0)\n",
    "\n",
    "    fig   = plt.figure(figsize=figsize)\n",
    "    ax    = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # pal  = sns.color_palette(\"Greens_d\")\n",
    "    # rank = data_hpc_inst[field].argsort().argsort()\n",
    "    # sns.barplot(data=data_hpc_inst, x='HPC', y=field, palette=np.array(pal[::-1])[rank], ax=ax)\n",
    "\n",
    "    y = data_hpc_inst[field].values\n",
    "    sns.barplot(data=data_hpc_inst, x='HPC', y=field, palette=colors_from_values(y, \"Greens_d\"), ax=ax)\n",
    "\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_ylim([0.0,1.0])\n",
    "    yticks = (np.array(range(0,11,1))/10).tolist()\n",
    "    ax.set_yticks(yticks, yticks)\n",
    "\n",
    "    ax.set_title(title,  fontsize=fontsize_labels*1.3, fontweight='bold')\n",
    "    ax.set_xlabel('\\nHistomorphological Phenotype Cluster (HPC)', fontsize=fontsize_labels,     fontweight='bold')\n",
    "    ax.set_ylabel(' ', fontsize=fontsize_labels, fontweight='bold')\n",
    "    if show_max_min:\n",
    "        max_val = np.max(data_hpc_inst[field].values)\n",
    "        min_val = np.min(data_hpc_inst[field].values)\n",
    "        ax.axhline(max_val, linestyle='--')\n",
    "        ax.axhline(min_val, linestyle='--')\n",
    "    ax.axhline(0.50, linestyle='--', color='black')\n",
    "    ax.axhline(0.25, linestyle='--', color='black')\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(4)\n",
    "    plt.show()\n",
    "\n",
    "def get_col_colors(cox_os_clusters, cox_pfs_clusters, immune_hot_clusters, p_th):\n",
    "\n",
    "    colors        = []\n",
    "    colors_masked = []\n",
    "\n",
    "    if immune_hot_clusters is not None:\n",
    "        cmap_PiYG = sns.diverging_palette(20, 250, as_cmap=True)\n",
    "        norm      = TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1)\n",
    "        immune_clusters = [1]*cox_pfs_clusters.shape[0]\n",
    "        for key in immune_hot_clusters:\n",
    "            if key == 'hot':\n",
    "                value = -1\n",
    "            elif key == 'warm':\n",
    "                value = -0.5\n",
    "            elif key == 'cold':\n",
    "                value = 0\n",
    "            for cluster in immune_hot_clusters[key]:\n",
    "                immune_clusters[cluster] = value\n",
    "        column_immune_colors       = pd.Series([cmap_PiYG(norm(coef)) for cluster, coef in enumerate(immune_clusters)], name='Hot/Warm/Cold Lymphocytic Infiltration')\n",
    "        if cox_os_clusters is not None:\n",
    "            coef_df          = cox_os_clusters.sort_values(by=groupby)\n",
    "            column_immune_colors.index = coef_df[groupby].astype(str)\n",
    "        else:\n",
    "            column_immune_colors.index = column_immune_colors.index.astype(str)\n",
    "        colors.append(column_immune_colors)\n",
    "        colors_masked.append(column_immune_colors)\n",
    "\n",
    "    # Column colors.\n",
    "    if cox_os_clusters is not None:\n",
    "        coef_df   = cox_os_clusters.sort_values(by=groupby)\n",
    "        cmap_PiYG = plt.cm.PiYG_r\n",
    "        norm      = TwoSlopeNorm(vmin=coef_df['coef'].min(), vcenter=0, vmax=coef_df['coef'].max())\n",
    "        column_os_colors              = pd.Series([cmap_PiYG(norm(coef)) for p, coef in zip(coef_df['p'], coef_df['coef'])], name='Cox Coefficient OS')\n",
    "        column_os_colors_masked       = pd.Series([cmap_PiYG(norm(coef)) if p <p_th else cmap_PiYG(norm(0))[:3] for p, coef in zip(coef_df['p'], coef_df['coef'])], name='Cox Coefficient OS')\n",
    "        column_os_colors_masked.index = coef_df[groupby].astype(str)\n",
    "        column_os_colors.index        = coef_df[groupby].astype(str)\n",
    "        colors.append(column_os_colors)\n",
    "        colors_masked.append(column_os_colors_masked)\n",
    "\n",
    "    if cox_pfs_clusters is not None:\n",
    "        cox_pfs_clusters = cox_pfs_clusters.sort_values(by=groupby)\n",
    "        cmap_PiYG = plt.cm.PiYG_r\n",
    "        norm                     = TwoSlopeNorm(vmin=cox_pfs_clusters['coef'].astype(float).min(), vcenter=0, vmax=cox_pfs_clusters['coef'].astype(float).max())\n",
    "        column_pfs_colors        = pd.Series([cmap_PiYG(norm(coef)) for p, coef in zip(cox_pfs_clusters['p'], cox_pfs_clusters['coef'])], name='Cox Coefficient RFS')\n",
    "        column_pfs_colors_masked = pd.Series([cmap_PiYG(norm(coef)) if p <p_th else cmap_PiYG(norm(0))[:3] for p, coef in zip(cox_pfs_clusters['p'], cox_pfs_clusters['coef'])], name='Cox Coefficient RFS')\n",
    "        column_pfs_colors.index        = coef_df[groupby].astype(str)\n",
    "        column_pfs_colors_masked.index = coef_df[groupby].astype(str)\n",
    "        colors.append(column_pfs_colors)\n",
    "        colors_masked.append(column_pfs_colors)\n",
    "\n",
    "    if len(colors) != 0:\n",
    "        colors = pd.concat(colors,axis=1)\n",
    "        colors_masked = pd.concat(colors_masked,axis=1)\n",
    "    else:\n",
    "        colors        = None\n",
    "        colors_masked = None\n",
    "\n",
    "    return colors, colors_masked\n",
    "\n",
    "def fixedWidthClusterMap(dataFrame, mask, x_label, y_label, vcenter=0, annot=True, fmt='.2f', col_linkage=None, row_linkage=None, \n",
    "                        fontsize_ticks=28, fontsize_labels=30, fontsize_annot=20, dendrogram_ratio=0.2, \n",
    "                        immune_hot_clusters=None, cox_os_clusters=None, cox_pfs_clusters=None, \n",
    "                        cellSizePixels_x=50, cellSizePixels_y=50, p_th=0.05, offset_col_color=2, \n",
    "                        resize_col_den=1.0, linewidths=5.0, row_cluster=True, col_cluster=True, round_cbar=2, cmap=sns.diverging_palette(250, 20, as_cmap=True)):\n",
    "    sns.set_theme(style='white')\n",
    "\n",
    "    colors, colors_masked = get_col_colors(cox_os_clusters, cox_pfs_clusters, immune_hot_clusters, p_th)\n",
    "\n",
    "    # Calculate the figure size, this gets us close, but not quite to the right place\n",
    "    dpi = matplotlib.rcParams['figure.dpi']\n",
    "    marginWidth  = (matplotlib.rcParams['figure.subplot.right']-matplotlib.rcParams['figure.subplot.left'])\n",
    "    marginHeight = (matplotlib.rcParams['figure.subplot.top']-matplotlib.rcParams['figure.subplot.bottom'])\n",
    "    Ny,Nx = dataFrame.shape\n",
    "    figWidth = (Nx*cellSizePixels_x/dpi)/0.8/marginWidth\n",
    "    figHeigh = ((Ny+offset_col_color)*cellSizePixels_y/dpi)/0.8/marginHeight\n",
    "\n",
    "    # do the actual plot\n",
    "    vmax = np.nanmax(dataFrame[~mask].values)\n",
    "    if vcenter == 0:\n",
    "        vmin = -vmax\n",
    "        cbar_kws = dict()\n",
    "    else:\n",
    "        vmin = np.nanmin(dataFrame[~mask].values)\n",
    "        ticks = np.array([vmin*1.01, (vmin+vcenter)/2, vcenter, (vmax+vcenter)/2, vmax*0.99])\n",
    "        ticks = np.round(ticks, round_cbar)\n",
    "        cbar_kws = dict(ticks=ticks)\n",
    "\n",
    "    if col_linkage is None and col_cluster:\n",
    "        Z = hierarchy.linkage(y=dataFrame.T, method='ward', metric='euclidean', optimal_ordering=True)\n",
    "        col_linkage = Z\n",
    "\n",
    "    if row_linkage is None and col_cluster:\n",
    "        Z = hierarchy.linkage(y=dataFrame, method='ward', metric='euclidean', optimal_ordering=True)\n",
    "        row_linkage = Z\n",
    "\n",
    "    norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "    grid = sns.clustermap(dataFrame, vmin=vmin, vmax=vmax, method='ward', metric='euclidean', annot=annot, mask=mask, col_linkage=col_linkage, row_linkage=row_linkage, fmt=fmt, col_colors=colors, tree_kws=dict(linewidths=linewidths), norm=norm,\n",
    "                          cmap=cmap, dendrogram_ratio=dendrogram_ratio, annot_kws={\"size\": fontsize_annot,'fontstyle':'italic','fontweight':'bold'},  yticklabels=True,  xticklabels=True,\n",
    "                          row_cluster=row_cluster, col_cluster=col_cluster, figsize=(figWidth, figHeigh), cbar_kws=cbar_kws)\n",
    "\n",
    "    if colors is not None:\n",
    "        grid.ax_col_colors.set_yticklabels(grid.ax_col_colors.get_ymajorticklabels(), fontsize=fontsize_ticks)\n",
    "\n",
    "    # calculate the size of the heatmap axes\n",
    "    axWidth  = (Nx*cellSizePixels_x)/(figWidth*dpi)\n",
    "    axHeight = (Ny*cellSizePixels_y)/(figHeigh*dpi)\n",
    "\n",
    "    # calculate size of column colors\n",
    "    ax_colors_height = (offset_col_color*cellSizePixels_y)/(figWidth*dpi)\n",
    "\n",
    "    # resize heatmap\n",
    "    ax_heatmap_orig_pos = grid.ax_heatmap.get_position()\n",
    "    grid.ax_heatmap.set_position([ax_heatmap_orig_pos.x0, ax_heatmap_orig_pos.y0, axWidth, axHeight])\n",
    "\n",
    "    # resize row dendrogram to match\n",
    "    ax_row_orig_pos = grid.ax_row_dendrogram.get_position()\n",
    "    grid.ax_row_dendrogram.set_position([ax_row_orig_pos.x0, ax_row_orig_pos.y0, ax_row_orig_pos.width, axHeight])\n",
    "\n",
    "    # resize col_colors\n",
    "    if colors is not None:\n",
    "        ax_col_colors_orig_pos = grid.ax_col_colors.get_position()\n",
    "        grid.ax_col_colors.set_position([ax_col_colors_orig_pos.x0, ax_heatmap_orig_pos.y0+axHeight+0.01, axWidth, ax_colors_height])\n",
    "\n",
    "    # resize col dendrogram to match\n",
    "    ax_col_orig_pos = grid.ax_col_dendrogram.get_position()\n",
    "    grid.ax_col_dendrogram.set_position([ax_col_orig_pos.x0, ax_heatmap_orig_pos.y0+axHeight+ax_colors_height+0.01, axWidth, ax_col_orig_pos.height*resize_col_den])\n",
    "\n",
    "    # tick_locator = ticker.MaxNLocator(nbins=cbar_bins)\n",
    "    # grid.ax_cbar.cla.locator = tick_locator\n",
    "    # grid.ax_cbar.cla.update_ticks()\n",
    "\n",
    "    ax_cbar_orig_pos = grid.ax_cbar.get_position()\n",
    "    grid.ax_cbar.set_position([ax_row_orig_pos.x0+ax_row_orig_pos.width*0.25, ax_heatmap_orig_pos.y0+axHeight, ax_row_orig_pos.width*0.25, ax_col_orig_pos.height*resize_col_den])\n",
    "\n",
    "    grid.ax_cbar.tick_params(labelsize=fontsize_ticks*0.9, length=10)\n",
    "    [label.set_fontweight('bold') for label in grid.ax_cbar.get_yticklabels()]\n",
    "\n",
    "    grid.ax_heatmap.set_xlabel('\\n%s' % x_label, fontsize=fontsize_labels, fontweight='bold')\n",
    "    grid.ax_heatmap.set_ylabel('\\n%s' % y_label, fontsize=fontsize_labels, fontweight='bold')\n",
    "\n",
    "    grid.ax_heatmap.set_xticklabels(grid.ax_heatmap.get_xmajorticklabels(), fontsize=fontsize_ticks, weight='bold')\n",
    "    grid.ax_heatmap.set_yticklabels(grid.ax_heatmap.get_ymajorticklabels(), fontsize=fontsize_ticks, weight='bold', rotation=0)\n",
    "\n",
    "    if colors is not None:\n",
    "        [label.set_fontweight('bold') for label in grid.ax_col_colors.get_yticklabels()]\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        grid.ax_heatmap.spines[axis].set_linewidth(4)\n",
    "\n",
    "    return grid # return ClusterGrid object\n",
    "\n",
    "def show_correlation_scatter(cross_df, cluster, annotations, all_data_rho, all_data_pval, fontsize_labels=22, fontsize_title=30):\n",
    "    from decimal import Decimal\n",
    "    cross_df.columns = cross_df.columns.astype(str)\n",
    "\n",
    "    for i, annotation in enumerate(annotations):\n",
    "        rho_annotation  = all_data_rho.loc[annotation, str(cluster)]\n",
    "        pval_annotation = all_data_pval.loc[annotation, str(cluster)]\n",
    "        g = sns.jointplot(data=cross_df, x=annotation, y=str(cluster), kind='reg', ci=None, height=10, ratio=2)\n",
    "        g.ax_joint.set_ylabel('HPC %s\\nContribution' % cluster, fontsize=fontsize_labels, fontweight='bold')\n",
    "        g.ax_joint.set_xlabel(annotation, fontsize=fontsize_labels, fontweight='bold')\n",
    "\n",
    "        for tick in g.ax_joint.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_labels)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "        for tick in g.ax_joint.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_labels)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            g.ax_joint.spines[axis].set_linewidth(4)\n",
    "            g.ax_marg_x.spines[axis].set_linewidth(4)\n",
    "            g.ax_marg_y.spines[axis].set_linewidth(4)\n",
    "\n",
    "        plt.suptitle('Spearman %s=%s\\np-value=%s' % (r'$\\mathbf{\\rho}$', np.round(rho_annotation, 1), '%.1E' % Decimal(pval_annotation)), fontsize=fontsize_title, fontweight='bold')\n",
    "        g.fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def relplot_figure(data, x, y, hue, col_wrap, col, col_order, size, pval_th, sizes=(10, 100), height=3, aspect=3.5, facet_kws={'sharex': False, 'sharey': True}):\n",
    "\n",
    "    g = sns.relplot(data=data, y=y, x=x, hue=hue, col_wrap=col_wrap, col=col, col_order=col_order, size=size, sizes=sizes, height=height, aspect=aspect, facet_kws=facet_kws)\n",
    "    i = 0\n",
    "    for ax in g._axes:\n",
    "        ann = ax.get_title().split('%s = ' % col)[1]\n",
    "        data_imm = data[data[col]==ann]\n",
    "        order_hpc = data_imm.groupby(by='HPC').mean().sort_values(by='Rho').index.tolist()\n",
    "        ax.set_ylim([-0.5, 0.8])\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            label = tick.label1\n",
    "            if label._text in data_imm[data_imm['HPC']==label._text]['HPC'].values.astype(str):\n",
    "                p_val = data_imm[(data_imm['HPC']==label._text)]['P-Value Combined'].values[0]\n",
    "                if p_val < pval_th:\n",
    "                    label.set_fontsize(label._fontproperties._size*1.2)\n",
    "                    label.set_fontweight('bold')\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontweight('bold')\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(4)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax_title = ax.title._text.replace('= ', '')\n",
    "        ax.set_title(ax_title, fontsize=ax.title._fontproperties._size*1.3, fontweight='bold')\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontsize=ax.title._fontproperties._size, fontweight='bold')\n",
    "        if i%col_wrap == 0:\n",
    "            ax.set_ylabel(r'$\\mathbf{\\rho}$', fontsize=ax.title._fontproperties._size, fontweight='bold')\n",
    "        i += 1\n",
    "        ax.axhline(0.0, linestyle='--', color='grey', lw=1)\n",
    "        ax.set_title(ann, fontsize=ax.title._fontproperties._size*1.2, fontweight='bold', y=0.9)\n",
    "\n",
    "    g._legend.get_title().set_weight('bold')\n",
    "    [leg_text.set_weight('bold') for leg_text in g._legend.get_texts()]\n",
    "    plt.show()\n",
    "\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Combine correlations Pan-Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out immune feature with low number of significant correlations.\n",
    "def keep_features_min_corr(mask, data, keep_th):\n",
    "    data_plot = data.copy(deep=True)\n",
    "    mask_plot = mask.copy(deep=True)\n",
    "\n",
    "    mask_plot_th = (~mask_plot).sum(axis=1)\n",
    "    subset_features = mask_plot_th[mask_plot_th>=keep_th].index\n",
    "\n",
    "    return data_plot.loc[subset_features], mask_plot.loc[subset_features]\n",
    "\n",
    "def clean_correlation(all_data_rho, all_data_pval, all_data_samples, mask, th_corr, remove_nan=False):\n",
    "    # Remove row and columns with all non-significant\n",
    "    if th_corr>0:\n",
    "        remove_empty_row = mask[np.sum(~mask,axis=1)<=th_corr].index\n",
    "        remove_empty_col = mask.columns[np.sum(~mask,axis=0)<=th_corr].tolist()\n",
    "        all_data_rho      = all_data_rho.drop(index=remove_empty_row)\n",
    "        all_data_rho      = all_data_rho.drop(columns=remove_empty_col)\n",
    "        all_data_pval     = all_data_pval.drop(index=remove_empty_row)\n",
    "        all_data_pval     = all_data_pval.drop(columns=remove_empty_col)\n",
    "        all_data_samples  = all_data_samples.drop(index=remove_empty_row)\n",
    "        all_data_samples  = all_data_samples.drop(columns=remove_empty_col)\n",
    "        mask              = mask.drop(index=remove_empty_row)\n",
    "        mask              = mask.drop(columns=remove_empty_col)\n",
    "\n",
    "    # Remove row and columns with all nan\n",
    "    if remove_nan:\n",
    "        remove_empty_row = all_data_rho[np.sum(~(all_data_rho.isnull()),axis=1)==0].index\n",
    "        # remove_empty_col = all_data_rho.columns[np.sum(~(all_data_rho.isnull()),axis=0)==0].tolist()\n",
    "        all_data_rho      = all_data_rho.drop(index=remove_empty_row)\n",
    "        all_data_pval     = all_data_pval.drop(index=remove_empty_row)\n",
    "        all_data_samples  = all_data_samples.drop(index=remove_empty_row)\n",
    "        mask              = mask.drop(index=remove_empty_row)\n",
    "\n",
    "    return all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "def combine_correlations_multiple(correlation_data, shape, labels_consider, type_integration='weighted_average', pval_th=0.01, method_comb_pval='fisher', th_corr=0, remove_nan=False):\n",
    "    all_data_rho     = np.zeros(shape)\n",
    "    all_data_pval    = np.ones(shape)\n",
    "    all_data_samples = np.zeros(shape)\n",
    "\n",
    "    for row in range(shape[0]):\n",
    "        for column in range(shape[1]):\n",
    "            weights = [correlation_data[label][2].values[row,column].astype(int) for label in labels_consider]\n",
    "            if 'weighted_average'==type_integration:\n",
    "                all_data_rho[row,column]     = np.average([correlation_data[label][0].values[row,column] for label in labels_consider], weights=weights)\n",
    "            else:\n",
    "                all_data_rho[row,column]     = np.mean([correlation_data[label][0].values[row,column] for label in labels_consider])\n",
    "            all_data_pval[row,column]    = combine_pvalues([correlation_data[label][1].values[row,column] for label in labels_consider], method=method_comb_pval)[1]\n",
    "            all_data_samples[row,column] = np.mean([correlation_data[label][2].values[row,column] for label in labels_consider])\n",
    "\n",
    "    label = labels_consider[0]\n",
    "    all_data_rho           = pd.DataFrame(all_data_rho, columns=correlation_data[label][0].columns)\n",
    "    all_data_rho.index     = correlation_data[label][0].index\n",
    "\n",
    "    all_data_pval          = pd.DataFrame(all_data_pval, columns=correlation_data[label][0].columns)\n",
    "    all_data_pval.index    = correlation_data[label][0].index\n",
    "\n",
    "    all_data_samples       = pd.DataFrame(all_data_samples, columns=correlation_data[label][0].columns)\n",
    "    all_data_samples.index = correlation_data[label][0].index\n",
    "\n",
    "    mask = (all_data_pval.values > pval_th)\n",
    "    mask = pd.DataFrame(mask, columns=correlation_data[label][0].columns)\n",
    "    mask.index = correlation_data[label][0].index\n",
    "\n",
    "    return all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "\n",
    "    # Run correlation per label\n",
    "\n",
    "def correlations_across_types(slide_rep_df, annotations_df, meta_field, groupby, fold_number, pval_th, file_name, directory, matching_field='samples', corr_method='spearman', method_comb_pval='fisher', type_integration='weighted_average',\n",
    "                              th_corr=0, remove_nan=False):\n",
    "    # All available fields.\n",
    "    annotation_fields = [annotation for annotation in immune_landscape_df.columns if annotation not in ['slides', matching_field]]\n",
    "\n",
    "    # Get labels that have annotations for all fields.\n",
    "    merged_df     = slide_rep_df.merge(annotations_df, how='inner', left_on=matching_field, right_on=matching_field)\n",
    "    labels_allann = merged_df[~(merged_df[annotation_fields].isnull()).any(axis=1)].labels.unique()\n",
    "\n",
    "    # Correlation all types combined.\n",
    "    final_dict = dict()\n",
    "    all_data_rho_clr, all_data_pval_clr, all_data_samples_clr, mask_clr, _ = correlate_clusters_annotation(slide_rep_df=slide_rep_df, annotations_df=annotations_df, purity_field=meta_field,\n",
    "                                                                                                       matching_field=matching_field, corr_method=corr_method, pval_th=pval_th, field_th=None,\n",
    "                                                                                                       groupby=groupby, fold_number=fold_number, directory=directory, file_name=None)\n",
    "    final_dict['blind'] =  all_data_rho_clr, all_data_pval_clr, all_data_samples_clr, mask_clr\n",
    "\n",
    "    correlation_data = dict()\n",
    "    labels_unique = np.unique(slide_rep_df[1:][meta_field])\n",
    "    for label in labels_unique:\n",
    "        wsi_rep_label = slide_rep_df[slide_rep_df[meta_field]==label]\n",
    "        all_data_rho, all_data_pval, all_data_samples, mask, _ = correlate_clusters_annotation(slide_rep_df=wsi_rep_label, annotations_df=annotations_df, purity_field=meta_field,\n",
    "                                                                                               matching_field=matching_field, corr_method=corr_method, pval_th=pval_th, field_th=None,\n",
    "                                                                                               groupby=groupby, fold_number=fold_number, directory=directory, file_name=None)\n",
    "        correlation_data[label] = all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "    # Correlations for all available cancer types.\n",
    "    shape = all_data_rho.shape\n",
    "    all_data_rho, all_data_pval, all_data_samples, mask = combine_correlations_multiple(correlation_data, shape, labels_unique, method_comb_pval=method_comb_pval, pval_th=pval_th, th_corr=th_corr, type_integration=type_integration)\n",
    "    all_data_rho.to_csv(os.path.join(correlations_path,     file_name+'_all_coef.csv'))\n",
    "    all_data_pval.to_csv(os.path.join(correlations_path,    file_name+'_all_pval.csv'))\n",
    "    all_data_samples.to_csv(os.path.join(correlations_path, file_name+'_all_samples.csv'))\n",
    "    # Remove non-significant and nan.\n",
    "    all_data_rho, all_data_pval, all_data_samples, mask = clean_correlation(all_data_rho, all_data_pval, all_data_samples, mask, th_corr, remove_nan)\n",
    "    final_dict['all'] = all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "    # Correlations for all available cancer types.\n",
    "    all_data_rho, all_data_pval, all_data_samples, mask = combine_correlations_multiple(correlation_data, shape, labels_allann, method_comb_pval=method_comb_pval, pval_th=pval_th, th_corr=th_corr, type_integration=type_integration)\n",
    "    all_data_rho.to_csv(os.path.join(correlations_path,     file_name+'_ann_coef.csv'))\n",
    "    all_data_pval.to_csv(os.path.join(correlations_path,    file_name+'_ann_pval.csv'))\n",
    "    all_data_samples.to_csv(os.path.join(correlations_path, file_name+'_ann_samples.csv'))\n",
    "    # Remove non-significant and nan.\n",
    "    all_data_rho, all_data_pval, all_data_samples, mask = clean_correlation(all_data_rho, all_data_pval, all_data_samples, mask, th_corr, remove_nan)\n",
    "    final_dict['ann'] = all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "    # Dump everything into a dataframe.\n",
    "    data_all = list()\n",
    "    for type in ['blind', 'all']:\n",
    "        for label in labels_unique:\n",
    "            if type == 'blind':\n",
    "                data_corr  = final_dict[type]\n",
    "                rho_comb_  = final_dict[type][0]\n",
    "                pval_comb_ = final_dict[type][1]\n",
    "            else:\n",
    "                data_corr  = correlation_data[label]\n",
    "                rho_comb_  = final_dict[type][0]\n",
    "                pval_comb_ = final_dict[type][1]\n",
    "            for hpc in final_dict['all'][0].columns:\n",
    "                for ann in annotation_fields:\n",
    "                    # Blind - Combined correlations for all types.\n",
    "                    rho         = np.NAN\n",
    "                    p_val       = np.NAN\n",
    "                    rho_comb    = np.NAN\n",
    "                    p_val_comb  = np.NAN\n",
    "                    sample_size = 0\n",
    "                    if ann in final_dict[type][0].index:\n",
    "                        rho         = data_corr[0].loc[ann, str(hpc)]\n",
    "                        p_val       = data_corr[1].loc[ann, str(hpc)]\n",
    "                        sample_size = data_corr[2].loc[ann, str(hpc)].astype(int)\n",
    "                        p_val_comb  = pval_comb_.loc[ann, str(hpc)]\n",
    "                        rho_comb    = rho_comb_.loc[ann, str(hpc)]\n",
    "                        data_all.append((label, ann, hpc, rho, p_val, rho_comb, p_val_comb, sample_size, type))\n",
    "\n",
    "    data_all = pd.DataFrame(data_all, columns=['Cancer Type', 'Immune Signature', 'HPC', 'Rho', 'P-Value', 'Rho Combined', 'P-Value Combined', 'Sample Size', 'Type'])\n",
    "\n",
    "    return final_dict, data_all, labels_allann, labels_unique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset name for images.\n",
    "dataset            = 'v07_10panCancer_5x'\n",
    "additional_dataset = None\n",
    "\n",
    "# Clustering folder details.\n",
    "meta_folder     = 'panC_os2_a6cl_v02_toFilter'\n",
    "meta_field      = 'labels'\n",
    "matching_field  = 'samples'\n",
    "resolution      = 2.0\n",
    "groupby         = 'leiden_%s' % resolution\n",
    "fold_number     = 1\n",
    "\n",
    "# Fold and Representations files.\n",
    "folds_pickle       = '%s/utilities/files/MultiCancer/tcga_v07_10panCancer.pkl' % main_path\n",
    "h5_complete_path   = '%s/results/BarlowTwins_3/v07_10panCancer_5x//h224_w224_n3_zdim128/hdf5_v07_10panCancer_5x_he_complete_os2_filtered_6cl.h5' % main_path\n",
    "h5_additional_path = None\n",
    "\n",
    "# Immune signatures.\n",
    "tcga_immune_csv  = '%s/utilities/files/TCGA/TCGA_immune_landscape.csv' % main_path\n",
    "immune_landscape_df = pd.read_csv(tcga_immune_csv)\n",
    "\n",
    "file_name = h5_complete_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s' % (groupby.replace('.', 'p'), fold_number)\n",
    "if h5_additional_path is not None: file_additional = h5_additional_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s' % (groupby.replace('.', 'p'), fold_number)\n",
    "\n",
    "# Setup folder scheme\n",
    "main_cluster_path = h5_complete_path.split('hdf5_')[0]\n",
    "main_cluster_path = os.path.join(main_cluster_path, meta_folder)\n",
    "adatas_path       = os.path.join(main_cluster_path, 'adatas')\n",
    "data_path            = os.path.join(main_cluster_path, 'leiden_%s_fold%s' % (str(resolution).replace('.','p'),fold_number))\n",
    "representations_path = os.path.join(data_path, 'representations')\n",
    "correlations_path    = os.path.join(data_path, 'correlations')\n",
    "figures_path          = os.path.join(data_path, 'figures')\n",
    "if not os.path.isdir(figures_path):\n",
    "    os.makedirs(representations_path)\n",
    "    os.makedirs(correlations_path)\n",
    "    os.makedirs(figures_path)\n",
    "\n",
    "# Rename variables dictionary\n",
    "rename_dict = {'Lymphocyte Infiltration Signature Score':'Lymph. Infiltration Signature Score', 'Homologous Recombination Defects':'Homologous Recomb. Defects'}\n",
    "remover_imm_fields = ['OS','OS Time','PFI','PFI Time','Neutrophils.1','Eosinophils.1',]\n",
    "immune_landscape_df = immune_landscape_df.rename(columns=rename_dict)\n",
    "immune_landscape_df  = immune_landscape_df.drop(columns=remover_imm_fields)\n",
    "\n",
    "# Images\n",
    "data = Data(dataset=dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path=main_path, load=True)\n",
    "\n",
    "# Set up vis. theme.\n",
    "sns.set_theme(style='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read H5 AnnData file where the clustering was done.\n",
    "adata_train, h5ad_path = read_h5ad_reference(h5_complete_path, meta_folder, groupby, fold_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read slide representations.\n",
    "type_composition = 'clr'\n",
    "min_tiles        = 100\n",
    "\n",
    "complete_path            = os.path.join(representations_path, '%s_%s_%s_mintiles_%s.csv' % (file_name, meta_folder, type_composition, min_tiles))\n",
    "if h5_additional_path is not None:\n",
    "    additional_complete_path = os.path.join(representations_path, '%s_%s_%s_mintiles_%s.csv' % (file_additional, meta_folder, type_composition, min_tiles))\n",
    "\n",
    "do_read = False\n",
    "if os.path.isfile(complete_path):\n",
    "    complete_df_clr = pd.read_csv(complete_path)\n",
    "    features = [column for column in complete_df_clr.columns if column != 'samples' and column != 'slides' and column != meta_field]\n",
    "    if h5_additional_path is not None:\n",
    "        if os.path.isfile(additional_complete_path):\n",
    "            additional_complete_df_clr = pd.read_csv(additional_complete_path)\n",
    "        else:\n",
    "            do_read = True\n",
    "else:\n",
    "    do_read = True\n",
    "\n",
    "if do_read:\n",
    "    all_data = build_cohort_representations(meta_folder, meta_field, matching_field, groupby, fold_number, folds_pickle, h5_complete_path, h5_additional_path,\n",
    "                                            type_composition=type_composition, min_tiles=min_tiles, use_conn=False, use_ratio=False, top_variance_feat=0, reduction=2)\n",
    "    complete_df_clr, additional_complete_df_clr, frame_clusters, frame_samples, features = all_data\n",
    "complete_df_clr.columns = complete_df_clr.columns.astype(str)\n",
    "\n",
    "# Read tile vector representations.\n",
    "folds = load_existing_split(folds_pickle)\n",
    "fold = folds[fold_number]\n",
    "dataframes, complete_df, leiden_clusters = read_csvs(adatas_path, matching_field, groupby, fold_number, fold, h5_complete_path, h5_additional_path, additional_as_fold=False, force_fold=fold_number)\n",
    "\n",
    "mapping_pancan = complete_df[[meta_field, 'patterns']].drop_duplicates().reset_index()\n",
    "mapping_pancan[meta_field] = mapping_pancan[meta_field].astype(int)\n",
    "mapping_dict = dict()\n",
    "remapping_dict = dict()\n",
    "for i in range(mapping_pancan.shape[0]):\n",
    "    mapping_dict[mapping_pancan.loc[i,'labels']]     = mapping_pancan.loc[i,'patterns']\n",
    "    remapping_dict[mapping_pancan.loc[i,'patterns']] = mapping_pancan.loc[i,'labels']\n",
    "\n",
    "# Visualize sample size per cancer type.\n",
    "data_vis = list()\n",
    "for lab, count in zip(*np.unique(complete_df_clr[1:][meta_field], return_counts=True)):\n",
    "    data_vis.append((lab,count))\n",
    "data_vis = pd.DataFrame(data_vis, columns=['Cancer Type', 'Sample Size'])\n",
    "data_vis['Cancer Type'] = data_vis['Cancer Type'].replace(mapping_dict)\n",
    "sns.set_theme(style='white')\n",
    "sns.barplot(data=data_vis, x='Cancer Type', y='Sample Size')\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "data_vis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Survival Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "event_ind_field  = 'os_event_ind'\n",
    "event_data_field = 'os_event_data'\n",
    "\n",
    "cancer_types = np.unique(data_vis['Cancer Type'].values.astype(str)).tolist()\n",
    "\n",
    "# Pan-cancer survival data.\n",
    "all_surv_df = list()\n",
    "for cancer_type in cancer_types:\n",
    "    if 'PRAD'==cancer_type: continue\n",
    "    survival_csv = '%s/utilities/files/%s/overall_survival_TCGA_folds.csv' % (main_path, cancer_type)\n",
    "    survival_df  = pd.read_csv(survival_csv)\n",
    "    survival_df['Cancer Type'] = cancer_type\n",
    "    all_surv_df.append(survival_df)\n",
    "all_surv_df = pd.concat(all_surv_df, axis=0)\n",
    "# Merge survival data with representations.\n",
    "complete_surv_df  = complete_df_clr.merge(all_surv_df, how='inner', on='samples')\n",
    "\n",
    "# Read 5-fold cross-validation.\n",
    "folds_dict = OrderedDict()\n",
    "for cancer_type in cancer_types:\n",
    "    if 'PRAD'==cancer_type: continue\n",
    "    survival_pkl = '%s/utilities/files/%s/overall_survival_TCGA_folds.pkl' % (main_path, cancer_type)\n",
    "    if os.path.isfile(survival_pkl):\n",
    "        folds = load_existing_split(survival_pkl)\n",
    "        folds_dict[cancer_type] = folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - Immune Lanscape Signatures Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_field        = 'labels'\n",
    "matching_field    = 'samples'\n",
    "corr_method      = 'spearman'\n",
    "method_comb_pval = 'fisher'\n",
    "type_integration = 'mean'\n",
    "pval_th          = 0.01\n",
    "th_corr          = 0\n",
    "remove_nan       = True\n",
    "\n",
    "# All Pan-Cancer combinations.\n",
    "corr_dict, data_all, labels_allann, labels_unique = correlations_across_types(complete_surv_df[[matching_field, meta_field]+leiden_clusters.astype(str).tolist()], immune_landscape_df, meta_field, groupby, fold_number, pval_th,\n",
    "                                                                              matching_field=matching_field, corr_method=corr_method, method_comb_pval=method_comb_pval,\n",
    "                                                                              type_integration=type_integration, th_corr=th_corr, remove_nan=remove_nan,\n",
    "                                                                              directory=correlations_path, file_name=file_name)\n",
    "data_all['Cancer Type'] = data_all['Cancer Type'].astype(int).replace(mapping_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure detail parameters.\n",
    "cellSizePixels_x  = 105\n",
    "cellSizePixels_y  = 110\n",
    "dendrogram_ratio  = (0.05, 0.2)\n",
    "fontsize_ticks    = 60\n",
    "fontsize_labels   = 70\n",
    "fontsize_annot    = 45\n",
    "p_th              = 0.05\n",
    "linewidths        = 7\n",
    "\n",
    "x_label = 'Histomorphological Phenotype Cluster (HPC)'\n",
    "\n",
    "# Per Cancer-Type Results.\n",
    "keep_th = int(len(leiden_clusters)*0.4)\n",
    "data_corr, mask_corr = keep_features_min_corr(mask=corr_dict['all'][-1], data=corr_dict['all'][0], keep_th=keep_th)\n",
    "g = fixedWidthClusterMap(dataFrame=data_corr, mask=mask_corr, x_label=x_label, y_label='Immune feature', \n",
    "                        cox_os_clusters=None, cox_pfs_clusters=None, immune_hot_clusters=None, p_th=p_th, fmt='.1f', \n",
    "                        fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, \n",
    "                        dendrogram_ratio=dendrogram_ratio, cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, \n",
    "                        offset_col_color=0, resize_col_den=0.5, linewidths=linewidths, row_cluster=True, col_cluster=True)\n",
    "                        # col_linkage=immune_linkage_clr_all)\n",
    "immune_linkage_clr_all = copy.deepcopy(g.dendrogram_col.linkage)\n",
    "plt.show()\n",
    "\n",
    "file_path = os.path.join(correlations_path, file_name + '_immune_all_dendrogram.pkl')\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(immune_linkage_clr_all, file)\n",
    "\n",
    "\n",
    "# Figure 10 Immune signatures.\n",
    "ann_to_display = ['TIL Regional Fraction', 'Lymphocyte Infiltration Signature Score', 'Leukocyte Fraction', 'Stromal Fraction', 'Macrophage Regulation',\n",
    "                  'Proliferation', 'Wound Healing', 'IFN-gamma Response', 'TGF-beta Response', 'T Cells CD8']\n",
    "# Figure 8 Immune signatures.\n",
    "ann_to_display = ['TIL Regional Fraction', 'Leukocyte Fraction', 'Stromal Fraction', 'Macrophage Regulation',\n",
    "                  'Proliferation', 'Wound Healing', 'IFN-gamma Response', 'TGF-beta Response']\n",
    "\n",
    "# Figure 4 Immune signatures.\n",
    "ann_to_display = ['TIL Regional Fraction', 'Macrophage Regulation', 'Proliferation', 'TGF-beta Response']\n",
    "\n",
    "cancer_mix           = 'all'\n",
    "data_plot            = data_all[data_all['Type']==cancer_mix]\n",
    "data_plot_ann        = data_plot[data_plot['Immune Signature'].isin(ann_to_display)]\n",
    "data_plot_ann['HPC'] = data_plot_ann['HPC'].astype(str)\n",
    "data_plot_ann        = data_plot_ann.sort_values(by=['Rho Combined', 'Sample Size'], ascending=False)\n",
    "\n",
    "p = relplot_figure(data=data_plot_ann, y='Rho', x='HPC', hue='Cancer Type', col_wrap=2, col='Immune Signature', col_order=ann_to_display, size='Sample Size', pval_th=pval_th,\n",
    "                   sizes=(30, 150), height=3, aspect=3.5, facet_kws={'sharex': False, 'sharey': True})\n",
    "\n",
    "legend_colors = dict()\n",
    "for i, handle in enumerate(p._legend.legendHandles):\n",
    "    text = handle._label\n",
    "    if text not in np.unique(data_plot_ann['Cancer Type']): continue\n",
    "    legend_colors[text]= handle._hatch_color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - C-Index HPCs Multi-cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hpc, matching_field, event_ind_field, event_data_field, dataframe, fold, use_fold=True):\n",
    "    train_set, valid_set, test_set = fold\n",
    "    train_df = dataframe[dataframe[matching_field].isin(train_set)]\n",
    "    test_df  = dataframe[dataframe[matching_field].isin(test_set)]\n",
    "    if not use_fold:\n",
    "        dataframe.insert(loc=0, column='hazard', value=dataframe[str(hpc)].values)\n",
    "        median_cutoff = dataframe['hazard'].median()\n",
    "        frame_return = dataframe\n",
    "    else:\n",
    "        train_df.insert(loc=0, column='hazard', value=train_df[str(hpc)].values)\n",
    "        test_df.insert(loc=0,  column='hazard', value=test_df[str(hpc)].values)\n",
    "        median_cutoff = train_df['hazard'].median()\n",
    "        frame_return = test_df\n",
    "\n",
    "    return frame_return, median_cutoff\n",
    "    \n",
    "def evaluation_and_riskgroups(evaluation_df, median_cutoff, risk_groups, event_data_field, event_ind_field):\n",
    "    c_index    = np.round(concordance_index_censored(evaluation_df[event_ind_field]==1.0, evaluation_df[event_data_field], evaluation_df['hazard'])[0], 3)\n",
    "    high_risk = evaluation_df[evaluation_df['hazard'].values>median_cutoff]\n",
    "    low_risk  = evaluation_df[evaluation_df['hazard'].values<=median_cutoff]\n",
    "    risk_groups[1] = risk_groups[1].append(high_risk, ignore_index=True)\n",
    "    risk_groups[0] = risk_groups[0].append(low_risk, ignore_index=True)\n",
    "    return c_index, risk_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fold = True\n",
    "\n",
    "ci_data       = list()\n",
    "c_indexes_u   = list()\n",
    "c_indexes_ci  = list()\n",
    "p_values      = list()\n",
    "for cancer_type in folds_dict:\n",
    "    cancer_cindexes_u   = list()\n",
    "    cancer_cindexes_ci  = list()\n",
    "    cancer_pvalues      = list()\n",
    "    folds_type          = folds_dict[cancer_type]\n",
    "    for hpc in leiden_clusters:\n",
    "        subset_df  = complete_surv_df[complete_surv_df['Cancer Type']==cancer_type]\n",
    "        subset_df  = subset_df[[matching_field, str(hpc), event_ind_field, event_data_field]]\n",
    "        \n",
    "        folds_cindex         = list()\n",
    "        risk_groups          = [pd.DataFrame(), pd.DataFrame()]\n",
    "        for i, fold in enumerate(folds_type):\n",
    "            evaluation_df, median_cutoff = train_model(hpc, matching_field, event_ind_field, event_data_field, subset_df, fold, use_fold=use_fold)\n",
    "            c_index, risk_groups = evaluation_and_riskgroups(evaluation_df, median_cutoff, risk_groups, event_data_field, event_ind_field)\n",
    "            folds_cindex.append(c_index)\n",
    "            if not use_fold:\n",
    "                break\n",
    "            \n",
    "        # calculate split and p-value.\n",
    "        c_index_u  = np.round(np.mean(folds_cindex),3)\n",
    "        mean, minus, plus = mean_confidence_interval(folds_cindex, confidence=0.95)\n",
    "        c_index_ci = np.round(plus-mean,3)\n",
    "\n",
    "        high_risk = risk_groups[1]\n",
    "        low_risk  = risk_groups[0]\n",
    "        p_value   = np.round(logrank_test(high_risk[event_data_field].astype(float), low_risk[event_data_field].astype(float), event_observed_A=high_risk[event_ind_field].astype(float), event_observed_B=low_risk[event_ind_field].astype(float)).p_value, 3)\n",
    "        ci_data.append((cancer_type, hpc, c_index_u, c_index_ci, p_value))\n",
    "        cancer_cindexes_u.append(c_index_u)\n",
    "        cancer_cindexes_ci.append(c_index_ci)\n",
    "        cancer_pvalues.append(p_value)\n",
    "    c_indexes_u.append(cancer_cindexes_u)\n",
    "    c_indexes_ci.append(cancer_cindexes_ci)\n",
    "    p_values.append(cancer_pvalues)\n",
    "\n",
    "# P Value for visualization.\n",
    "ci_data = pd.DataFrame(ci_data, columns=['Cancer Type', 'HPC', 'C-Index Mean', 'C-Index 95CI', 'P-Value'])\n",
    "ci_data['P-Value-Minus'] = -ci_data['P-Value'].values\n",
    "\n",
    "# DataFrames for clusterplot.\n",
    "c_indexes_u = pd.DataFrame(c_indexes_u, columns=leiden_clusters)\n",
    "c_indexes_u.index = folds_dict.keys()\n",
    "c_indexes_ci = pd.DataFrame(c_indexes_ci, columns=leiden_clusters)\n",
    "c_indexes_ci.index = folds_dict.keys()\n",
    "\n",
    "p_values = pd.DataFrame(p_values, columns=leiden_clusters)\n",
    "p_values.index = folds_dict.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = 'Histomorphological Phenotype Cluster (HPC)'\n",
    "y_label = 'Cancer Type'\n",
    "cellSizePixels_x  = 130\n",
    "cellSizePixels_y  = 110\n",
    "dendrogram_ratio  = (0.05, 0.2)\n",
    "fontsize_ticks    = 60\n",
    "fontsize_labels   = 70\n",
    "fontsize_annot    = 45\n",
    "linewidths        = 7\n",
    "\n",
    "p_th = 0.05\n",
    "c_i  = 0.50\n",
    "c_indexes_vis = c_indexes_u\n",
    "p_values_vis  = p_values\n",
    "mask_vis      = p_values_vis > p_th\n",
    "g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                         fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                         cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths, \n",
    "                         row_cluster=True, col_cluster=True)\n",
    "col_dendrogram = g.dendrogram_col.linkage\n",
    "row_dendrogram = g.dendrogram_row .linkage\n",
    "figure_name = 'hpc_mean.png'\n",
    "print(figure_name)\n",
    "plt.show()\n",
    "\n",
    "if use_fold:\n",
    "    c_i  = 0.0\n",
    "    c_indexes_vis = c_indexes_ci\n",
    "    g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                            fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                            cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths,\n",
    "                            col_linkage=col_dendrogram, row_linkage=row_dendrogram, row_cluster=True, col_cluster=True)\n",
    "    figure_name = 'hpc_ci.png'\n",
    "    print(figure_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This figure uses the dendogram from immune signature correlations.\n",
    "# Figure detail parameters.\n",
    "x_label = 'Histomorphological Phenotype Cluster (HPC)'\n",
    "y_label = 'Cancer Type'\n",
    "cellSizePixels_x  = 130\n",
    "cellSizePixels_y  = 110\n",
    "dendrogram_ratio  = (0.05, 0.2)\n",
    "fontsize_ticks    = 80\n",
    "fontsize_labels   = 90\n",
    "fontsize_annot    = 45\n",
    "linewidths        = 7\n",
    "\n",
    "\n",
    "p_th = 0.05\n",
    "c_i  = 0.50\n",
    "c_indexes_vis = c_indexes_u\n",
    "p_values_vis  = p_values\n",
    "mask_vis      = p_values_vis > p_th\n",
    "g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                         fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                         cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths,\n",
    "                         col_linkage=immune_linkage_clr_all)\n",
    "row_dendrogram = g.dendrogram_row .linkage\n",
    "figure_name = 'hpc_mean_x_immune.png'\n",
    "print(figure_name)\n",
    "plt.show()\n",
    "\n",
    "if use_fold:\n",
    "    p_th = 0.05\n",
    "    c_i  = 0.0\n",
    "    c_indexes_vis = c_indexes_ci\n",
    "    g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                            fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                            cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.4, linewidths=linewidths,\n",
    "                            col_linkage=immune_linkage_clr_all, row_linkage=row_dendrogram)\n",
    "    figure_name = 'hpc_ci_x_immune.png'\n",
    "    print(figure_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - Latent Space and Cluster Network - Multi-cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "if os.path.isfile(h5ad_path.replace('.h5ad', '_paga.h5ad')):\n",
    "    done=True\n",
    "    adata_train = anndata.read_h5ad(h5ad_path.replace('.h5ad', '_paga.h5ad'))\n",
    "else:\n",
    "    sc.tl.paga(adata_train, groups=groupby, neighbors_key='nn_leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Graph visualization related\n",
    "# This next variable can be modified so it more clearly shows the cluster network\n",
    "# Layout corresponds to the technique for the cluster network layout.\n",
    "# Threshold corresponds to threshold for the edge connection between nodes, higher values keep only stronger bonds.\n",
    "layout           = 'fa'  # fa, fr, rt, rt_circular, drl, eq_tree\n",
    "random_state     = 3\n",
    "threshold        = 0.75\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 5\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .01\n",
    "fontsize         = 10\n",
    "fontoutline      = 2\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "fig = plt.figure(figsize=(100,10))\n",
    "ax  = fig.add_subplot(1, 3, 1)\n",
    "sc.pl.paga(adata_train, layout=layout, random_state=random_state, color=meta_field, threshold=threshold, node_size_scale=node_size_scale, node_size_power=node_size_power,\n",
    "           edge_width_scale=edge_width_scale, fontsize=fontsize, fontoutline=fontoutline, frameon=False, show=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not done:\n",
    "    sc.tl.umap(adata_train, init_pos=\"paga\", neighbors_key='nn_leiden')\n",
    "    adata_train.write(h5ad_path.replace('.h5ad', '_paga.h5ad'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_field        = 'labels'\n",
    "matching_field    = 'samples'\n",
    "corr_method       = 'spearman'\n",
    "method_comb_pval  = 'fisher'\n",
    "type_integration  = 'mean'\n",
    "pval_th           = 0.01\n",
    "th_corr           = 0\n",
    "remove_nan        = True\n",
    "\n",
    "# Remove cancer types.\n",
    "data_frame_to_use = complete_df_clr.copy(deep=True)\n",
    "\n",
    "# All Pan-Cancer subset.\n",
    "corr_dict, data_all, labels_allann, labels_unique = correlations_across_types(data_frame_to_use, immune_landscape_df, meta_field, groupby, fold_number, pval_th,\n",
    "                                                                              matching_field=matching_field, corr_method=corr_method, method_comb_pval=method_comb_pval,\n",
    "                                                                              type_integration=type_integration, th_corr=th_corr, remove_nan=remove_nan,\n",
    "                                                                              directory=correlations_path, file_name=file_name)\n",
    "data_all['Cancer Type'] = data_all['Cancer Type'].astype(int).replace(mapping_dict)\n",
    "\n",
    "all_data_rho_clr = corr_dict['all'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_umap_annotations(ax1):\n",
    "    # HPC 20\n",
    "    old_x = ax1.texts[20]._x\n",
    "    ax1.texts[20]._x = old_x*1.03\n",
    "\n",
    "    # HPC 17\n",
    "    old_y = ax1.texts[17]._y\n",
    "    ax1.texts[17]._y = old_y*1.8\n",
    "    # HPC 30\n",
    "    old_y = ax1.texts[30]._y\n",
    "    ax1.texts[30]._y = old_y*0.2\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1  = fig.add_subplot(1, 1, 1)\n",
    "colors = sns.color_palette('tab20', len(np.unique(adata_train.obs[groupby].values)))\n",
    "ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='on data', frameon=False, show=False, ax=ax1, color=groupby, palette=colors, size=10)\n",
    "ax1.set_title('')\n",
    "\n",
    "fix_umap_annotations(ax1=ax1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_1 = 'TIL Regional Fraction'\n",
    "feature_2 = 'Proliferation'\n",
    "feature_3 = 'TGF-beta Response'\n",
    "\n",
    "# feature_1 = 'Macrophage Regulation'\n",
    "# feature_2 = 'Wound Healing'\n",
    "# feature_3 = 'Stromal Fraction'\n",
    "\n",
    "adata_train.obs['Cancer Type'] = adata_train.obs['labels'].astype(float).replace(mapping_dict).values\n",
    "adata_train.obs['samples']     = adata_train.obs['slides'].apply(lambda x: '-'.join(x.split('-')[:3]))\n",
    "adata_train.obs['TSS Code']    = adata_train.obs['samples'].apply(lambda x: x.split('-')[1]).values.astype(str)\n",
    "feat1_assignations = list()\n",
    "feat2_assignations = list()\n",
    "feat3_assignations = list()\n",
    "for leiden_tile in adata_train.obs[groupby].values.astype(str):\n",
    "    feat1_assignations.append(all_data_rho_clr.loc[feature_1,leiden_tile])\n",
    "    feat2_assignations.append(all_data_rho_clr.loc[feature_2,leiden_tile])\n",
    "    feat3_assignations.append(all_data_rho_clr.loc[feature_3,leiden_tile])\n",
    "adata_train.obs[feature_1] = feat1_assignations\n",
    "adata_train.obs[feature_2] = feat2_assignations\n",
    "adata_train.obs[feature_3] = feat3_assignations\n",
    "\n",
    "# Graph visualization related\n",
    "layout           = 'fa'  # fa, fr, rt, rt_circular, drl, eq_tree\n",
    "random_state     = 0\n",
    "threshold        = 0.74\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 7\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .05\n",
    "fontsize    = 15\n",
    "fontoutline = 4\n",
    "marker_size = 3\n",
    "only_seleted = []\n",
    "\n",
    "\n",
    "cmap = sns.diverging_palette(250, 20, as_cmap=True)\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "fig = plt.figure(figsize=(30,10))\n",
    "\n",
    "ax1  = fig.add_subplot(1, 3, 1)\n",
    "colors = sns.color_palette('tab20', len(np.unique(adata_train.obs[groupby].values)))\n",
    "ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='on data', frameon=False, show=False, ax=ax1, color=groupby, palette=colors, size=marker_size)\n",
    "fix_umap_annotations(ax1=ax1)\n",
    "prev_texts = ax1.texts\n",
    "\n",
    "\n",
    "# Axes 2 - TIL Regional Fraction\n",
    "vmax = np.max(adata_train.obs[feature_2].to_numpy())\n",
    "vmin = np.min(adata_train.obs[feature_2].to_numpy())\n",
    "if vmin != 0:\n",
    "    vmin = -vmax\n",
    "ax2  = fig.add_subplot(1, 3, 2)\n",
    "ax2 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, show=False, ax=ax2, color=feature_2, cmap=cmap, legend_loc=None, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "ax2.set_title(feature_2, fontweight='bold', fontsize=20)\n",
    "cbar = ax2.collections[-1].colorbar\n",
    "for a in prev_texts:\n",
    "    ax2.annotate(a._text, xy=(a._x,a._y), color=a._color, verticalalignment=a._verticalalignment, horizontalalignment=a._horizontalalignment,\n",
    "                 fontproperties=a._fontproperties, linespacing=a._linespacing, path_effects=a._path_effects)\n",
    "# adjust_text(ax2.texts)\n",
    "prev_texts = ax2.texts\n",
    "# # Legend on side\n",
    "cbar.ax.tick_params(labelsize=fontsize*0.9)\n",
    "[label.set_fontweight('bold') for label in cbar.ax.get_yticklabels()]\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cbar.locator = tick_locator\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Axes 2 - Macrophage Regulation\n",
    "vmax = np.max(adata_train.obs[feature_3].to_numpy())\n",
    "vmin = np.min(adata_train.obs[feature_3].to_numpy())\n",
    "if vmin != 0:\n",
    "    vmin = -vmax\n",
    "\n",
    "ax3  = fig.add_subplot(1, 3, 3)\n",
    "ax3 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, show=False, ax=ax3, color=feature_3, cmap=cmap, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "ax3.set_title(feature_3, fontweight='bold', fontsize=20)\n",
    "cbar = ax3.collections[-1].colorbar\n",
    "for a in prev_texts:\n",
    "    ax3.annotate(a._text, xy=(a._x,a._y), color=a._color, verticalalignment=a._verticalalignment, horizontalalignment=a._horizontalalignment,\n",
    "                 fontproperties=a._fontproperties, linespacing=a._linespacing, path_effects=a._path_effects)\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cbar.locator = tick_locator\n",
    "cbar.update_ticks()\n",
    "\n",
    "# # Legend on side\n",
    "cbar.ax.tick_params(labelsize=fontsize*0.9)\n",
    "[label.set_fontweight('bold') for label in cbar.ax.get_yticklabels()]\n",
    "\n",
    "ax1.clear()\n",
    "\n",
    "# Axes 1 - TIL Regional Fraction\n",
    "vmax = np.max(adata_train.obs[feature_1].to_numpy())\n",
    "vmin = np.min(adata_train.obs[feature_1].to_numpy())\n",
    "if vmin != 0:\n",
    "    vmin = -vmax\n",
    "ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, show=False, ax=ax1, color=feature_1, cmap=cmap, legend_loc=None, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "ax1.set_title(feature_1, fontweight='bold', fontsize=20)\n",
    "cbar = ax1.collections[-1].colorbar\n",
    "for a in prev_texts:\n",
    "    ax1.annotate(a._text, xy=(a._x,a._y), color=a._color, verticalalignment=a._verticalalignment, horizontalalignment=a._horizontalalignment,\n",
    "                 fontproperties=a._fontproperties, linespacing=a._linespacing, path_effects=a._path_effects)\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cbar.locator = tick_locator\n",
    "cbar.update_ticks()\n",
    "\n",
    "# # Legend on side\n",
    "cbar.ax.tick_params(labelsize=fontsize*0.9)\n",
    "[label.set_fontweight('bold') for label in cbar.ax.get_yticklabels()]\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HPC - Tile Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_img(data):\n",
    "    content = h5py.File(data.hdf5_path, 'r')\n",
    "    frame = pd.DataFrame(range(data.images.shape[0]), columns=['indexes'])\n",
    "    for key in content.keys():\n",
    "        if 'slides' in key:\n",
    "            frame['slides'] = content[key][:].astype(str)\n",
    "        elif 'tiles' in key:\n",
    "            frame['tiles'] = content[key][:].astype(str)\n",
    "    return data.images, frame\n",
    "\n",
    "images, frame_img = data_img(data=data.training)\n",
    "\n",
    "tiles_df = pd.concat([dataframes[0], dataframes[1], dataframes[2]])\n",
    "tiles_df = tiles_df.merge(frame_img, on=['slides','tiles'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_set_images(review_clusters, frame, images, groupby, batches=1, ncols=20, nrows=4, annotated=None):\n",
    "    for cluster_id in review_clusters:\n",
    "        indexes       = frame[(frame[groupby]==cluster_id)]['indexes'].values.tolist()\n",
    "        random.shuffle(indexes)\n",
    "        combined_plot = sorted(indexes[:100*batches])\n",
    "\n",
    "        csv_information = list()\n",
    "        images_cluster = list()\n",
    "        for index in combined_plot:\n",
    "            images_cluster.append(images[int(index)]/255.)\n",
    "\n",
    "        for batch in range(batches):\n",
    "            fig, axs = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "            fig.set_figheight(8)\n",
    "            fig.set_figwidth(8*(ncols/4)*0.8)\n",
    "            if annotated is not None:\n",
    "                fig.suptitle('HPC %s - %s' % (cluster_id, annotated), ha='center', fontweight='bold', fontsize=65)\n",
    "            else:\n",
    "                fig.suptitle('HPC %s' % (cluster_id), ha='center', fontweight='bold', fontsize=65)\n",
    "            gs = axs[0, -4].get_gridspec()\n",
    "            # remove the underlying axes\n",
    "            for i in range(ncols-4,ncols):\n",
    "                for ax in axs[0:, i]:\n",
    "                    ax.remove()\n",
    "            axbig = fig.add_subplot(gs[0:, -4:])\n",
    "            axbig.set_xticks([])\n",
    "            axbig.set_yticks([])\n",
    "            axbig.set_yticks([])\n",
    "            axes_list = list(axs.flatten())\n",
    "            axes_list.append(axbig)\n",
    "            for ax, im in zip(axes_list, images_cluster[batch*100:(batch+1)*100]):\n",
    "                ax.imshow(im)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.set_yticks([])\n",
    "                for axis in ['top','bottom','left','right']:\n",
    "                    ax.spines[axis].set_linewidth(4)\n",
    "            plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "def cluster_set_images_pertype(review_clusters, frame, images, groupby, batches=1, ncols=20, nrows=4, annotated=False, remove_type=None, legend_colors=None, wspace=0.1, figures_path=None):\n",
    "    types = [type for type in np.unique(frame.patterns) if type not in remove_type]\n",
    "\n",
    "    colors = sns.color_palette(legend_colors, len(types))\n",
    "\n",
    "    if figures_path is not None and not os.path.isdir(figures_path):\n",
    "        figures_path = os.path.join(figures_path, 'cluster_samples')\n",
    "        os.makedirs(figures_path)\n",
    "\n",
    "    indexes_dict = dict()\n",
    "    for cluster_id in review_clusters:\n",
    "        cluster_frame = frame[(frame[groupby]==cluster_id)]\n",
    "        for type in types:\n",
    "            indexes = cluster_frame[cluster_frame.patterns==type]['indexes_x'].values.tolist()\n",
    "            random.shuffle(indexes)\n",
    "            indexes_dict[type] = indexes\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            fig, axs = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "            fig.set_figheight(8)\n",
    "            fig.set_figwidth(8*(ncols/4)*0.6)\n",
    "            if annotated:\n",
    "                fig.suptitle('HPC %s' % (cluster_id), ha='center', fontweight='bold', fontsize=50)\n",
    "\n",
    "            for i, type in enumerate(indexes_dict):\n",
    "                axes_type = list()\n",
    "                indexes_type = indexes_dict[type]\n",
    "                column = 0\n",
    "                cols_type = int(ncols/len(types))\n",
    "\n",
    "                gs = axs[-1, 2*(i)].get_gridspec()\n",
    "                axs[-1, 2*i].remove()\n",
    "                axs[-2, 2*i].remove()\n",
    "                axs[-1, 2*(i)+1].remove()\n",
    "                axs[-2, 2*(i)+1].remove()\n",
    "                axbig = fig.add_subplot(gs[-2:, 2*(i):2*(i)+2])\n",
    "                axes_type.append(axbig)\n",
    "\n",
    "                for column in range(cols_type):\n",
    "                    for row in range(nrows-2):\n",
    "                        ax = axs[row, i*cols_type + column]\n",
    "                        axes_type.append(ax)\n",
    "\n",
    "                for j, ax in enumerate(axes_type):\n",
    "                    index = indexes_type[batch*len(axes_type)+j]\n",
    "                    im    = images[int(index)]/255.\n",
    "                    ax.imshow(im)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    for axis in ['top','bottom','left','right']:\n",
    "                        ax.spines[axis].set_linewidth(4)\n",
    "                        ax.spines[axis].set_color(colors[i])\n",
    "                    if j == 0:\n",
    "                        ax.set_xlabel(type, fontsize=26, fontweight='bold')\n",
    "                        ax.xaxis.set_label_coords(.5, -.1)\n",
    "\n",
    "            plt.subplots_adjust(wspace=wspace, hspace=0.1)\n",
    "            fig.tight_layout()\n",
    "            if figures_path is not None:\n",
    "                plt.savefig(os.path.join(figures_path, 'HPC_%s_batch%s.jpg' % (cluster_id, batch)), dpi=500)\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cluster_set_images_pertype(review_clusters=leiden_clusters, frame=tiles_df, images=images, groupby=groupby, batches=2, ncols=20, nrows=6, annotated=True, remove_type=list(),\n",
    "                           legend_colors='tab10', wspace=0.05, figures_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
