{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adalberto/.local/lib/python3.7/site-packages/umap/__init__.py:9: UserWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
      "  warn(\"Tensorflow not installed; ParametricUMAP will be unavailable\")\n"
     ]
    }
   ],
   "source": [
    "from lifelines.statistics    import logrank_test\n",
    "from lifelines.utils         import concordance_index\n",
    "from sksurv.metrics          import concordance_index_censored\n",
    "from matplotlib.colors       import LinearSegmentedColormap\n",
    "from matplotlib.colors       import TwoSlopeNorm\n",
    "from matplotlib.pyplot       import rc_context\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from skimage.transform       import resize\n",
    "from scipy.cluster           import hierarchy\n",
    "from plottify                import autosize\n",
    "from PIL                     import Image\n",
    "from scipy.stats             import combine_pvalues\n",
    "from collections             import OrderedDict\n",
    "from adjustText              import adjust_text\n",
    "from matplotlib              import ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api   as sm\n",
    "import seaborn           as sns\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import scanpy            as sc\n",
    "import matplotlib\n",
    "import fastcluster\n",
    "import pickle\n",
    "import anndata\n",
    "import random\n",
    "import umap\n",
    "import h5py\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "\n",
    "main_path = '/media/adalberto/Disk2/PhD_Workspace'\n",
    "sys.path.append(main_path)\n",
    "from models.clustering.cox_proportional_hazard_regression_leiden_clusters import *\n",
    "from models.clustering.logistic_regression_leiden_clusters                import *\n",
    "from models.visualization.survival                                        import save_fold_KMs\n",
    "from models.visualization.clusters                                        import cluster_circular, plot_confusion_matrix_lr\n",
    "from models.visualization.forest_plots                                    import report_forest_plot_lr\n",
    "from models.evaluation.folds                                              import load_existing_split\n",
    "from data_manipulation.data                                               import Data\n",
    "from models.clustering.correlations      import *\n",
    "from models.clustering.data_processing   import *\n",
    "from models.visualization.attention_maps import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Figure method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_institution_distribution(data_hpc_inst, field, title, figsize=(30,7), fontsize_labels=22, fontsize_legend=20, show_max_min=False):\n",
    "    def colors_from_values(values, palette_name, normalize=False):\n",
    "        # normalize the values to range [0, 1]\n",
    "        if normalize:\n",
    "            normalized = (values - min(values)) / (max(values) - min(values))\n",
    "        else:\n",
    "            normalized = values\n",
    "        # convert to indices\n",
    "        indices = np.round(normalized * (len(values) - 1)).astype(np.int32)\n",
    "        # use the indices to get the colors\n",
    "        palette = sns.color_palette(palette_name, int(1.5*len(values)))\n",
    "        return np.array(palette).take(indices, axis=0)\n",
    "\n",
    "    fig   = plt.figure(figsize=figsize)\n",
    "    ax    = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # pal  = sns.color_palette(\"Greens_d\")\n",
    "    # rank = data_hpc_inst[field].argsort().argsort()\n",
    "    # sns.barplot(data=data_hpc_inst, x='HPC', y=field, palette=np.array(pal[::-1])[rank], ax=ax)\n",
    "\n",
    "    y = data_hpc_inst[field].values\n",
    "    sns.barplot(data=data_hpc_inst, x='HPC', y=field, palette=colors_from_values(y, \"Greens_d\"), ax=ax)\n",
    "\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_ylim([0.0,1.0])\n",
    "    yticks = (np.array(range(0,11,1))/10).tolist()\n",
    "    ax.set_yticks(yticks, yticks)\n",
    "\n",
    "    ax.set_title(title,  fontsize=fontsize_labels*1.3, fontweight='bold')\n",
    "    ax.set_xlabel('\\nHistomorphological Phenotype Cluster (HPC)', fontsize=fontsize_labels,     fontweight='bold')\n",
    "    ax.set_ylabel(' ', fontsize=fontsize_labels, fontweight='bold')\n",
    "    if show_max_min:\n",
    "        max_val = np.max(data_hpc_inst[field].values)\n",
    "        min_val = np.min(data_hpc_inst[field].values)\n",
    "        ax.axhline(max_val, linestyle='--')\n",
    "        ax.axhline(min_val, linestyle='--')\n",
    "    ax.axhline(0.50, linestyle='--', color='black')\n",
    "    ax.axhline(0.25, linestyle='--', color='black')\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(4)\n",
    "    plt.show()\n",
    "\n",
    "def get_col_colors(cox_os_clusters, cox_pfs_clusters, immune_hot_clusters, p_th):\n",
    "\n",
    "    colors        = []\n",
    "    colors_masked = []\n",
    "\n",
    "    if immune_hot_clusters is not None:\n",
    "        cmap_PiYG = sns.diverging_palette(20, 250, as_cmap=True)\n",
    "        norm      = TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1)\n",
    "        immune_clusters = [1]*cox_pfs_clusters.shape[0]\n",
    "        for key in immune_hot_clusters:\n",
    "            if key == 'hot':\n",
    "                value = -1\n",
    "            elif key == 'warm':\n",
    "                value = -0.5\n",
    "            elif key == 'cold':\n",
    "                value = 0\n",
    "            for cluster in immune_hot_clusters[key]:\n",
    "                immune_clusters[cluster] = value\n",
    "        column_immune_colors       = pd.Series([cmap_PiYG(norm(coef)) for cluster, coef in enumerate(immune_clusters)], name='Hot/Warm/Cold Lymphocytic Infiltration')\n",
    "        if cox_os_clusters is not None:\n",
    "            coef_df          = cox_os_clusters.sort_values(by=groupby)\n",
    "            column_immune_colors.index = coef_df[groupby].astype(str)\n",
    "        else:\n",
    "            column_immune_colors.index = column_immune_colors.index.astype(str)\n",
    "        colors.append(column_immune_colors)\n",
    "        colors_masked.append(column_immune_colors)\n",
    "\n",
    "    # Column colors.\n",
    "    if cox_os_clusters is not None:\n",
    "        coef_df   = cox_os_clusters.sort_values(by=groupby)\n",
    "        cmap_PiYG = plt.cm.PiYG_r\n",
    "        norm      = TwoSlopeNorm(vmin=coef_df['coef'].min(), vcenter=0, vmax=coef_df['coef'].max())\n",
    "        column_os_colors              = pd.Series([cmap_PiYG(norm(coef)) for p, coef in zip(coef_df['p'], coef_df['coef'])], name='Cox Coefficient OS')\n",
    "        column_os_colors_masked       = pd.Series([cmap_PiYG(norm(coef)) if p <p_th else cmap_PiYG(norm(0))[:3] for p, coef in zip(coef_df['p'], coef_df['coef'])], name='Cox Coefficient OS')\n",
    "        column_os_colors_masked.index = coef_df[groupby].astype(str)\n",
    "        column_os_colors.index        = coef_df[groupby].astype(str)\n",
    "        colors.append(column_os_colors)\n",
    "        colors_masked.append(column_os_colors_masked)\n",
    "\n",
    "    if cox_pfs_clusters is not None:\n",
    "        cox_pfs_clusters = cox_pfs_clusters.sort_values(by=groupby)\n",
    "        cmap_PiYG = plt.cm.PiYG_r\n",
    "        norm                     = TwoSlopeNorm(vmin=cox_pfs_clusters['coef'].astype(float).min(), vcenter=0, vmax=cox_pfs_clusters['coef'].astype(float).max())\n",
    "        column_pfs_colors        = pd.Series([cmap_PiYG(norm(coef)) for p, coef in zip(cox_pfs_clusters['p'], cox_pfs_clusters['coef'])], name='Cox Coefficient RFS')\n",
    "        column_pfs_colors_masked = pd.Series([cmap_PiYG(norm(coef)) if p <p_th else cmap_PiYG(norm(0))[:3] for p, coef in zip(cox_pfs_clusters['p'], cox_pfs_clusters['coef'])], name='Cox Coefficient RFS')\n",
    "        column_pfs_colors.index        = coef_df[groupby].astype(str)\n",
    "        column_pfs_colors_masked.index = coef_df[groupby].astype(str)\n",
    "        colors.append(column_pfs_colors)\n",
    "        colors_masked.append(column_pfs_colors)\n",
    "\n",
    "    if len(colors) != 0:\n",
    "        colors = pd.concat(colors,axis=1)\n",
    "        colors_masked = pd.concat(colors_masked,axis=1)\n",
    "    else:\n",
    "        colors        = None\n",
    "        colors_masked = None\n",
    "\n",
    "    return colors, colors_masked\n",
    "\n",
    "def fixedWidthClusterMap(dataFrame, mask, x_label, y_label, vcenter=0, annot=True, fmt='.2f', col_linkage=None, row_linkage=None, \n",
    "                        fontsize_ticks=28, fontsize_labels=30, fontsize_annot=20, dendrogram_ratio=0.2, \n",
    "                        immune_hot_clusters=None, cox_os_clusters=None, cox_pfs_clusters=None, \n",
    "                        cellSizePixels_x=50, cellSizePixels_y=50, p_th=0.05, offset_col_color=2, \n",
    "                        resize_col_den=1.0, linewidths=5.0, row_cluster=True, col_cluster=True, round_cbar=2, cmap=sns.diverging_palette(250, 20, as_cmap=True)):\n",
    "    sns.set_theme(style='white')\n",
    "\n",
    "    colors, colors_masked = get_col_colors(cox_os_clusters, cox_pfs_clusters, immune_hot_clusters, p_th)\n",
    "\n",
    "    # Calculate the figure size, this gets us close, but not quite to the right place\n",
    "    dpi = matplotlib.rcParams['figure.dpi']\n",
    "    marginWidth  = (matplotlib.rcParams['figure.subplot.right']-matplotlib.rcParams['figure.subplot.left'])\n",
    "    marginHeight = (matplotlib.rcParams['figure.subplot.top']-matplotlib.rcParams['figure.subplot.bottom'])\n",
    "    Ny,Nx = dataFrame.shape\n",
    "    figWidth = (Nx*cellSizePixels_x/dpi)/0.8/marginWidth\n",
    "    figHeigh = ((Ny+offset_col_color)*cellSizePixels_y/dpi)/0.8/marginHeight\n",
    "\n",
    "    # do the actual plot\n",
    "    vmax = np.nanmax(dataFrame[~mask].values)\n",
    "    if vcenter == 0:\n",
    "        vmin = -vmax\n",
    "        cbar_kws = dict()\n",
    "    else:\n",
    "        vmin = np.nanmin(dataFrame[~mask].values)\n",
    "        ticks = np.array([vmin*1.01, (vmin+vcenter)/2, vcenter, (vmax+vcenter)/2, vmax*0.99])\n",
    "        ticks = np.round(ticks, round_cbar)\n",
    "        cbar_kws = dict(ticks=ticks)\n",
    "\n",
    "    if col_linkage is None and col_cluster:\n",
    "        Z = hierarchy.linkage(y=dataFrame.T, method='ward', metric='euclidean', optimal_ordering=True)\n",
    "        col_linkage = Z\n",
    "\n",
    "    if row_linkage is None and col_cluster:\n",
    "        Z = hierarchy.linkage(y=dataFrame, method='ward', metric='euclidean', optimal_ordering=True)\n",
    "        row_linkage = Z\n",
    "\n",
    "    norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "    grid = sns.clustermap(dataFrame, vmin=vmin, vmax=vmax, method='ward', metric='euclidean', annot=annot, mask=mask, col_linkage=col_linkage, row_linkage=row_linkage, fmt=fmt, col_colors=colors, tree_kws=dict(linewidths=linewidths), norm=norm,\n",
    "                          cmap=cmap, dendrogram_ratio=dendrogram_ratio, annot_kws={\"size\": fontsize_annot,'fontstyle':'italic','fontweight':'bold'},  yticklabels=True,  xticklabels=True,\n",
    "                          row_cluster=row_cluster, col_cluster=col_cluster, figsize=(figWidth, figHeigh), cbar_kws=cbar_kws)\n",
    "\n",
    "    if colors is not None:\n",
    "        grid.ax_col_colors.set_yticklabels(grid.ax_col_colors.get_ymajorticklabels(), fontsize=fontsize_ticks)\n",
    "\n",
    "    # calculate the size of the heatmap axes\n",
    "    axWidth  = (Nx*cellSizePixels_x)/(figWidth*dpi)\n",
    "    axHeight = (Ny*cellSizePixels_y)/(figHeigh*dpi)\n",
    "\n",
    "    # calculate size of column colors\n",
    "    ax_colors_height = (offset_col_color*cellSizePixels_y)/(figWidth*dpi)\n",
    "\n",
    "    # resize heatmap\n",
    "    ax_heatmap_orig_pos = grid.ax_heatmap.get_position()\n",
    "    grid.ax_heatmap.set_position([ax_heatmap_orig_pos.x0, ax_heatmap_orig_pos.y0, axWidth, axHeight])\n",
    "\n",
    "    # resize row dendrogram to match\n",
    "    ax_row_orig_pos = grid.ax_row_dendrogram.get_position()\n",
    "    grid.ax_row_dendrogram.set_position([ax_row_orig_pos.x0, ax_row_orig_pos.y0, ax_row_orig_pos.width, axHeight])\n",
    "\n",
    "    # resize col_colors\n",
    "    if colors is not None:\n",
    "        ax_col_colors_orig_pos = grid.ax_col_colors.get_position()\n",
    "        grid.ax_col_colors.set_position([ax_col_colors_orig_pos.x0, ax_heatmap_orig_pos.y0+axHeight+0.01, axWidth, ax_colors_height])\n",
    "\n",
    "    # resize col dendrogram to match\n",
    "    ax_col_orig_pos = grid.ax_col_dendrogram.get_position()\n",
    "    grid.ax_col_dendrogram.set_position([ax_col_orig_pos.x0, ax_heatmap_orig_pos.y0+axHeight+ax_colors_height+0.01, axWidth, ax_col_orig_pos.height*resize_col_den])\n",
    "\n",
    "    # tick_locator = ticker.MaxNLocator(nbins=cbar_bins)\n",
    "    # grid.ax_cbar.cla.locator = tick_locator\n",
    "    # grid.ax_cbar.cla.update_ticks()\n",
    "\n",
    "    ax_cbar_orig_pos = grid.ax_cbar.get_position()\n",
    "    grid.ax_cbar.set_position([ax_row_orig_pos.x0+ax_row_orig_pos.width*0.25, ax_heatmap_orig_pos.y0+axHeight, ax_row_orig_pos.width*0.25, ax_col_orig_pos.height*resize_col_den])\n",
    "\n",
    "    grid.ax_cbar.tick_params(labelsize=fontsize_ticks*0.9, length=10)\n",
    "    [label.set_fontweight('bold') for label in grid.ax_cbar.get_yticklabels()]\n",
    "\n",
    "    grid.ax_heatmap.set_xlabel('\\n%s' % x_label, fontsize=fontsize_labels, fontweight='bold')\n",
    "    grid.ax_heatmap.set_ylabel('\\n%s' % y_label, fontsize=fontsize_labels, fontweight='bold')\n",
    "\n",
    "    grid.ax_heatmap.set_xticklabels(grid.ax_heatmap.get_xmajorticklabels(), fontsize=fontsize_ticks, weight='bold')\n",
    "    grid.ax_heatmap.set_yticklabels(grid.ax_heatmap.get_ymajorticklabels(), fontsize=fontsize_ticks, weight='bold', rotation=0)\n",
    "\n",
    "    if colors is not None:\n",
    "        [label.set_fontweight('bold') for label in grid.ax_col_colors.get_yticklabels()]\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        grid.ax_heatmap.spines[axis].set_linewidth(4)\n",
    "\n",
    "    return grid # return ClusterGrid object\n",
    "\n",
    "def show_correlation_scatter(cross_df, cluster, annotations, all_data_rho, all_data_pval, fontsize_labels=22, fontsize_title=30):\n",
    "    from decimal import Decimal\n",
    "    cross_df.columns = cross_df.columns.astype(str)\n",
    "\n",
    "    for i, annotation in enumerate(annotations):\n",
    "        rho_annotation  = all_data_rho.loc[annotation, str(cluster)]\n",
    "        pval_annotation = all_data_pval.loc[annotation, str(cluster)]\n",
    "        g = sns.jointplot(data=cross_df, x=annotation, y=str(cluster), kind='reg', ci=None, height=10, ratio=2)\n",
    "        g.ax_joint.set_ylabel('HPC %s\\nContribution' % cluster, fontsize=fontsize_labels, fontweight='bold')\n",
    "        g.ax_joint.set_xlabel(annotation, fontsize=fontsize_labels, fontweight='bold')\n",
    "\n",
    "        for tick in g.ax_joint.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_labels)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "        for tick in g.ax_joint.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_labels)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            g.ax_joint.spines[axis].set_linewidth(4)\n",
    "            g.ax_marg_x.spines[axis].set_linewidth(4)\n",
    "            g.ax_marg_y.spines[axis].set_linewidth(4)\n",
    "\n",
    "        plt.suptitle('Spearman %s=%s\\np-value=%s' % (r'$\\mathbf{\\rho}$', np.round(rho_annotation, 1), '%.1E' % Decimal(pval_annotation)), fontsize=fontsize_title, fontweight='bold')\n",
    "        g.fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def relplot_figure(data, x, y, hue, col_wrap, col, col_order, size, pval_th, sizes=(10, 100), height=3, aspect=3.5, facet_kws={'sharex': False, 'sharey': True}):\n",
    "\n",
    "    g = sns.relplot(data=data, y=y, x=x, hue=hue, col_wrap=col_wrap, col=col, col_order=col_order, size=size, sizes=sizes, height=height, aspect=aspect, facet_kws=facet_kws)\n",
    "    i = 0\n",
    "    for ax in g._axes:\n",
    "        ann = ax.get_title().split('%s = ' % col)[1]\n",
    "        data_imm = data[data[col]==ann]\n",
    "        order_hpc = data_imm.groupby(by='HPC').mean().sort_values(by='Rho').index.tolist()\n",
    "        ax.set_ylim([-0.5, 0.8])\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            label = tick.label1\n",
    "            if label._text in data_imm[data_imm['HPC']==label._text]['HPC'].values.astype(str):\n",
    "                p_val = data_imm[(data_imm['HPC']==label._text)]['P-Value Combined'].values[0]\n",
    "                if p_val < pval_th:\n",
    "                    label.set_fontsize(label._fontproperties._size*1.2)\n",
    "                    label.set_fontweight('bold')\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontweight('bold')\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(4)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax_title = ax.title._text.replace('= ', '')\n",
    "        ax.set_title(ax_title, fontsize=ax.title._fontproperties._size*1.3, fontweight='bold')\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontsize=ax.title._fontproperties._size, fontweight='bold')\n",
    "        if i%col_wrap == 0:\n",
    "            ax.set_ylabel(r'$\\mathbf{\\rho}$', fontsize=ax.title._fontproperties._size, fontweight='bold')\n",
    "        i += 1\n",
    "        ax.axhline(0.0, linestyle='--', color='grey', lw=1)\n",
    "        ax.set_title(ann, fontsize=ax.title._fontproperties._size*1.2, fontweight='bold', y=0.9)\n",
    "\n",
    "    g._legend.get_title().set_weight('bold')\n",
    "    [leg_text.set_weight('bold') for leg_text in g._legend.get_texts()]\n",
    "    plt.show()\n",
    "\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Combine correlations Pan-Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out immune feature with low number of significant correlations.\n",
    "def keep_features_min_corr(mask, data, keep_th):\n",
    "    data_plot = data.copy(deep=True)\n",
    "    mask_plot = mask.copy(deep=True)\n",
    "\n",
    "    mask_plot_th = (~mask_plot).sum(axis=1)\n",
    "    subset_features = mask_plot_th[mask_plot_th>=keep_th].index\n",
    "\n",
    "    return data_plot.loc[subset_features], mask_plot.loc[subset_features]\n",
    "\n",
    "def clean_correlation(all_data_rho, all_data_pval, all_data_samples, mask, th_corr, remove_nan=False):\n",
    "    # Remove row and columns with all non-significant\n",
    "    if th_corr>0:\n",
    "        remove_empty_row = mask[np.sum(~mask,axis=1)<=th_corr].index\n",
    "        remove_empty_col = mask.columns[np.sum(~mask,axis=0)<=th_corr].tolist()\n",
    "        all_data_rho      = all_data_rho.drop(index=remove_empty_row)\n",
    "        all_data_rho      = all_data_rho.drop(columns=remove_empty_col)\n",
    "        all_data_pval     = all_data_pval.drop(index=remove_empty_row)\n",
    "        all_data_pval     = all_data_pval.drop(columns=remove_empty_col)\n",
    "        all_data_samples  = all_data_samples.drop(index=remove_empty_row)\n",
    "        all_data_samples  = all_data_samples.drop(columns=remove_empty_col)\n",
    "        mask              = mask.drop(index=remove_empty_row)\n",
    "        mask              = mask.drop(columns=remove_empty_col)\n",
    "\n",
    "    # Remove row and columns with all nan\n",
    "    if remove_nan:\n",
    "        remove_empty_row = all_data_rho[np.sum(~(all_data_rho.isnull()),axis=1)==0].index\n",
    "        # remove_empty_col = all_data_rho.columns[np.sum(~(all_data_rho.isnull()),axis=0)==0].tolist()\n",
    "        all_data_rho      = all_data_rho.drop(index=remove_empty_row)\n",
    "        all_data_pval     = all_data_pval.drop(index=remove_empty_row)\n",
    "        all_data_samples  = all_data_samples.drop(index=remove_empty_row)\n",
    "        mask              = mask.drop(index=remove_empty_row)\n",
    "\n",
    "    return all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "def combine_correlations_multiple(correlation_data, shape, labels_consider, type_integration='weighted_average', pval_th=0.01, method_comb_pval='fisher', th_corr=0, remove_nan=False):\n",
    "    all_data_rho     = np.zeros(shape)\n",
    "    all_data_pval    = np.ones(shape)\n",
    "    all_data_samples = np.zeros(shape)\n",
    "\n",
    "    for row in range(shape[0]):\n",
    "        for column in range(shape[1]):\n",
    "            weights = [correlation_data[label][2].values[row,column].astype(int) for label in labels_consider]\n",
    "            if 'weighted_average'==type_integration:\n",
    "                all_data_rho[row,column]     = np.average([correlation_data[label][0].values[row,column] for label in labels_consider], weights=weights)\n",
    "            else:\n",
    "                all_data_rho[row,column]     = np.mean([correlation_data[label][0].values[row,column] for label in labels_consider])\n",
    "            all_data_pval[row,column]    = combine_pvalues([correlation_data[label][1].values[row,column] for label in labels_consider], method=method_comb_pval)[1]\n",
    "            all_data_samples[row,column] = np.mean([correlation_data[label][2].values[row,column] for label in labels_consider])\n",
    "\n",
    "    label = labels_consider[0]\n",
    "    all_data_rho           = pd.DataFrame(all_data_rho, columns=correlation_data[label][0].columns)\n",
    "    all_data_rho.index     = correlation_data[label][0].index\n",
    "\n",
    "    all_data_pval          = pd.DataFrame(all_data_pval, columns=correlation_data[label][0].columns)\n",
    "    all_data_pval.index    = correlation_data[label][0].index\n",
    "\n",
    "    all_data_samples       = pd.DataFrame(all_data_samples, columns=correlation_data[label][0].columns)\n",
    "    all_data_samples.index = correlation_data[label][0].index\n",
    "\n",
    "    mask = (all_data_pval.values > pval_th)\n",
    "    mask = pd.DataFrame(mask, columns=correlation_data[label][0].columns)\n",
    "    mask.index = correlation_data[label][0].index\n",
    "\n",
    "    return all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "\n",
    "    # Run correlation per label\n",
    "\n",
    "def correlations_across_types(slide_rep_df, annotations_df, meta_field, groupby, fold_number, pval_th, file_name, directory, matching_field='samples', corr_method='spearman', method_comb_pval='fisher', type_integration='weighted_average',\n",
    "                              th_corr=0, remove_nan=False):\n",
    "    # All available fields.\n",
    "    annotation_fields = [annotation for annotation in immune_landscape_df.columns if annotation not in ['slides', matching_field]]\n",
    "\n",
    "    # Get labels that have annotations for all fields.\n",
    "    merged_df     = slide_rep_df.merge(annotations_df, how='inner', left_on=matching_field, right_on=matching_field)\n",
    "    labels_allann = merged_df[~(merged_df[annotation_fields].isnull()).any(axis=1)].labels.unique()\n",
    "\n",
    "    # Correlation all types combined.\n",
    "    final_dict = dict()\n",
    "    all_data_rho_clr, all_data_pval_clr, all_data_samples_clr, mask_clr, _ = correlate_clusters_annotation(slide_rep_df=slide_rep_df, annotations_df=annotations_df, purity_field=meta_field,\n",
    "                                                                                                       matching_field=matching_field, corr_method=corr_method, pval_th=pval_th, field_th=None,\n",
    "                                                                                                       groupby=groupby, fold_number=fold_number, directory=directory, file_name=None)\n",
    "    final_dict['blind'] =  all_data_rho_clr, all_data_pval_clr, all_data_samples_clr, mask_clr\n",
    "\n",
    "    correlation_data = dict()\n",
    "    labels_unique = np.unique(slide_rep_df[1:][meta_field])\n",
    "    for label in labels_unique:\n",
    "        wsi_rep_label = slide_rep_df[slide_rep_df[meta_field]==label]\n",
    "        all_data_rho, all_data_pval, all_data_samples, mask, _ = correlate_clusters_annotation(slide_rep_df=wsi_rep_label, annotations_df=annotations_df, purity_field=meta_field,\n",
    "                                                                                               matching_field=matching_field, corr_method=corr_method, pval_th=pval_th, field_th=None,\n",
    "                                                                                               groupby=groupby, fold_number=fold_number, directory=directory, file_name=None)\n",
    "        correlation_data[label] = all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "    # Correlations for all available cancer types.\n",
    "    shape = all_data_rho.shape\n",
    "    all_data_rho, all_data_pval, all_data_samples, mask = combine_correlations_multiple(correlation_data, shape, labels_unique, method_comb_pval=method_comb_pval, pval_th=pval_th, th_corr=th_corr, type_integration=type_integration)\n",
    "    all_data_rho.to_csv(os.path.join(correlations_path,     file_name+'_all_coef.csv'))\n",
    "    all_data_pval.to_csv(os.path.join(correlations_path,    file_name+'_all_pval.csv'))\n",
    "    all_data_samples.to_csv(os.path.join(correlations_path, file_name+'_all_samples.csv'))\n",
    "    # Remove non-significant and nan.\n",
    "    all_data_rho, all_data_pval, all_data_samples, mask = clean_correlation(all_data_rho, all_data_pval, all_data_samples, mask, th_corr, remove_nan)\n",
    "    final_dict['all'] = all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "    # Correlations for all available cancer types.\n",
    "    all_data_rho, all_data_pval, all_data_samples, mask = combine_correlations_multiple(correlation_data, shape, labels_allann, method_comb_pval=method_comb_pval, pval_th=pval_th, th_corr=th_corr, type_integration=type_integration)\n",
    "    all_data_rho.to_csv(os.path.join(correlations_path,     file_name+'_ann_coef.csv'))\n",
    "    all_data_pval.to_csv(os.path.join(correlations_path,    file_name+'_ann_pval.csv'))\n",
    "    all_data_samples.to_csv(os.path.join(correlations_path, file_name+'_ann_samples.csv'))\n",
    "    # Remove non-significant and nan.\n",
    "    all_data_rho, all_data_pval, all_data_samples, mask = clean_correlation(all_data_rho, all_data_pval, all_data_samples, mask, th_corr, remove_nan)\n",
    "    final_dict['ann'] = all_data_rho, all_data_pval, all_data_samples, mask\n",
    "\n",
    "    # Dump everything into a dataframe.\n",
    "    data_all = list()\n",
    "    for type in ['blind', 'all']:\n",
    "        for label in labels_unique:\n",
    "            if type == 'blind':\n",
    "                data_corr  = final_dict[type]\n",
    "                rho_comb_  = final_dict[type][0]\n",
    "                pval_comb_ = final_dict[type][1]\n",
    "            else:\n",
    "                data_corr  = correlation_data[label]\n",
    "                rho_comb_  = final_dict[type][0]\n",
    "                pval_comb_ = final_dict[type][1]\n",
    "            for hpc in final_dict['all'][0].columns:\n",
    "                for ann in annotation_fields:\n",
    "                    # Blind - Combined correlations for all types.\n",
    "                    rho         = np.NAN\n",
    "                    p_val       = np.NAN\n",
    "                    rho_comb    = np.NAN\n",
    "                    p_val_comb  = np.NAN\n",
    "                    sample_size = 0\n",
    "                    if ann in final_dict[type][0].index:\n",
    "                        rho         = data_corr[0].loc[ann, str(hpc)]\n",
    "                        p_val       = data_corr[1].loc[ann, str(hpc)]\n",
    "                        sample_size = data_corr[2].loc[ann, str(hpc)].astype(int)\n",
    "                        p_val_comb  = pval_comb_.loc[ann, str(hpc)]\n",
    "                        rho_comb    = rho_comb_.loc[ann, str(hpc)]\n",
    "                        data_all.append((label, ann, hpc, rho, p_val, rho_comb, p_val_comb, sample_size, type))\n",
    "\n",
    "    data_all = pd.DataFrame(data_all, columns=['Cancer Type', 'Immune Signature', 'HPC', 'Rho', 'P-Value', 'Rho Combined', 'P-Value Combined', 'Sample Size', 'Type'])\n",
    "\n",
    "    return final_dict, data_all, labels_allann, labels_unique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: /media/adalberto/Disk2/PhD_Workspace/datasets/v07_10panCancer_5x/he/patches_h224_w224/hdf5_v07_10panCancer_5x_he_train.h5\n",
      "Validation Set: /media/adalberto/Disk2/PhD_Workspace/datasets/v07_10panCancer_5x/he/patches_h224_w224/hdf5_v07_10panCancer_5x_he_validation.h5\n",
      "Test Set: /media/adalberto/Disk2/PhD_Workspace/datasets/v07_10panCancer_5x/he/patches_h224_w224/hdf5_v07_10panCancer_5x_he_test.h5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset name for images.\n",
    "dataset            = 'v07_10panCancer_5x'\n",
    "additional_dataset = None\n",
    "\n",
    "# Clustering folder details.\n",
    "meta_folder     = 'panC_os2_a6cl_v02_toFilter'\n",
    "meta_field      = 'labels'\n",
    "matching_field  = 'samples'\n",
    "resolution      = 2.0\n",
    "# resolution      = 3.5\n",
    "groupby         = 'leiden_%s' % resolution\n",
    "fold_number     = 1\n",
    "\n",
    "# Fold and Representations files.\n",
    "folds_pickle       = '%s/utilities/files/PanCancer/tcga_v07_10panCancer.pkl' % main_path\n",
    "h5_complete_path   = '%s/results/BarlowTwins_3/v07_10panCancer_5x//h224_w224_n3_zdim128/hdf5_v07_10panCancer_5x_he_complete_os2_filtered_6cl.h5' % main_path\n",
    "h5_additional_path = None\n",
    "\n",
    "# Immune signatures.\n",
    "tcga_immune_csv  = '%s/utilities/files/TCGA/TCGA_immune_landscape.csv' % main_path\n",
    "immune_landscape_df = pd.read_csv(tcga_immune_csv)\n",
    "\n",
    "file_name = h5_complete_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s' % (groupby.replace('.', 'p'), fold_number)\n",
    "if h5_additional_path is not None: file_additional = h5_additional_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s' % (groupby.replace('.', 'p'), fold_number)\n",
    "\n",
    "# Setup folder scheme\n",
    "main_cluster_path = h5_complete_path.split('hdf5_')[0]\n",
    "main_cluster_path = os.path.join(main_cluster_path, meta_folder)\n",
    "adatas_path       = os.path.join(main_cluster_path, 'adatas')\n",
    "data_path            = os.path.join(main_cluster_path, 'leiden_%s_fold%s' % (str(resolution).replace('.','p'),fold_number))\n",
    "representations_path = os.path.join(data_path, 'representations')\n",
    "correlations_path    = os.path.join(data_path, 'correlations')\n",
    "figures_path          = os.path.join(data_path, 'figures')\n",
    "if not os.path.isdir(figures_path):\n",
    "    os.makedirs(representations_path)\n",
    "    os.makedirs(correlations_path)\n",
    "    os.makedirs(figures_path)\n",
    "\n",
    "# Rename variables dictionary\n",
    "rename_dict = {'Lymphocyte Infiltration Signature Score':'Lymph. Infiltration Signature Score', 'Homologous Recombination Defects':'Homologous Recomb. Defects'}\n",
    "remover_imm_fields = ['OS','OS Time','PFI','PFI Time','Neutrophils.1','Eosinophils.1',]\n",
    "immune_landscape_df = immune_landscape_df.rename(columns=rename_dict)\n",
    "immune_landscape_df  = immune_landscape_df.drop(columns=remover_imm_fields)\n",
    "\n",
    "# Images\n",
    "data = Data(dataset=dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path='/media/adalberto/Disk2/PhD_Workspace', load=True)\n",
    "\n",
    "# Set up vis. theme.\n",
    "sns.set_theme(style='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read H5 AnnData file where the clustering was done.\n",
    "adata_train, h5ad_path = read_h5ad_reference(h5_complete_path, meta_folder, groupby, fold_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adalberto/.local/lib/python3.7/site-packages/ipykernel_launcher.py:30: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancer Type</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CESC</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COAD</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LUAD</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LUSC</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRAD</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SKCM</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STAD</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UCEC</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cancer Type  Sample Size\n",
       "0        BLCA          384\n",
       "1        BRCA         1011\n",
       "2        CESC          231\n",
       "3        COAD          400\n",
       "4        LUAD          434\n",
       "5        LUSC          467\n",
       "6        PRAD          378\n",
       "7        SKCM          405\n",
       "8        STAD          350\n",
       "9        UCEC          500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read slide representations.\n",
    "type_composition = 'clr'\n",
    "min_tiles        = 100\n",
    "\n",
    "complete_path            = os.path.join(representations_path, '%s_%s_%s_mintiles_%s.csv' % (file_name, meta_folder, type_composition, min_tiles))\n",
    "if h5_additional_path is not None:\n",
    "    additional_complete_path = os.path.join(representations_path, '%s_%s_%s_mintiles_%s.csv' % (file_additional, meta_folder, type_composition, min_tiles))\n",
    "\n",
    "do_read = False\n",
    "if os.path.isfile(complete_path):\n",
    "    complete_df_clr = pd.read_csv(complete_path)\n",
    "    features = [column for column in complete_df_clr.columns if column != 'samples' and column != 'slides' and column != meta_field]\n",
    "    if h5_additional_path is not None:\n",
    "        if os.path.isfile(additional_complete_path):\n",
    "            additional_complete_df_clr = pd.read_csv(additional_complete_path)\n",
    "        else:\n",
    "            do_read = True\n",
    "else:\n",
    "    do_read = True\n",
    "\n",
    "if do_read:\n",
    "    all_data = build_cohort_representations(meta_folder, meta_field, matching_field, groupby, fold_number, folds_pickle, h5_complete_path, h5_additional_path,\n",
    "                                            type_composition=type_composition, min_tiles=min_tiles, use_conn=False, use_ratio=False, top_variance_feat=0, reduction=2)\n",
    "    complete_df_clr, additional_complete_df_clr, frame_clusters, frame_samples, features = all_data\n",
    "complete_df_clr.columns = complete_df_clr.columns.astype(str)\n",
    "\n",
    "# Read tile vector representations.\n",
    "folds = load_existing_split(folds_pickle)\n",
    "fold = folds[fold_number]\n",
    "dataframes, complete_df, leiden_clusters = read_csvs(adatas_path, matching_field, groupby, fold_number, fold, h5_complete_path, h5_additional_path, additional_as_fold=False, force_fold=fold_number)\n",
    "\n",
    "mapping_pancan = complete_df[[meta_field, 'patterns']].drop_duplicates().reset_index()\n",
    "mapping_pancan[meta_field] = mapping_pancan[meta_field].astype(int)\n",
    "mapping_dict = dict()\n",
    "remapping_dict = dict()\n",
    "for i in range(mapping_pancan.shape[0]):\n",
    "    mapping_dict[mapping_pancan.loc[i,'labels']]     = mapping_pancan.loc[i,'patterns']\n",
    "    remapping_dict[mapping_pancan.loc[i,'patterns']] = mapping_pancan.loc[i,'labels']\n",
    "\n",
    "# Visualize sample size per cancer type.\n",
    "data_vis = list()\n",
    "for lab, count in zip(*np.unique(complete_df_clr[1:][meta_field], return_counts=True)):\n",
    "    data_vis.append((lab,count))\n",
    "data_vis = pd.DataFrame(data_vis, columns=['Cancer Type', 'Sample Size'])\n",
    "data_vis['Cancer Type'] = data_vis['Cancer Type'].replace(mapping_dict)\n",
    "sns.set_theme(style='white')\n",
    "sns.barplot(data=data_vis, x='Cancer Type', y='Sample Size')\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "data_vis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Survival Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "event_ind_field  = 'os_event_ind'\n",
    "event_data_field = 'os_event_data'\n",
    "\n",
    "cancer_types = np.unique(data_vis['Cancer Type'].values.astype(str)).tolist()\n",
    "\n",
    "# Pan-cancer survival data.\n",
    "all_surv_df = list()\n",
    "for cancer_type in cancer_types:\n",
    "    if 'PRAD'==cancer_type: continue\n",
    "    survival_csv = '%s/utilities/files/%s/overall_survival_TCGA_folds.csv' % (main_path, cancer_type)\n",
    "    survival_df  = pd.read_csv(survival_csv)\n",
    "    survival_df['Cancer Type'] = cancer_type\n",
    "    all_surv_df.append(survival_df)\n",
    "all_surv_df = pd.concat(all_surv_df, axis=0)\n",
    "# Merge survival data with representations.\n",
    "complete_surv_df  = complete_df_clr.merge(all_surv_df, how='inner', on='samples')\n",
    "\n",
    "# Read 5-fold cross-validation.\n",
    "folds_dict = OrderedDict()\n",
    "for cancer_type in cancer_types:\n",
    "    if 'PRAD'==cancer_type: continue\n",
    "    survival_pkl = '%s/utilities/files/%s/overall_survival_TCGA_folds.pkl' % (main_path, cancer_type)\n",
    "    if os.path.isfile(survival_pkl):\n",
    "        folds = load_existing_split(survival_pkl)\n",
    "        folds_dict[cancer_type] = folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Immune Lanscape Signatures - Spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_field        = 'labels'\n",
    "matching_field    = 'samples'\n",
    "corr_method      = 'spearman'\n",
    "method_comb_pval = 'fisher'\n",
    "type_integration = 'mean'\n",
    "pval_th          = 0.01\n",
    "th_corr          = 0\n",
    "remove_nan       = True\n",
    "\n",
    "# All Pan-Cancer combinations.\n",
    "corr_dict, data_all, labels_allann, labels_unique = correlations_across_types(complete_surv_df[[matching_field, meta_field]+leiden_clusters.astype(str).tolist()], immune_landscape_df, meta_field, groupby, fold_number, pval_th,\n",
    "                                                                              matching_field=matching_field, corr_method=corr_method, method_comb_pval=method_comb_pval,\n",
    "                                                                              type_integration=type_integration, th_corr=th_corr, remove_nan=remove_nan,\n",
    "                                                                              directory=correlations_path, file_name=file_name)\n",
    "data_all['Cancer Type'] = data_all['Cancer Type'].astype(int).replace(mapping_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure detail parameters.\n",
    "cellSizePixels_x  = 105\n",
    "cellSizePixels_y  = 110\n",
    "dendrogram_ratio  = (0.05, 0.2)\n",
    "fontsize_ticks    = 60\n",
    "fontsize_labels   = 70\n",
    "fontsize_annot    = 45\n",
    "p_th              = 0.05\n",
    "linewidths        = 7\n",
    "\n",
    "x_label = 'Histomorphological Phenotype Cluster (HPC)'\n",
    "\n",
    "# Cancer-Type Blind Results.\n",
    "# g = fixedWidthClusterMap(dataFrame=corr_dict['blind'][0], mask=corr_dict['blind'][-1].values, x_label=x_label, y_label='Immune feature', p_th=p_th, fmt='.1f',\n",
    "                        #  fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                        #  cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=0.2, linewidths=linewidths)\n",
    "# immune_linkage_clr = copy.deepcopy(g.dendrogram_col.linkage)\n",
    "\n",
    "# Per Cancer-Type Results.\n",
    "keep_th = int(len(leiden_clusters)*0.4)\n",
    "data_corr, mask_corr = keep_features_min_corr(mask=corr_dict['all'][-1], data=corr_dict['all'][0], keep_th=keep_th)\n",
    "g = fixedWidthClusterMap(dataFrame=data_corr, mask=mask_corr, x_label=x_label, y_label='Immune feature', \n",
    "                        cox_os_clusters=None, cox_pfs_clusters=None, immune_hot_clusters=None, p_th=p_th, fmt='.1f', \n",
    "                        fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, \n",
    "                        dendrogram_ratio=dendrogram_ratio, cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, \n",
    "                        offset_col_color=0, resize_col_den=0.5, linewidths=linewidths, row_cluster=True, col_cluster=True)\n",
    "                        # col_linkage=immune_linkage_clr_all)\n",
    "immune_linkage_clr_all = copy.deepcopy(g.dendrogram_col.linkage)\n",
    "plt.show()\n",
    "\n",
    "file_path = os.path.join(correlations_path, file_name + '_immune_all_dendrogram.pkl')\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(immune_linkage_clr_all, file)\n",
    "\n",
    "\n",
    "# Figure 10 Immune signatures.\n",
    "ann_to_display = ['TIL Regional Fraction', 'Lymphocyte Infiltration Signature Score', 'Leukocyte Fraction', 'Stromal Fraction', 'Macrophage Regulation',\n",
    "                  'Proliferation', 'Wound Healing', 'IFN-gamma Response', 'TGF-beta Response', 'T Cells CD8']\n",
    "# Figure 8 Immune signatures.\n",
    "ann_to_display = ['TIL Regional Fraction', 'Leukocyte Fraction', 'Stromal Fraction', 'Macrophage Regulation',\n",
    "                  'Proliferation', 'Wound Healing', 'IFN-gamma Response', 'TGF-beta Response']\n",
    "\n",
    "# Figure 4 Immune signatures.\n",
    "ann_to_display = ['TIL Regional Fraction', 'Macrophage Regulation', 'Proliferation', 'TGF-beta Response']\n",
    "\n",
    "cancer_mix           = 'all'\n",
    "data_plot            = data_all[data_all['Type']==cancer_mix]\n",
    "data_plot_ann        = data_plot[data_plot['Immune Signature'].isin(ann_to_display)]\n",
    "data_plot_ann['HPC'] = data_plot_ann['HPC'].astype(str)\n",
    "data_plot_ann        = data_plot_ann.sort_values(by=['Rho Combined', 'Sample Size'], ascending=False)\n",
    "\n",
    "p = relplot_figure(data=data_plot_ann, y='Rho', x='HPC', hue='Cancer Type', col_wrap=2, col='Immune Signature', col_order=ann_to_display, size='Sample Size', pval_th=pval_th,\n",
    "                   sizes=(30, 150), height=3, aspect=3.5, facet_kws={'sharex': False, 'sharey': True})\n",
    "\n",
    "legend_colors = dict()\n",
    "for i, handle in enumerate(p._legend.legendHandles):\n",
    "    text = handle._label\n",
    "    if text not in np.unique(data_plot_ann['Cancer Type']): continue\n",
    "    legend_colors[text]= handle._hatch_color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# C-Index per HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hpc, matching_field, event_ind_field, event_data_field, dataframe, fold, model, use_fold=True, penalizer=0.0, l1_ratio=0.0):\n",
    "    train_set, valid_set, test_set = fold\n",
    "\n",
    "    train_df = dataframe[dataframe[matching_field].isin(train_set)]\n",
    "    test_df  = dataframe[dataframe[matching_field].isin(test_set)]\n",
    "    coef     = 1\n",
    "    if model=='cox':\n",
    "        cph = CoxPHFitter(penalizer=penalizer, l1_ratio=l1_ratio)\n",
    "        if not use_fold:\n",
    "            cph.fit(dataframe[[event_ind_field,event_data_field, str(hpc)]], duration_col=event_data_field, event_col=event_ind_field, show_progress=False, robust=True)\n",
    "            dataframe.insert(loc=0, column='hazard', value=cph.predict_partial_hazard(dataframe[[event_ind_field,event_data_field, str(hpc)]]))\n",
    "            median_cutoff = dataframe['hazard'].median()\n",
    "            frame_return = dataframe\n",
    "            coef = cph.summary['coef'].values[0]\n",
    "        else:\n",
    "            cph.fit(train_df[[event_ind_field,event_data_field, str(hpc)]], duration_col=event_data_field, event_col=event_ind_field, show_progress=False, robust=True)\n",
    "            train_df.insert(loc=0, column='hazard', value=cph.predict_partial_hazard(train_df[[event_ind_field,event_data_field, str(hpc)]]))\n",
    "            test_df.insert(loc=0,  column='hazard', value=cph.predict_partial_hazard(test_df[[event_ind_field,event_data_field, str(hpc)]]))\n",
    "            median_cutoff = train_df['hazard'].median()\n",
    "            frame_return = test_df\n",
    "            coef = cph.summary['coef'].values[0]\n",
    "    elif model=='hpc':\n",
    "        if not use_fold:\n",
    "            dataframe.insert(loc=0, column='hazard', value=dataframe[str(hpc)].values)\n",
    "            median_cutoff = dataframe['hazard'].median()\n",
    "            frame_return = dataframe\n",
    "        else:\n",
    "            train_df.insert(loc=0, column='hazard', value=train_df[str(hpc)].values)\n",
    "            test_df.insert(loc=0,  column='hazard', value=test_df[str(hpc)].values)\n",
    "            median_cutoff = train_df['hazard'].median()\n",
    "            frame_return = test_df\n",
    "    else:\n",
    "        print('Not contemplated option', model)\n",
    "        return\n",
    "\n",
    "    return frame_return, median_cutoff, coef\n",
    "    \n",
    "def evaluation_and_riskgroups(evaluation_df, median_cutoff, risk_groups, event_data_field, event_ind_field):\n",
    "    c_index    = np.round(concordance_index_censored(evaluation_df[event_ind_field]==1.0, evaluation_df[event_data_field], evaluation_df['hazard'])[0], 3)\n",
    "    high_risk = evaluation_df[evaluation_df['hazard'].values>median_cutoff]\n",
    "    low_risk  = evaluation_df[evaluation_df['hazard'].values<=median_cutoff]\n",
    "    risk_groups[1] = risk_groups[1].append(high_risk, ignore_index=True)\n",
    "    risk_groups[0] = risk_groups[0].append(low_risk, ignore_index=True)\n",
    "    return c_index, risk_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fold = True\n",
    "model    = 'hpc'\n",
    "\n",
    "ci_data       = list()\n",
    "c_indexes_u   = list()\n",
    "c_indexes_ci  = list()\n",
    "p_values      = list()\n",
    "coefs_u       = list()\n",
    "coefs_ci      = list()\n",
    "for cancer_type in folds_dict:\n",
    "    cancer_cindexes_u   = list()\n",
    "    cancer_cindexes_ci  = list()\n",
    "    cancer_pvalues      = list()\n",
    "    cancer_coef_u       = list()\n",
    "    cancer_coef_ci      = list()\n",
    "    folds_type          = folds_dict[cancer_type]\n",
    "    for hpc in leiden_clusters:\n",
    "        subset_df  = complete_surv_df[complete_surv_df['Cancer Type']==cancer_type]\n",
    "        subset_df  = subset_df[[matching_field, str(hpc), event_ind_field, event_data_field]]\n",
    "        \n",
    "        folds_cindex         = list()\n",
    "        folds_coef           = list()\n",
    "        risk_groups          = [pd.DataFrame(), pd.DataFrame()]\n",
    "        for i, fold in enumerate(folds_type):\n",
    "            evaluation_df, median_cutoff, coef = train_model(hpc, matching_field, event_ind_field, event_data_field, subset_df, fold, model, use_fold=use_fold, penalizer=10.0, l1_ratio=0.0)\n",
    "            c_index, risk_groups = evaluation_and_riskgroups(evaluation_df, median_cutoff, risk_groups, event_data_field, event_ind_field)\n",
    "            folds_cindex.append(c_index)\n",
    "            folds_coef.append(coef)\n",
    "            if not use_fold:\n",
    "                break\n",
    "            \n",
    "        # calculate split and p-value.\n",
    "        c_index_u  = np.round(np.mean(folds_cindex),3)\n",
    "        mean, minus, plus = mean_confidence_interval(folds_cindex, confidence=0.95)\n",
    "        c_index_ci = np.round(plus-mean,3)\n",
    "\n",
    "        coef_u     = np.round(np.mean(folds_coef),3)\n",
    "        c_mean, c_minus, c_plus = mean_confidence_interval(folds_cindex, confidence=0.95)\n",
    "        coef_ci    = np.round(c_plus-c_mean,3)\n",
    "        \n",
    "        high_risk = risk_groups[1]\n",
    "        low_risk  = risk_groups[0]\n",
    "        p_value   = np.round(logrank_test(high_risk[event_data_field].astype(float), low_risk[event_data_field].astype(float), event_observed_A=high_risk[event_ind_field].astype(float), event_observed_B=low_risk[event_ind_field].astype(float)).p_value, 3)\n",
    "        ci_data.append((cancer_type, hpc, c_index_u, c_index_ci, p_value))\n",
    "        cancer_cindexes_u.append(c_index_u)\n",
    "        cancer_cindexes_ci.append(c_index_ci)\n",
    "        cancer_pvalues.append(p_value)\n",
    "        cancer_coef_u.append(coef_u)\n",
    "        cancer_coef_ci.append(coef_ci)\n",
    "    c_indexes_u.append(cancer_cindexes_u)\n",
    "    c_indexes_ci.append(cancer_cindexes_ci)\n",
    "    p_values.append(cancer_pvalues)\n",
    "    coefs_u.append(cancer_coef_u)\n",
    "    coefs_ci.append(cancer_coef_ci)\n",
    "\n",
    "# P Value for visualization.\n",
    "ci_data = pd.DataFrame(ci_data, columns=['Cancer Type', 'HPC', 'C-Index Mean', 'C-Index 95CI', 'P-Value'])\n",
    "ci_data['P-Value-Minus'] = -ci_data['P-Value'].values\n",
    "\n",
    "# DataFrames for clusterplot.\n",
    "c_indexes_u = pd.DataFrame(c_indexes_u, columns=leiden_clusters)\n",
    "c_indexes_u.index = folds_dict.keys()\n",
    "c_indexes_ci = pd.DataFrame(c_indexes_ci, columns=leiden_clusters)\n",
    "c_indexes_ci.index = folds_dict.keys()\n",
    "\n",
    "p_values = pd.DataFrame(p_values, columns=leiden_clusters)\n",
    "p_values.index = folds_dict.keys()\n",
    "\n",
    "coefs_u = pd.DataFrame(coefs_u, columns=leiden_clusters)\n",
    "coefs_u.index = folds_dict.keys()\n",
    "coefs_ci = pd.DataFrame(coefs_ci, columns=leiden_clusters)\n",
    "coefs_ci.index = folds_dict.keys()\n",
    "\n",
    "\n",
    "if use_fold:\n",
    "    name_fold = '5fold'\n",
    "else:\n",
    "    name_fold = 'Nofold'\n",
    "\n",
    "run_name = '%s_%s' % (model, name_fold)\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_label = 'Histomorphological Phenotype Cluster (HPC)'\n",
    "y_label = 'Cancer Type'\n",
    "cellSizePixels_x  = 130\n",
    "cellSizePixels_y  = 110\n",
    "dendrogram_ratio  = (0.05, 0.2)\n",
    "fontsize_ticks    = 60\n",
    "fontsize_labels   = 70\n",
    "fontsize_annot    = 45\n",
    "linewidths        = 7\n",
    "\n",
    "p_th = 0.05\n",
    "c_i  = 0.50\n",
    "c_indexes_vis = c_indexes_u\n",
    "p_values_vis  = p_values\n",
    "mask_vis      = p_values_vis > p_th\n",
    "g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                         fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                         cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths, \n",
    "                         row_cluster=False, col_cluster=False)\n",
    "figure_name = '%s_mean_nolinkage.png' % run_name\n",
    "print(figure_name)\n",
    "plt.show()\n",
    "\n",
    "if use_fold:\n",
    "    c_i  = 0.0\n",
    "    c_indexes_vis = c_indexes_ci\n",
    "    g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                            fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                            cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths,\n",
    "                            row_cluster=False, col_cluster=False)\n",
    "    figure_name = '%s_ci_nolinkage.png' % run_name\n",
    "    print(figure_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = 'Histomorphological Phenotype Cluster (HPC)'\n",
    "y_label = 'Cancer Type'\n",
    "cellSizePixels_x  = 130\n",
    "cellSizePixels_y  = 110\n",
    "dendrogram_ratio  = (0.05, 0.2)\n",
    "fontsize_ticks    = 60\n",
    "fontsize_labels   = 70\n",
    "fontsize_annot    = 45\n",
    "linewidths        = 7\n",
    "\n",
    "p_th = 0.05\n",
    "c_i  = 0.50\n",
    "c_indexes_vis = c_indexes_u\n",
    "p_values_vis  = p_values\n",
    "mask_vis      = p_values_vis > p_th\n",
    "g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                         fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                         cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths, \n",
    "                         row_cluster=True, col_cluster=True)\n",
    "col_dendrogram = g.dendrogram_col.linkage\n",
    "row_dendrogram = g.dendrogram_row .linkage\n",
    "figure_name = '%s_mean.png' % run_name\n",
    "print(figure_name)\n",
    "plt.show()\n",
    "\n",
    "if use_fold:\n",
    "    c_i  = 0.0\n",
    "    c_indexes_vis = c_indexes_ci\n",
    "    g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                            fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                            cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths,\n",
    "                            col_linkage=col_dendrogram, row_linkage=row_dendrogram, row_cluster=True, col_cluster=True)\n",
    "    figure_name = '%s_ci.png' % run_name\n",
    "    print(figure_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_th = 0.05\n",
    "c_i  = 0.50\n",
    "c_indexes_vis = c_indexes_u\n",
    "p_values_vis  = p_values\n",
    "mask_vis      = p_values_vis > p_th\n",
    "g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                         fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                         cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths,\n",
    "                         col_linkage=immune_linkage_clr_all)\n",
    "row_dendrogram = g.dendrogram_row .linkage\n",
    "figure_name = '%s_mean_x_immune.png' % run_name\n",
    "print(figure_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure detail parameters.\n",
    "x_label = 'Histomorphological Phenotype Cluster (HPC)'\n",
    "y_label = 'Cancer Type'\n",
    "cellSizePixels_x  = 130\n",
    "cellSizePixels_y  = 110\n",
    "dendrogram_ratio  = (0.05, 0.2)\n",
    "fontsize_ticks    = 80\n",
    "fontsize_labels   = 90\n",
    "fontsize_annot    = 45\n",
    "linewidths        = 7\n",
    "\n",
    "\n",
    "p_th = 0.05\n",
    "c_i  = 0.50\n",
    "c_indexes_vis = c_indexes_u\n",
    "p_values_vis  = p_values\n",
    "mask_vis      = p_values_vis > p_th\n",
    "g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                         fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                         cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths,\n",
    "                         col_linkage=immune_linkage_clr_all)\n",
    "row_dendrogram = g.dendrogram_row .linkage\n",
    "figure_name = '%s_mean_x_immune.png' % run_name\n",
    "print(figure_name)\n",
    "plt.show()\n",
    "\n",
    "if use_fold:\n",
    "    p_th = 0.05\n",
    "    c_i  = 0.0\n",
    "    c_indexes_vis = c_indexes_ci\n",
    "    g = fixedWidthClusterMap(dataFrame=c_indexes_vis, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                            fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                            cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.4, linewidths=linewidths,\n",
    "                            col_linkage=immune_linkage_clr_all, row_linkage=row_dendrogram)\n",
    "    figure_name = '%s_ci_x_immune.png' % run_name\n",
    "    print(figure_name)\n",
    "    plt.show()\n",
    "\n",
    "if model=='cox':\n",
    "    coef_i = 0.0\n",
    "    g = fixedWidthClusterMap(dataFrame=coefs_u, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.3f', vcenter=coef_i,\n",
    "                         fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                         cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=1.3, linewidths=linewidths,\n",
    "                         col_linkage=immune_linkage_clr_all, row_linkage=row_dendrogram)\n",
    "    figure_name = '%s_coef_mean_x_immune.png' % run_name\n",
    "    print(figure_name)\n",
    "    plt.show()\n",
    "\n",
    "    if use_fold:\n",
    "        p_th = 0.05\n",
    "        c_i  = 0.0\n",
    "        g = fixedWidthClusterMap(dataFrame=coefs_ci, mask=mask_vis, x_label=x_label, y_label=y_label, p_th=p_th, fmt='.2f', vcenter=c_i,\n",
    "                                fontsize_ticks=fontsize_ticks, fontsize_labels=fontsize_labels, fontsize_annot=fontsize_annot, dendrogram_ratio=dendrogram_ratio,\n",
    "                                cellSizePixels_x=cellSizePixels_x, cellSizePixels_y=cellSizePixels_y, offset_col_color=0, resize_col_den=2., linewidths=linewidths,\n",
    "                                col_linkage=immune_linkage_clr_all, row_linkage=row_dendrogram)\n",
    "        figure_name = '%s_coef_ci_x_immune.png' % run_name\n",
    "        print(figure_name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_subsample_legend(size_field, handles, labels, number_hue=5, number_size=10):\n",
    "    def get_subsample_ind(indexes, number=5):\n",
    "        ind = int(np.ceil((len(indexes)/(number-1))))\n",
    "        indexes_sub = indexes[::ind]\n",
    "        if len(indexes_sub) != 5 and indexes_sub[-1]!=indexes[-1]:\n",
    "            indexes_sub.append(indexes[-1])\n",
    "        elif len(indexes_sub) == 5 and indexes_sub[-1]!=indexes[-1]:\n",
    "            indexes_sub[-1] = indexes[-1]\n",
    "        return indexes_sub\n",
    "\n",
    "    # Get end and start of hue and size.\n",
    "    end_hue = np.argwhere(np.array(labels)==size_field)[0,0]-1\n",
    "    start_size = end_hue + 2\n",
    "    # List of indexes.\n",
    "    hue_idx  = list(range(1,end_hue+1,1))\n",
    "    size_idx = list(range(start_size,len(labels),1))\n",
    "    # Get a subset of indexes.\n",
    "    hue_sub  = [0] + get_subsample_ind(hue_idx, number=number_hue)\n",
    "    size_sub = [start_size-1] + get_subsample_ind(size_idx, number=number_size)\n",
    "\n",
    "    # final set of handles and labels\n",
    "    size_label_sub = [labels[size_sub[0]].split('-Minus')[0]] + [label[1:] for label in np.array(labels)[size_sub[1:]].tolist()]\n",
    "    labels_sub  = np.array(labels)[hue_sub].tolist() + size_label_sub\n",
    "    handles_sub = [handles[ind] for ind in hue_sub+size_sub]\n",
    "\n",
    "    if float(labels_sub[-1]) == 0.0:\n",
    "        labels_sub.pop()\n",
    "        handles_sub.pop()\n",
    "\n",
    "    return handles_sub, labels_sub\n",
    "\n",
    "cmap = sns.diverging_palette(250, 20, as_cmap=True)\n",
    "\n",
    "hue  = 'C-Index Mean'\n",
    "size = 'P-Value-Minus'\n",
    "p_th = 0.05\n",
    "c_i  = 0.50\n",
    "\n",
    "ci_data_vis = ci_data\n",
    "\n",
    "hue_norm  = TwoSlopeNorm(vmin=ci_data_vis[hue].min(),  vcenter=c_i,   vmax=ci_data_vis[hue].max())\n",
    "size_norm = TwoSlopeNorm(vmin=ci_data_vis[size].min(), vcenter=-p_th, vmax=ci_data_vis[size].max())\n",
    "\n",
    "fig = plt.figure(figsize=(40,10))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "grid = sns.scatterplot(data=ci_data_vis, y='Cancer Type', x='HPC', size=size, hue=hue, hue_norm=hue_norm, size_norm=size_norm, palette=cmap, sizes=(10, 200), ax=ax, legend='full')\n",
    "ax.set_xticks(leiden_clusters, labels=leiden_clusters)\n",
    "handles, labels = grid._axes.get_legend_handles_labels()\n",
    "handles_sub, labels_sub = get_subsample_legend(size_field=size, handles=handles, labels=labels, number_hue=10, number_size=15)\n",
    "grid.legend_.remove()\n",
    "legend = plt.legend(handles_sub,labels_sub, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontweight('bold')\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontweight('bold')\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "ax.xaxis.get_label().set_fontweight('bold')\n",
    "ax.yaxis.get_label().set_fontweight('bold')\n",
    "\n",
    "legend.get_title().set_weight('bold')\n",
    "[leg_text.set_weight('bold') for leg_text in legend.get_texts()]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPCs Generalization Patients & Institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all data.\n",
    "tiles_df = pd.concat([dataframes[0], dataframes[1], dataframes[2]])\n",
    "tiles_df['samples']  = tiles_df['slides'].apply(lambda x: '-'.join(x.split('-')[:3]))\n",
    "tiles_df['TSS Code'] = tiles_df['samples'].apply(lambda x: x.split('-')[1]).values.astype(str)\n",
    "\n",
    "# Include counts per samples and HPC\n",
    "for name, field in [('sample',matching_field), ('hpc', groupby)]:\n",
    "    counts_per_field = tiles_df.groupby(field).count()\n",
    "    counts_per_field = counts_per_field.reset_index()\n",
    "    counts_per_field = counts_per_field.rename(columns={'tiles':'nt_per_%s'%name})\n",
    "    tiles_df = tiles_df.merge(counts_per_field[[field, 'nt_per_%s'%name]], on=field)\n",
    "\n",
    "# Normalized values of percentage of total tiles in HPC\n",
    "tiles_df.insert(loc=len(tiles_df.columns), column='nt_per_hpc_norm', value=tiles_df['nt_per_hpc'].values/tiles_df.shape[0])\n",
    "\n",
    "# Normalize contribution of HPC in patient.\n",
    "hpc_pat = tiles_df[[matching_field, groupby, 'tiles']].groupby([matching_field, groupby]).count()\n",
    "hpc_pat = hpc_pat.reset_index()\n",
    "hpc_pat = hpc_pat.rename(columns={'tiles':'nt_per_sample_hpc'})\n",
    "hpc_pat = hpc_pat.merge(tiles_df[[matching_field, 'nt_per_sample']].drop_duplicates(), on=matching_field)\n",
    "hpc_pat = hpc_pat.drop_duplicates()\n",
    "hpc_pat['nt_per_sample_hpc_norm'] = np.divide(hpc_pat['nt_per_sample_hpc'].values.astype(float), hpc_pat['nt_per_sample'].values.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Median and Mean.\n",
    "fig = plt.figure(figsize=(40,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "sns.pointplot(data=hpc_pat, x=groupby, y='nt_per_sample_hpc_norm', ci=99.9, join=False, color='blue', scale=1.5, markers='s', ax=ax)\n",
    "sns.pointplot(data=hpc_pat, x=groupby, y='nt_per_sample_hpc_norm', estimator=np.median, ci=99.9, join=False, color='red', scale=1.5, markers='s', ax=ax)\n",
    "ax.set_title('Mean and 95 Confidence Interval for all patients\\npercetage of total tissue area per patient')\n",
    "ax.axhline(1/len(leiden_clusters))\n",
    "ax.axhline(0.02)\n",
    "plt.show()\n",
    "\n",
    "# Distribution of percentage of HPC per patient.\n",
    "fig = plt.figure(figsize=(30,15))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "sns.violinplot(data=hpc_pat, x=groupby, y='nt_per_sample_hpc_norm', scale='count', ax=ax)\n",
    "ax.set_title('Distribution of percetage of total tissue area per patient')\n",
    "ax.set_ylim([-0.05,0.6])\n",
    "ax = fig.add_subplot(2, 1, 2)\n",
    "sns.boxplot(data=hpc_pat, x=groupby, y='nt_per_sample_hpc_norm', fliersize=2, whis=1., flierprops={\"marker\": \"x\"}, ax=ax)\n",
    "ax.set_title('Distribution of percetage of total tissue area per patient')\n",
    "ax.set_ylim([-0.05,0.6])\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "pal = sns.cubehelix_palette(len(leiden_clusters), rot=-.25, light=.7)\n",
    "for hpc in reversed(leiden_clusters):\n",
    "    sns.kdeplot(hpc_pat[hpc_pat[groupby]==hpc]['nt_per_sample_hpc_norm'].values, ax=ax, cut=0, color=pal[hpc])\n",
    "    ax.axvline(np.median(hpc_pat[hpc_pat[groupby]==hpc]['nt_per_sample_hpc_norm'].values))\n",
    "ax.axvline(1/len(leiden_clusters), color='black')\n",
    "ax.axvline(0, color='black')\n",
    "ax.set_xlim([-.005,0.175])\n",
    "ax.set_xlim([-.005,0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.01\n",
    "hpc_pat_th = hpc_pat[hpc_pat.nt_per_sample_hpc_norm >= threshold]\n",
    "hpc_pat_th = hpc_pat_th.groupby([groupby]).count()['samples']/len(np.unique(hpc_pat[matching_field]))\n",
    "hpc_pat_th = hpc_pat_th.reset_index()\n",
    "hpc_pat_th = hpc_pat_th.rename(columns={groupby:'HPC'})\n",
    "\n",
    "plot_institution_distribution(hpc_pat_th, field='samples', title='Percentage of total patients\\npresent in the HPC', figsize=(30,7), fontsize_labels=22, fontsize_legend=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiles_df = pd.concat([dataframes[0], dataframes[1], dataframes[2]])\n",
    "tiles_df['TSS Code'] = tiles_df['samples'].apply(lambda x: x.split('-')[1]).values.astype(str)\n",
    "tss_hpc = tiles_df[['TSS Code', 'tiles']].groupby('TSS Code').count()\n",
    "tss_hpc = tss_hpc.reset_index()\n",
    "tss_hpc = tss_hpc.rename(columns={'tiles':'total_tiles'})\n",
    "\n",
    "data_hpc_inst = list()\n",
    "total_institutions = np.unique(tiles_df['TSS Code'].values)\n",
    "total_patients     = np.unique(tiles_df[matching_field].values)\n",
    "for hpc in np.unique(tiles_df[groupby]):\n",
    "    hpc_df    = tiles_df[tiles_df[groupby]==hpc]\n",
    "    patients  = np.unique(hpc_df[matching_field].values)\n",
    "    hpc_df    = hpc_df.groupby('TSS Code').count()\n",
    "    hpc_df    = hpc_df.reset_index()[['TSS Code', 'tiles']]\n",
    "    hpc_df    = hpc_df.merge(tss_hpc, on='TSS Code', how='inner')\n",
    "    hpc_df.insert(len(hpc_df.columns), 'tiles_norm', np.divide(hpc_df['tiles'].values,hpc_df['total_tiles'].values))\n",
    "    hpc_df    = hpc_df[hpc_df['tiles_norm']>=threshold]\n",
    "    data_hpc_inst.append((hpc, hpc_df.shape[0]/tss_hpc.shape[0], len(patients)/len(total_patients)))\n",
    "data_hpc_inst = pd.DataFrame(data_hpc_inst, columns=['HPC', 'Percentage of Institutions in HPC', 'Percentage of All Patients in HPC'])\n",
    "\n",
    "plot_institution_distribution(data_hpc_inst, field='Percentage of Institutions in HPC', title='Percentage of total institutions\\npresent in the HPC', figsize=(30,7), fontsize_labels=22, fontsize_legend=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_institution_distribution_ax(data_hpc_inst, field, title, ax, fontsize_labels=22, fontsize_legend=20, show_max_min=False):\n",
    "    def colors_from_values(values, palette_name, normalize=False):\n",
    "        # normalize the values to range [0, 1]\n",
    "        if normalize:\n",
    "            normalized = (values - min(values)) / (max(values) - min(values))\n",
    "        else:\n",
    "            normalized = values\n",
    "        # convert to indices\n",
    "        indices = np.round(normalized * (len(values) - 1)).astype(np.int32)\n",
    "        # use the indices to get the colors\n",
    "        palette = sns.color_palette(palette_name, int(1.5*len(values)))\n",
    "        return np.array(palette).take(indices, axis=0)\n",
    "\n",
    "    y = data_hpc_inst[field].values\n",
    "    sns.barplot(data=data_hpc_inst, x='HPC', y=field, palette=colors_from_values(y, \"Greens_d\"), ax=ax)\n",
    "\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.set_ylim([0.0,1.0])\n",
    "    yticks = (np.array(range(0,11,1))/10).tolist()\n",
    "    ax.set_yticks(yticks, yticks)\n",
    "\n",
    "    ax.set_title(title,  fontsize=fontsize_labels*1.3, fontweight='bold')\n",
    "    ax.set_xlabel('\\nHistomorphological Phenotype Cluster (HPC)', fontsize=fontsize_labels,     fontweight='bold')\n",
    "    ax.set_ylabel(' ', fontsize=fontsize_labels, fontweight='bold')\n",
    "    if show_max_min:\n",
    "        max_val = np.max(data_hpc_inst[field].values)\n",
    "        min_val = np.min(data_hpc_inst[field].values)\n",
    "        ax.axhline(max_val, linestyle='--')\n",
    "        ax.axhline(min_val, linestyle='--')\n",
    "    ax.axhline(0.50, linestyle='--', color='black')\n",
    "    ax.axhline(0.25, linestyle='--', color='black')\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(4)\n",
    "    \n",
    "number_res = 7\n",
    "fig   = plt.figure(figsize=(30,7*number_res))\n",
    "for i in range(number_res):\n",
    "    ax    = fig.add_subplot(number_res, 1, i+1)\n",
    "    plot_institution_distribution_ax(data_hpc_inst, field='Percentage of Institutions in HPC', title='Percentage of total institutions\\npresent in the HPC', ax=ax, fontsize_labels=22, fontsize_legend=20)\n",
    "plt.tight_layout()\n",
    "print(main_cluster_path)\n",
    "plt.savefig(os.path.join(main_cluster_path, 'cluster_evalutation_institution_distribution.jpg'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cluster Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "if os.path.isfile(h5ad_path.replace('.h5ad', '_paga.h5ad')):\n",
    "    done=True\n",
    "    adata_train = anndata.read_h5ad(h5ad_path.replace('.h5ad', '_paga.h5ad'))\n",
    "else:\n",
    "    sc.tl.paga(adata_train, groups=groupby, neighbors_key='nn_leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Graph visualization related\n",
    "# This next variable can be modified so it more clearly shows the cluster network\n",
    "# Layout corresponds to the technique for the cluster network layout.\n",
    "# Threshold corresponds to threshold for the edge connection between nodes, higher values keep only stronger bonds.\n",
    "layout           = 'fa'  # fa, fr, rt, rt_circular, drl, eq_tree\n",
    "random_state     = 3\n",
    "threshold        = 0.75\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 5\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .01\n",
    "fontsize         = 10\n",
    "fontoutline      = 2\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "fig = plt.figure(figsize=(100,10))\n",
    "ax  = fig.add_subplot(1, 3, 1)\n",
    "sc.pl.paga(adata_train, layout=layout, random_state=random_state, color=meta_field, threshold=threshold, node_size_scale=node_size_scale, node_size_power=node_size_power,\n",
    "           edge_width_scale=edge_width_scale, fontsize=fontsize, fontoutline=fontoutline, frameon=False, show=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# UMAP - PAGA Leiden based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not done:\n",
    "    sc.tl.umap(adata_train, init_pos=\"paga\", neighbors_key='nn_leiden')\n",
    "    adata_train.write(h5ad_path.replace('.h5ad', '_paga.h5ad'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "meta_field        = 'labels'\n",
    "matching_field    = 'samples'\n",
    "corr_method      = 'spearman'\n",
    "method_comb_pval = 'fisher'\n",
    "type_integration = 'mean'\n",
    "pval_th          = 0.01\n",
    "th_corr          = 0\n",
    "remove_nan       = True\n",
    "\n",
    "# Remove cancer types.\n",
    "data_frame_to_use = complete_df_clr.copy(deep=True)\n",
    "\n",
    "# All Pan-Cancer subset.\n",
    "corr_dict, data_all, labels_allann, labels_unique = correlations_across_types(data_frame_to_use, immune_landscape_df, meta_field, groupby, fold_number, pval_th,\n",
    "                                                                              matching_field=matching_field, corr_method=corr_method, method_comb_pval=method_comb_pval,\n",
    "                                                                              type_integration=type_integration, th_corr=th_corr, remove_nan=remove_nan,\n",
    "                                                                              directory=correlations_path, file_name=file_name)\n",
    "data_all['Cancer Type'] = data_all['Cancer Type'].astype(int).replace(mapping_dict)\n",
    "\n",
    "all_data_rho_clr = corr_dict['all'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_umap_annotations(ax1):\n",
    "    # HPC 20\n",
    "    old_x = ax1.texts[20]._x\n",
    "    ax1.texts[20]._x = old_x*1.03\n",
    "\n",
    "    # HPC 17\n",
    "    old_y = ax1.texts[17]._y\n",
    "    ax1.texts[17]._y = old_y*1.8\n",
    "    # HPC 30\n",
    "    old_y = ax1.texts[30]._y\n",
    "    ax1.texts[30]._y = old_y*0.2\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax1  = fig.add_subplot(1, 1, 1)\n",
    "colors = sns.color_palette('tab20', len(np.unique(adata_train.obs[groupby].values)))\n",
    "ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='on data', frameon=False, show=False, ax=ax1, color=groupby, palette=colors, size=marker_size)\n",
    "ax1.set_title('')\n",
    "\n",
    "fix_umap_annotations(ax1=ax1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_1 = 'TIL Regional Fraction'\n",
    "feature_2 = 'Proliferation'\n",
    "feature_3 = 'TGF-beta Response'\n",
    "\n",
    "# feature_1 = 'Macrophage Regulation'\n",
    "# feature_2 = 'Wound Healing'\n",
    "# feature_3 = 'Stromal Fraction'\n",
    "\n",
    "adata_train.obs['Cancer Type'] = adata_train.obs['labels'].astype(float).replace(mapping_dict).values\n",
    "adata_train.obs['samples']     = adata_train.obs['slides'].apply(lambda x: '-'.join(x.split('-')[:3]))\n",
    "adata_train.obs['TSS Code']    = adata_train.obs['samples'].apply(lambda x: x.split('-')[1]).values.astype(str)\n",
    "feat1_assignations = list()\n",
    "feat2_assignations = list()\n",
    "feat3_assignations = list()\n",
    "for leiden_tile in adata_train.obs[groupby].values.astype(str):\n",
    "    feat1_assignations.append(all_data_rho_clr.loc[feature_1,leiden_tile])\n",
    "    feat2_assignations.append(all_data_rho_clr.loc[feature_2,leiden_tile])\n",
    "    feat3_assignations.append(all_data_rho_clr.loc[feature_3,leiden_tile])\n",
    "adata_train.obs[feature_1] = feat1_assignations\n",
    "adata_train.obs[feature_2] = feat2_assignations\n",
    "adata_train.obs[feature_3] = feat3_assignations\n",
    "\n",
    "# Graph visualization related\n",
    "layout           = 'fa'  # fa, fr, rt, rt_circular, drl, eq_tree\n",
    "random_state     = 0\n",
    "threshold        = 0.74\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 7\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .05\n",
    "fontsize    = 15\n",
    "fontoutline = 4\n",
    "marker_size = 3\n",
    "only_seleted = []\n",
    "\n",
    "\n",
    "cmap = sns.diverging_palette(250, 20, as_cmap=True)\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "fig = plt.figure(figsize=(30,10))\n",
    "\n",
    "ax1  = fig.add_subplot(1, 3, 1)\n",
    "colors = sns.color_palette('tab20', len(np.unique(adata_train.obs[groupby].values)))\n",
    "ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='on data', frameon=False, show=False, ax=ax1, color=groupby, palette=colors, size=marker_size)\n",
    "fix_umap_annotations(ax1=ax1)\n",
    "prev_texts = ax1.texts\n",
    "\n",
    "\n",
    "# Axes 2 - TIL Regional Fraction\n",
    "vmax = np.max(adata_train.obs[feature_2].to_numpy())\n",
    "vmin = np.min(adata_train.obs[feature_2].to_numpy())\n",
    "if vmin != 0:\n",
    "    vmin = -vmax\n",
    "ax2  = fig.add_subplot(1, 3, 2)\n",
    "ax2 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, show=False, ax=ax2, color=feature_2, cmap=cmap, legend_loc=None, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "ax2.set_title(feature_2, fontweight='bold', fontsize=20)\n",
    "cbar = ax2.collections[-1].colorbar\n",
    "for a in prev_texts:\n",
    "    ax2.annotate(a._text, xy=(a._x,a._y), color=a._color, verticalalignment=a._verticalalignment, horizontalalignment=a._horizontalalignment,\n",
    "                 fontproperties=a._fontproperties, linespacing=a._linespacing, path_effects=a._path_effects)\n",
    "# adjust_text(ax2.texts)\n",
    "prev_texts = ax2.texts\n",
    "# # Legend on side\n",
    "cbar.ax.tick_params(labelsize=fontsize*0.9)\n",
    "[label.set_fontweight('bold') for label in cbar.ax.get_yticklabels()]\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cbar.locator = tick_locator\n",
    "cbar.update_ticks()\n",
    "\n",
    "# Axes 2 - Macrophage Regulation\n",
    "vmax = np.max(adata_train.obs[feature_3].to_numpy())\n",
    "vmin = np.min(adata_train.obs[feature_3].to_numpy())\n",
    "if vmin != 0:\n",
    "    vmin = -vmax\n",
    "\n",
    "ax3  = fig.add_subplot(1, 3, 3)\n",
    "ax3 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, show=False, ax=ax3, color=feature_3, cmap=cmap, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "ax3.set_title(feature_3, fontweight='bold', fontsize=20)\n",
    "cbar = ax3.collections[-1].colorbar\n",
    "for a in prev_texts:\n",
    "    ax3.annotate(a._text, xy=(a._x,a._y), color=a._color, verticalalignment=a._verticalalignment, horizontalalignment=a._horizontalalignment,\n",
    "                 fontproperties=a._fontproperties, linespacing=a._linespacing, path_effects=a._path_effects)\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cbar.locator = tick_locator\n",
    "cbar.update_ticks()\n",
    "\n",
    "# # Legend on side\n",
    "cbar.ax.tick_params(labelsize=fontsize*0.9)\n",
    "[label.set_fontweight('bold') for label in cbar.ax.get_yticklabels()]\n",
    "\n",
    "ax1.clear()\n",
    "\n",
    "# Axes 1 - TIL Regional Fraction\n",
    "vmax = np.max(adata_train.obs[feature_1].to_numpy())\n",
    "vmin = np.min(adata_train.obs[feature_1].to_numpy())\n",
    "if vmin != 0:\n",
    "    vmin = -vmax\n",
    "ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, show=False, ax=ax1, color=feature_1, cmap=cmap, legend_loc=None, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "ax1.set_title(feature_1, fontweight='bold', fontsize=20)\n",
    "cbar = ax1.collections[-1].colorbar\n",
    "for a in prev_texts:\n",
    "    ax1.annotate(a._text, xy=(a._x,a._y), color=a._color, verticalalignment=a._verticalalignment, horizontalalignment=a._horizontalalignment,\n",
    "                 fontproperties=a._fontproperties, linespacing=a._linespacing, path_effects=a._path_effects)\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cbar.locator = tick_locator\n",
    "cbar.update_ticks()\n",
    "\n",
    "# # Legend on side\n",
    "cbar.ax.tick_params(labelsize=fontsize*0.9)\n",
    "[label.set_fontweight('bold') for label in cbar.ax.get_yticklabels()]\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize = (15,7)\n",
    "\n",
    "fontsize_labels = 25\n",
    "fontsize_legend = 20\n",
    "l_box_w         = 2\n",
    "\n",
    "df_all = adata_train.obs.copy(deep=True)\n",
    "df_all.insert(0, 'UMAP Dim. 1', adata_train.obsm['X_umap'][:,1])\n",
    "df_all.insert(0, 'UMAP Dim. 0', adata_train.obsm['X_umap'][:,0])\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "plot_umaps(data_df=df_all, x='UMAP Dim. 0', y='UMAP Dim. 1', hue='Cancer Type', scatter_size=5, palette='tab20', figsize=figsize, fontsize_labels=fontsize_labels,\n",
    "           fontsize_legend=fontsize_legend, l_box_w=l_box_w)\n",
    "\n",
    "plot_umaps(data_df=df_all, x='UMAP Dim. 0', y='UMAP Dim. 1', hue='TSS Code', scatter_size=1, palette='tab20_r', figsize=figsize, fontsize_labels=fontsize_labels,\n",
    "           fontsize_legend=fontsize_legend, l_box_w=l_box_w)\n",
    "\n",
    "plot_umaps(data_df=df_all, x='UMAP Dim. 0', y='UMAP Dim. 1', hue='TSS Code', scatter_size=1, palette='colorblind', figsize=figsize, fontsize_labels=fontsize_labels,\n",
    "           fontsize_legend=fontsize_legend, l_box_w=l_box_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HPC - Tile Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_img(data):\n",
    "    content = h5py.File(data.hdf5_path, 'r')\n",
    "    frame = pd.DataFrame(range(data.images.shape[0]), columns=['indexes'])\n",
    "    for key in content.keys():\n",
    "        if 'slides' in key:\n",
    "            frame['slides'] = content[key][:].astype(str)\n",
    "        elif 'tiles' in key:\n",
    "            frame['tiles'] = content[key][:].astype(str)\n",
    "    return data.images, frame\n",
    "\n",
    "images, frame_img = data_img(data=data.training)\n",
    "\n",
    "tiles_df = pd.concat([dataframes[0], dataframes[1], dataframes[2]])\n",
    "tiles_df = tiles_df.merge(frame_img, on=['slides','tiles'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_set_images(review_clusters, frame, images, groupby, batches=1, ncols=20, nrows=4, annotated=None):\n",
    "    for cluster_id in review_clusters:\n",
    "        indexes       = frame[(frame[groupby]==cluster_id)]['indexes'].values.tolist()\n",
    "        random.shuffle(indexes)\n",
    "        combined_plot = sorted(indexes[:100*batches])\n",
    "\n",
    "        csv_information = list()\n",
    "        images_cluster = list()\n",
    "        for index in combined_plot:\n",
    "            images_cluster.append(images[int(index)]/255.)\n",
    "\n",
    "        for batch in range(batches):\n",
    "            fig, axs = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "            fig.set_figheight(8)\n",
    "            fig.set_figwidth(8*(ncols/4)*0.8)\n",
    "            if annotated is not None:\n",
    "                fig.suptitle('HPC %s - %s' % (cluster_id, annotated), ha='center', fontweight='bold', fontsize=65)\n",
    "            else:\n",
    "                fig.suptitle('HPC %s' % (cluster_id), ha='center', fontweight='bold', fontsize=65)\n",
    "            gs = axs[0, -4].get_gridspec()\n",
    "            # remove the underlying axes\n",
    "            for i in range(ncols-4,ncols):\n",
    "                for ax in axs[0:, i]:\n",
    "                    ax.remove()\n",
    "            axbig = fig.add_subplot(gs[0:, -4:])\n",
    "            axbig.set_xticks([])\n",
    "            axbig.set_yticks([])\n",
    "            axbig.set_yticks([])\n",
    "            axes_list = list(axs.flatten())\n",
    "            axes_list.append(axbig)\n",
    "            for ax, im in zip(axes_list, images_cluster[batch*100:(batch+1)*100]):\n",
    "                ax.imshow(im)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.set_yticks([])\n",
    "                for axis in ['top','bottom','left','right']:\n",
    "                    ax.spines[axis].set_linewidth(4)\n",
    "            plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "def cluster_set_images_pertype(review_clusters, frame, images, groupby, batches=1, ncols=20, nrows=4, annotated=False, remove_type=None, legend_colors=None, wspace=0.1, figures_path=None):\n",
    "    types = [type for type in np.unique(frame.patterns) if type not in remove_type]\n",
    "\n",
    "    colors = sns.color_palette(legend_colors, len(types))\n",
    "\n",
    "    figures_path = os.path.join(figures_path, 'cluster_samples')\n",
    "\n",
    "\n",
    "    if figures_path is not None and not os.path.isdir(figures_path):\n",
    "        os.makedirs(figures_path)\n",
    "\n",
    "    indexes_dict = dict()\n",
    "    for cluster_id in review_clusters:\n",
    "        cluster_frame = frame[(frame[groupby]==cluster_id)]\n",
    "        for type in types:\n",
    "            indexes = cluster_frame[cluster_frame.patterns==type]['indexes_x'].values.tolist()\n",
    "            random.shuffle(indexes)\n",
    "            indexes_dict[type] = indexes\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            fig, axs = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "            fig.set_figheight(8)\n",
    "            fig.set_figwidth(8*(ncols/4)*0.6)\n",
    "            if annotated:\n",
    "                fig.suptitle('HPC %s' % (cluster_id), ha='center', fontweight='bold', fontsize=50)\n",
    "\n",
    "            for i, type in enumerate(indexes_dict):\n",
    "                axes_type = list()\n",
    "                indexes_type = indexes_dict[type]\n",
    "                column = 0\n",
    "                cols_type = int(ncols/len(types))\n",
    "\n",
    "                gs = axs[-1, 2*(i)].get_gridspec()\n",
    "                axs[-1, 2*i].remove()\n",
    "                axs[-2, 2*i].remove()\n",
    "                axs[-1, 2*(i)+1].remove()\n",
    "                axs[-2, 2*(i)+1].remove()\n",
    "                axbig = fig.add_subplot(gs[-2:, 2*(i):2*(i)+2])\n",
    "                axes_type.append(axbig)\n",
    "\n",
    "                for column in range(cols_type):\n",
    "                    for row in range(nrows-2):\n",
    "                        ax = axs[row, i*cols_type + column]\n",
    "                        axes_type.append(ax)\n",
    "\n",
    "                for j, ax in enumerate(axes_type):\n",
    "                    index = indexes_type[batch*len(axes_type)+j]\n",
    "                    im    = images[int(index)]/255.\n",
    "                    ax.imshow(im)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    for axis in ['top','bottom','left','right']:\n",
    "                        ax.spines[axis].set_linewidth(4)\n",
    "                        ax.spines[axis].set_color(colors[i])\n",
    "                    if j == 0:\n",
    "                        ax.set_xlabel(type, fontsize=26, fontweight='bold')\n",
    "                        ax.xaxis.set_label_coords(.5, -.1)\n",
    "\n",
    "            plt.subplots_adjust(wspace=wspace, hspace=0.1)\n",
    "            fig.tight_layout()\n",
    "            if figures_path is not None:\n",
    "                plt.savefig(os.path.join(figures_path, 'HPC_%s_batch%s.jpg' % (cluster_id, batch)), dpi=500)\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cluster_set_images_pertype(review_clusters=leiden_clusters, frame=tiles_df, images=images, groupby=groupby, batches=2, ncols=20, nrows=6, annotated=True, remove_type=list(),\n",
    "                           legend_colors='tab10', wspace=0.05, figures_path=figures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cluster_id = 1\n",
    "cluster_frame = frame[(frame[groupby]==cluster_id)]\n",
    "types = [type for type in np.unique(cluster_frame.patterns) if type not in remove_type]\n",
    "for type in types:\n",
    "    type_df = cluster_frame[cluster_frame.patterns==type]\n",
    "    cluster_set_images(review_clusters=[1], frame=type_df, images=images, groupby=groupby, batches=2, ncols=20, nrows=4, annotated=type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
