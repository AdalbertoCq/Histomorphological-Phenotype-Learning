{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from matplotlib.colors       import LinearSegmentedColormap\n",
    "from matplotlib.colors       import TwoSlopeNorm\n",
    "from skimage.transform       import resize\n",
    "from plottify                import autosize\n",
    "from sklearn                 import metrics\n",
    "from PIL                     import Image\n",
    "from adjustText              import adjust_text\n",
    "from scipy.cluster           import hierarchy\n",
    "import statsmodels.api       as sm\n",
    "import matplotlib.pyplot     as plt\n",
    "import numpy                 as np\n",
    "import seaborn               as sns\n",
    "import pandas                as pd\n",
    "import scanpy                as sc\n",
    "import matplotlib\n",
    "import anndata\n",
    "import random\n",
    "import fastcluster\n",
    "import copy\n",
    "import umap\n",
    "import h5py\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Variables for data selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace path.\n",
    "main_path = '/media/adalberto/Disk2/PhD_Workspace'\n",
    "sys.path.append(main_path)\n",
    "from models.clustering.cox_proportional_hazard_regression_leiden_clusters import *\n",
    "from models.evaluation.folds import load_existing_split\n",
    "from models.visualization.attention_maps import *\n",
    "from models.clustering.data_processing import *\n",
    "from data_manipulation.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Image dataset variables.\n",
    "dataset            = 'TCGAFFPE_LUADLUSC_5x_60pc'\n",
    "additional_dataset = 'NYUFFPE_survival_5x_60pc'\n",
    "\n",
    "############# LUAD Overall and Recurrence Free Survival\n",
    "meta_field       = 'luad'\n",
    "matching_field   = 'samples'\n",
    "resolution      = 2.0\n",
    "fold_number     = 0\n",
    "groupby         = 'leiden_%s' % resolution\n",
    "meta_folder     = 'luad_overall_survival_nn250_fold%s_NYU_v3' % fold_number\n",
    "folds_pickle    = '%s/utilities/files/LUAD/overall_survival_TCGA_folds.pkl'  % main_path\n",
    "\n",
    "# Institutions.\n",
    "inst_csv   = '%s/utilities/files/TCGA/TCGA_Institutions.csv' % main_path\n",
    "inst_frame = pd.read_csv(inst_csv)\n",
    "inst_frame = inst_frame[inst_frame['Study Name'].isin(['Lung adenocarcinoma', 'Lung squamous cell carcinoma'])]\n",
    "\n",
    "# Representations.\n",
    "h5_complete_path = '%s/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/hdf5_TCGAFFPE_LUADLUSC_5x_60pc_he_complete_lungsubtype_survival_filtered.h5' % main_path\n",
    "h5_additional_path = '%s/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/NYU300LUAD_Survival_5x_60pc/h224_w224_n3_zdim128/hdf5_NYU300LUAD_Survival_5x_60pc_he_train_overall_progression_free_surival_filtered.h5' % main_path\n",
    "\n",
    "# File name and directories.\n",
    "file_name = h5_complete_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s' % (groupby.replace('.', 'p'), fold_number)\n",
    "if h5_additional_path is not None: file_additional = h5_additional_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s' % (groupby.replace('.', 'p'), fold_number)\n",
    "\n",
    "# Setup folder.\n",
    "main_cluster_path = h5_complete_path.split('hdf5_')[0]\n",
    "main_cluster_path = os.path.join(main_cluster_path, meta_folder)\n",
    "adatas_path       = os.path.join(main_cluster_path, 'adatas')\n",
    "figures_path      = os.path.join(main_cluster_path, 'figures')\n",
    "if not os.path.isdir(figures_path):\n",
    "    os.makedirs(figures_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Correlation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This correlation values come from the correlation notebook.\n",
    "correlation_hovernet = '%s/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/luad_overall_survival_nn250_fold0_NYU_v3/leiden_2p0_fold0/correlations/NYU300LUAD_Survival_5x_60pc_he_train_overall_progression_free_surival_filtered_leiden_2p0__fold0_luad_overall_survival_nn250_fold0_NYU_v3_hovernet_critical_coef.csv' % main_path\n",
    "hovernet_df = pd.read_csv(correlation_hovernet)\n",
    "hovernet_df = hovernet_df.rename(columns={'Unnamed: 0':'Cell Type'})\n",
    "hovernet_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = Data(dataset=dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path=main_path, load=True)\n",
    "img_dicts = dict()\n",
    "img_dicts['train'] = data.training.images\n",
    "img_dicts['valid'] = data.validation.images\n",
    "img_dicts['test'] = data.test.images\n",
    "\n",
    "additional_data = Data(dataset=additional_dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path=main_path, load=True)\n",
    "additional_img_dicts = dict()\n",
    "additional_img_dicts['train'] = additional_data.training.images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPC Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_annotations_path = '%s/utilities/files/LUAD/HPC_annotations/LUAD_HPC_annotations.csv' % main_path\n",
    "annotations          = pd.read_csv(csv_annotations_path)\n",
    "annotations          = annotations.set_index('HPC')\n",
    "annotations          = annotations.replace({'other predominant tissue':'no epithelium', 'very sparse':'Very Sparse', 'severe':'Severe', 'moderate':'Moderate', 'mild':'Mild'})\n",
    "annotations          = annotations.replace({'more stroma':'More Stroma', 'more epithelium':'More Epithelium', 'no epithelium':'No Epithelium', 'roughly equal':'Roughly Equal'})\n",
    "\n",
    "annotations          = annotations.replace({'malignant epithelium':'Malignant Epithelium', 'elastosis or collagenosis':'Elastosis/Collagenosis',\n",
    "       'near-normal lung':'Near-normal Lung', 'reactive lung changes':'Reactive Lung Changes', 'necrosis':'Necrosis',\n",
    "       'other connective tissue':'Connective Tissue', 'vessels':'Vessels', 'airway':'Airway', 'cartilage':'Cartilage'})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - Latent Space and Cluster Network - LUAD OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata_train, h5ad_path = read_h5ad_reference(h5_complete_path, meta_folder, groupby, fold_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "if os.path.isfile(h5ad_path.replace('.h5ad', '_paga.h5ad')):\n",
    "    done=True\n",
    "    adata_train = anndata.read_h5ad(h5ad_path.replace('.h5ad', '_paga.h5ad'))\n",
    "else:\n",
    "    sc.tl.paga(adata_train, groups=groupby, neighbors_key='nn_leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPC network visualization\n",
    "layout           = 'fa'  # ‘fa’, ‘fr’, ‘rt’, ‘rt_circular’, ‘drl’, ‘eq_tree’\n",
    "random_state     = 0\n",
    "threshold        = 0.74\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 7\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .05\n",
    "fontsize    = 15\n",
    "fontoutline = 2\n",
    "\n",
    "if not done:\n",
    "        fig = plt.figure(figsize=(100,10))\n",
    "        ax  = fig.add_subplot(1, 3, 1)\n",
    "        sc.pl.paga(adata_train, layout=layout, random_state=random_state, threshold=threshold, node_size_scale=node_size_scale, node_size_power=node_size_power,\n",
    "                edge_width_scale=edge_width_scale, fontsize=fontsize, fontoutline=fontoutline, frameon=False, show=False, ax=ax)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not done:\n",
    "    sc.tl.umap(adata_train, init_pos=\"paga\", neighbors_key='nn_leiden')\n",
    "    adata_train.write(h5ad_path.replace('.h5ad', '_paga.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_depletion = False\n",
    "\n",
    "cell_types = list()\n",
    "for cell_type in hovernet_df['Cell Type']:\n",
    "    cell_types.append(cell_type)\n",
    "    for cluster in np.unique(adata_train.obs[groupby]):\n",
    "        value = hovernet_df[hovernet_df['Cell Type']==cell_type][cluster].values[0]\n",
    "        if cap_depletion and value < 0:\n",
    "            value = 0\n",
    "        adata_train.obs.at[adata_train.obs[groupby]==str(cluster), cell_type] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Graph visualization related\n",
    "layout           = 'fa'  # ‘fa’, ‘fr’, ‘rt’, ‘rt_circular’, ‘drl’, ‘eq_tree’\n",
    "random_state     = 0\n",
    "threshold        = 0.74\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 7\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .05\n",
    "fontsize    = 15\n",
    "fontoutline = 2\n",
    "\n",
    "cmap = sns.diverging_palette(250, 20, as_cmap=True)\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "fig = plt.figure(figsize=(30,10))\n",
    "\n",
    "ax  = fig.add_subplot(1, 3, 1)\n",
    "ax.set_title('Cell Neoplastic\\nEnrichment', fontweight='bold', fontsize=20)\n",
    "sc.pl.paga(adata_train, layout=layout, random_state=random_state, threshold=threshold, node_size_scale=node_size_scale, node_size_power=node_size_power,\n",
    "           edge_width_scale=edge_width_scale, fontsize=fontsize, fontoutline=fontoutline, frameon=False, show=False, ax=ax, color='cell neoplastic', cmap=cmap, colorbar=False)\n",
    "\n",
    "\n",
    "ax  = fig.add_subplot(1, 3, 2)\n",
    "ax.set_title('Cell Inflammatory\\nEnrichment', fontweight='bold', fontsize=20)\n",
    "sc.pl.paga(adata_train, layout=layout, random_state=random_state, threshold=threshold, node_size_scale=node_size_scale, node_size_power=node_size_power,\n",
    "           edge_width_scale=edge_width_scale, fontsize=fontsize, fontoutline=fontoutline, frameon=False, show=False, ax=ax, color='cell inflammatory', cmap=cmap, colorbar=False)\n",
    "\n",
    "ax  = fig.add_subplot(1, 3, 3)\n",
    "ax.set_title('Cell Dead\\nEnrichment', fontweight='bold', fontsize=20)\n",
    "sc.pl.paga(adata_train, layout=layout, random_state=random_state, threshold=threshold, node_size_scale=node_size_scale, node_size_power=node_size_power,\n",
    "           edge_width_scale=edge_width_scale, fontsize=fontsize, fontoutline=fontoutline, frameon=False, show=False, ax=ax, color='cell dead', cmap=cmap, colorbar=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for feature in annotations.columns:\n",
    "    adata_assignations = list()\n",
    "    for leiden_tile in adata_train.obs[groupby].values.astype(int):\n",
    "        value = annotations.loc[leiden_tile, feature]\n",
    "        if str(annotations.loc[leiden_tile, feature])=='nan':\n",
    "            value = 'N/A'\n",
    "        adata_assignations.append(value)\n",
    "    adata_train.obs[feature] = np.array(adata_assignations).astype(str)\n",
    "annotations.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_umap_annotations(ax1):\n",
    "    # HPC 15\n",
    "    old_y = ax1.texts[15]._y\n",
    "    ax1.texts[15]._y = old_y*1.02\n",
    "\n",
    "    #  -----------\n",
    "    # HPC 14\n",
    "    old_y = ax1.texts[14]._y\n",
    "    ax1.texts[14]._y = old_y*1.022\n",
    "\n",
    "    # HPC 3\n",
    "    old_y = ax1.texts[3]._y\n",
    "    ax1.texts[3]._y = old_y*0.975\n",
    "\n",
    "    #  -----------\n",
    "    # HPC 13\n",
    "    old_y = ax1.texts[13]._y\n",
    "    ax1.texts[13]._y = old_y*1.5\n",
    "\n",
    "    # HPC 12\n",
    "    old_y = ax1.texts[12]._y\n",
    "    ax1.texts[12]._y = old_y*0.8\n",
    "\n",
    "    #  -----------\n",
    "    # HPC 21\n",
    "    old_y = ax1.texts[21]._y\n",
    "    ax1.texts[21]._y = old_y*1.02\n",
    "\n",
    "    # HPC 12\n",
    "    old_y = ax1.texts[11]._y\n",
    "    ax1.texts[11]._y = old_y*0.98\n",
    "\n",
    "    #  -----------\n",
    "    # HPC 39\n",
    "    old_y = ax1.texts[39]._y\n",
    "    ax1.texts[39]._y = old_y*0.97\n",
    "\n",
    "    #  -----------\n",
    "    # HPC 41\n",
    "    old_x = ax1.texts[41]._x\n",
    "    ax1.texts[41]._x = old_x*1.1\n",
    "\n",
    "    # HPC 9\n",
    "    old_y = ax1.texts[9]._y\n",
    "    ax1.texts[9]._y = old_y*1.02\n",
    "\n",
    "    #  -----------\n",
    "    # HPC 40\n",
    "    old_y = ax1.texts[40]._y\n",
    "    ax1.texts[40]._y = old_y*0.95\n",
    "\n",
    "    #  -----------\n",
    "    # HPC 27\n",
    "    old_y = ax1.texts[27]._y\n",
    "    ax1.texts[27]._y = old_y*0.8\n",
    "\n",
    "    #  -----------\n",
    "    # HPC 24\n",
    "    old_x = ax1.texts[24]._x\n",
    "    ax1.texts[24]._x = old_x-0.5\n",
    "\n",
    "    # HPC 35\n",
    "    old_y = ax1.texts[35]._y\n",
    "    ax1.texts[35]._y = old_y-0.2\n",
    "\n",
    "# Graph visualization related\n",
    "layout           = 'fa'  # ‘fa’, ‘fr’, ‘rt’, ‘rt_circular’, ‘drl’, ‘eq_tree’\n",
    "random_state     = 0\n",
    "threshold        = 0.74\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 7\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .05\n",
    "fontoutline = 4\n",
    "marker_size = 2\n",
    "\n",
    "fontsize       = 20\n",
    "fontsize_title = 22\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "print('UMAP_leiden')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "# # Axes 1 - Leiden clusters.\n",
    "colors = sns.color_palette('tab20', len(np.unique(adata_train.obs[groupby].values)))\n",
    "ax1  = fig.add_subplot(1, 1, 1)\n",
    "ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='on data', frameon=False, show=False, ax=ax1, color=groupby, palette=colors, size=marker_size)\n",
    "# adjust_text(ax1.texts)\n",
    "ax1.set_title('LUAD\\nHistomorphological Phenotype Clusters', fontweight='bold', fontsize=fontsize_title)\n",
    "fix_umap_annotations(ax1)\n",
    "plt.show()\n",
    "\n",
    "print('UMAP_tissue_morphologies')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "# Axes 3 - Morphological Supergroup.\n",
    "feature_3 = 'Tissue Morphologies'\n",
    "colors = sns.color_palette('Set1', len(np.unique(adata_train.obs[feature_3].values)))\n",
    "colors = ['Grey', colors[5], colors[0], 'purple', colors[2], colors[1]]\n",
    "ax3  = fig.add_subplot(1, 1, 1)\n",
    "ax3 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='right margin', frameon=False, show=False, ax=ax3, color=feature_3, palette=colors, size=marker_size)\n",
    "adjust_text(ax3.texts)\n",
    "ax3.set_title('Tissue Morphologies', fontweight='bold', fontsize=fontsize_title)\n",
    "handles, labels = ax3.get_legend_handles_labels()\n",
    "handles = [handles[5], handles[4], handles[2], handles[3], handles[1], handles[0]]\n",
    "labels  = [labels[5],  labels[4],  labels[2],  labels[3],  labels[1],  labels[0]]\n",
    "ax3.legend(handles, labels, loc='upper right', frameon=False, bbox_to_anchor=(1.52,0.75))\n",
    "for text in ax3.legend_.get_texts():\n",
    "    text.set_size(fontsize)\n",
    "    text.set_fontweight('bold')\n",
    "plt.show()\n",
    "\n",
    "print('UMAP_epth_stroma_ratio')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "# Axes 2 - Lymphocytic Infiltration.\n",
    "feature_2 = 'Epithelium Stroma Ratio'\n",
    "colors = sns.color_palette('Set1', len(np.unique(adata_train.obs[feature_3].values)))\n",
    "colors = [colors[0], colors[1], colors[4], colors[2]]\n",
    "ax2  = fig.add_subplot(1, 1, 1)\n",
    "ax2 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='right margin', frameon=False, show=False, ax=ax2, color=feature_2, palette=colors, size=marker_size)\n",
    "adjust_text(ax2.texts)\n",
    "ax2.set_title('Epithelium Stroma Ratio', fontweight='bold', fontsize=fontsize_title)\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "handles = [handles[1], handles[2], handles[0], handles[3]]\n",
    "labels  = [labels[1],  labels[2],  labels[0],  labels[3]]\n",
    "ax2.legend(handles, labels, loc='center right', frameon=False, bbox_to_anchor=(1.3,0.55))\n",
    "for text in ax2.legend_.get_texts():\n",
    "    text.set_size(fontsize)\n",
    "    text.set_fontweight('bold')\n",
    "plt.show()\n",
    "\n",
    "print('UMAP_inflammation')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "# Axes 3 - Morphological Supergroup.\n",
    "feature_3 = 'Lymphocytic Infiltration'\n",
    "colors = sns.diverging_palette(250, 20, n=len(np.unique(adata_train.obs[feature_3].values))-1, center='light')\n",
    "colors = [colors[1], colors[2], 'Grey', colors[3], colors[0]]\n",
    "ax3  = fig.add_subplot(1, 1, 1)\n",
    "ax3 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='right margin', frameon=False, show=False, ax=ax3, color=feature_3, palette=colors, size=marker_size)\n",
    "ax3.set_title('Lymphocytic Infiltration', fontweight='bold', fontsize=fontsize_title)\n",
    "handles, labels = ax3.get_legend_handles_labels()\n",
    "handles = [handles[3], handles[1], handles[0], handles[-1], handles[2]]\n",
    "labels  = [labels[3],  labels[1],  labels[0],  labels[-1],  labels[2]]\n",
    "ax3.legend(handles, labels, loc='center right', frameon=False, bbox_to_anchor=(1.2,0.5))\n",
    "for text in ax3.legend_.get_texts():\n",
    "    text.set_size(fontsize)\n",
    "    text.set_fontweight('bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Graph visualization related\n",
    "layout           = 'fa'  # ‘fa’, ‘fr’, ‘rt’, ‘rt_circular’, ‘drl’, ‘eq_tree’\n",
    "random_state     = 0\n",
    "threshold        = 0.74\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 7\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .05\n",
    "fontsize    = 15\n",
    "fontoutline = 4\n",
    "marker_size = 6\n",
    "only_seleted = []\n",
    "\n",
    "\n",
    "cmap = sns.color_palette(\"Reds\", as_cmap=True)\n",
    "vmax = np.max(adata_train.obs[cell_types].to_numpy())\n",
    "vmin = np.min(adata_train.obs[cell_types].to_numpy())\n",
    "if vmin != 0:\n",
    "    vmin = -vmax\n",
    "    # cmap = sns.color_palette(\"vlag\", as_cmap=True)\n",
    "    cmap = sns.diverging_palette(250, 20, as_cmap=True)\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "fig = plt.figure(figsize=(30,10))\n",
    "\n",
    "ax1  = fig.add_subplot(1, 3, 1)\n",
    "ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='on data', frameon=False, show=False, ax=ax1, color=groupby, cmap=cmap, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "fix_umap_annotations(ax1=ax1)\n",
    "prev_texts = ax1.texts\n",
    "\n",
    "# Axes 1 - Inflammatory\n",
    "ax2  = fig.add_subplot(1, 3, 2)\n",
    "ax2 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, show=False, ax=ax2, color='cell inflammatory', cmap=cmap, legend_loc=None, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "ax2.set_title('Cell Inflammatory\\nEnrichment', fontweight='bold', fontsize=20)\n",
    "ax2.collections[-1].colorbar.remove()\n",
    "for a in prev_texts:\n",
    "    ax2.annotate(a._text, xy=(a._x,a._y), color=a._color, verticalalignment=a._verticalalignment, horizontalalignment=a._horizontalalignment,\n",
    "                 fontproperties=a._fontproperties, linespacing=a._linespacing, path_effects=a._path_effects)\n",
    "\n",
    "# Axes 2 - Dead\n",
    "ax3  = fig.add_subplot(1, 3, 3)\n",
    "ax3 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, show=False, ax=ax3, color='cell dead', cmap=cmap, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "ax3.set_title('Cell Dead\\nEnrichment', fontweight='bold', fontsize=20)\n",
    "cbar = ax3.collections[-1].colorbar\n",
    "for a in prev_texts:\n",
    "    ax3.annotate(a._text, xy=(a._x,a._y), color=a._color, verticalalignment=a._verticalalignment, horizontalalignment=a._horizontalalignment,\n",
    "                 fontproperties=a._fontproperties, linespacing=a._linespacing, path_effects=a._path_effects)\n",
    "prev_texts = ax3.texts\n",
    "\n",
    "# Legend on side\n",
    "cbar.ax.tick_params(labelsize=fontsize*0.9)\n",
    "[label.set_fontweight('bold') for label in cbar.ax.get_yticklabels()]\n",
    "\n",
    "# Axes 0 - Neoplastic\n",
    "ax1.clear()\n",
    "ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, show=False, ax=ax1, color='cell neoplastic', cmap=cmap, vmin=vmin, vmax=vmax, size=marker_size)\n",
    "ax1.collections[-1].colorbar.remove()\n",
    "ax1.set_title('Cell Neoplastic\\nEnrichment', fontweight='bold', fontsize=20)\n",
    "for a in prev_texts:\n",
    "    ax1.annotate(a._text, xy=(a._x,a._y), color=a._color, verticalalignment=a._verticalalignment, horizontalalignment=a._horizontalalignment,\n",
    "                 fontproperties=a._fontproperties, linespacing=a._linespacing, path_effects=a._path_effects)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_set = list()\n",
    "mark_set.append(('UMAP_leiden_A', [2, 4, 10, 13, 32, 36]))\n",
    "mark_set.append(('UMAP_leiden_B', [3, 14, 16, 20, 22, 23, 31, 34, 40, 42, 42]))\n",
    "mark_set.append(('UMAP_leiden_C', [8, 21, 0, 26, 5, 15, 25, 29, 38, 18, 45, 19, 24, 30, 35, 28, 37]))\n",
    "mark_set.append(('UMAP_leiden_D', [6, 11, 12, 27, 33, 39, 41]))\n",
    "mark_set.append(('UMAP_leiden_E', [1,7,9,12,17,41,44]))\n",
    "\n",
    "for name, mark in mark_set:\n",
    "\n",
    "    print(name)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    # # Axes 1 - Leiden clusters.\n",
    "    colors = sns.color_palette('tab20', len(np.unique(adata_train.obs[groupby].values)))\n",
    "    for i in np.unique(adata_train.obs[groupby].values.astype(int)):\n",
    "        if i not in mark:\n",
    "            colors[i] = 'Grey'\n",
    "\n",
    "    ax1  = fig.add_subplot(1, 1, 1)\n",
    "    # ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='on data', frameon=False, show=False, ax=ax1, color=groupby, palette=colors, size=marker_size)\n",
    "    ax1 = sc.pl.umap(adata_train, legend_fontsize=fontsize, legend_fontoutline=fontoutline, legend_loc='on data', frameon=False, show=False, ax=ax1, \n",
    "                    color=groupby, palette=colors, size=5)\n",
    "    ax1.set_title('LUAD\\nHistomorphological Phenotype Clusters', fontweight='bold', fontsize=fontsize_title)\n",
    "    fix_umap_annotations(ax1)\n",
    "\n",
    "    sizes = list()\n",
    "    for flag in adata_train.obs[groupby].astype(int).isin(mark):\n",
    "        if flag:\n",
    "            sizes.append(10)\n",
    "        else:\n",
    "            sizes.append(0.75)\n",
    "    ax1._children[0]._sizes = np.array(sizes)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Figure - UMAP Patient vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = build_cohort_representations(meta_folder, meta_field, matching_field, groupby, fold_number, folds_pickle, h5_complete_path, h5_additional_path, 'clr', 100)\n",
    "complete_df, additional_complete_df, frame_clusters, frame_samples, features = frames\n",
    "\n",
    "labels = complete_df.to_numpy()[1:,-1]\n",
    "data   = complete_df.to_numpy()[1:,2:-1]\n",
    "\n",
    "labels_add = additional_complete_df.to_numpy()[1:,-1]\n",
    "data_add   = additional_complete_df.to_numpy()[1:,2:-1]\n",
    "\n",
    "columns = [col for col in complete_df.columns if col != 'luad' and col != 'samples' and col != 'slides']\n",
    "\n",
    "labels = complete_df.to_numpy()[1:,-1]\n",
    "data   = complete_df.to_numpy()[1:,2:-1]\n",
    "df     = pd.DataFrame(data, columns=columns)\n",
    "df['Lung Type'] = labels\n",
    "df['Cohort']       = 'TCGA'\n",
    "\n",
    "labels_add = additional_complete_df.to_numpy()[1:,-1]\n",
    "data_add   = additional_complete_df.to_numpy()[1:,1:-1]\n",
    "df_add     = pd.DataFrame(data_add, columns=columns)\n",
    "df_add['Lung Type'] = labels_add\n",
    "df_add['Cohort']       = 'NYU'\n",
    "\n",
    "df_all = pd.concat([df, df_add], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_size    = 200\n",
    "\n",
    "figsize         = (10,10)\n",
    "fontsize_labels = 30\n",
    "fontsize_legend = 30\n",
    "l_markerscale   = 5\n",
    "l_box_w         = 2\n",
    "lw              = 2\n",
    "\n",
    "min_dist     = 0.0\n",
    "n_components = 2\n",
    "n_neighbors  = 25\n",
    "metric       = 'euclidean'\n",
    "\n",
    "print(metric, n_neighbors)\n",
    "# UMAP\n",
    "fit = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, metric=metric)\n",
    "u   = fit.fit_transform(df_all[columns])\n",
    "df_all['UMAP Dim. 0'] = u[:, 0]\n",
    "df_all['UMAP Dim. 1'] = u[:, 1]\n",
    "\n",
    "fig   = plt.figure(figsize=figsize)\n",
    "ax    = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# Scatter plot.\n",
    "sns.scatterplot(data=df_all, x='UMAP Dim. 0', y='UMAP Dim. 1', hue='Lung Type', style='Cohort', markers={'TCGA':'v', 'NYU':'s'}, s=scatter_size, ax=ax)\n",
    "ax.set_xlabel('UMAP Dim. 0', fontsize=fontsize_labels)\n",
    "ax.set_ylabel('UMAP Dim. 1', fontsize=fontsize_labels)\n",
    "ax.set_title('Patient\\nVector Representations',  fontsize=fontsize_labels, fontweight='bold')\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize_labels)\n",
    "legend = ax.legend(loc='upper left', markerscale=l_markerscale, prop={'size': fontsize_legend-5}, ncol=2)\n",
    "legend.get_texts()[1].set_text('LUSC')\n",
    "legend.get_texts()[2].set_text('LUAD')\n",
    "legend.get_texts()[0].set_size(fontsize_legend)\n",
    "legend.get_texts()[3].set_size(fontsize_legend)\n",
    "legend.get_frame().set_linewidth(l_box_w)\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "\n",
    "ax.set_xlabel('UMAP Dim. 0', fontsize=fontsize_labels, fontweight='bold')\n",
    "ax.set_ylabel('UMAP Dim. 1', fontsize=fontsize_labels, fontweight='bold')\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Figure - HPC Generalization across Institutions and Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tile vector representations.\n",
    "folds = load_existing_split(folds_pickle)\n",
    "fold = folds[fold_number]\n",
    "dataframes, complete_df, leiden_clusters = read_csvs(adatas_path, matching_field, groupby, fold_number, fold, h5_complete_path, h5_additional_path, additional_as_fold=False, force_fold=fold_number)\n",
    "\n",
    "# Concatenate all data.\n",
    "tiles_df = pd.concat([dataframes[0], dataframes[1], dataframes[2]])\n",
    "tiles_df['samples']  = tiles_df['slides'].apply(lambda x: '-'.join(x.split('-')[:3]))\n",
    "tiles_df['TSS Code'] = tiles_df['samples'].apply(lambda x: x.split('-')[1]).values.astype(str)\n",
    "\n",
    "# Include counts per samples and HPC\n",
    "for name, field in [('sample',matching_field), ('hpc', groupby)]:\n",
    "    counts_per_field = tiles_df.groupby(field).count()\n",
    "    counts_per_field = counts_per_field.reset_index()\n",
    "    counts_per_field = counts_per_field.rename(columns={'tiles':'nt_per_%s'%name})\n",
    "    tiles_df = tiles_df.merge(counts_per_field[[field, 'nt_per_%s'%name]], on=field)\n",
    "\n",
    "# Normalized values of percentage of total tiles in HPC\n",
    "tiles_df.insert(loc=len(tiles_df.columns), column='nt_per_hpc_norm', value=tiles_df['nt_per_hpc'].values/tiles_df.shape[0])\n",
    "\n",
    "# Normalize contribution of HPC in patient.\n",
    "hpc_pat = tiles_df[[matching_field, groupby, 'tiles']].groupby([matching_field, groupby]).count()\n",
    "hpc_pat = hpc_pat.reset_index()\n",
    "hpc_pat = hpc_pat.rename(columns={'tiles':'nt_per_sample_hpc'})\n",
    "hpc_pat = hpc_pat.merge(tiles_df[[matching_field, 'nt_per_sample']].drop_duplicates(), on=matching_field)\n",
    "hpc_pat = hpc_pat.drop_duplicates()\n",
    "hpc_pat['nt_per_sample_hpc_norm'] = np.divide(hpc_pat['nt_per_sample_hpc'].values.astype(float), hpc_pat['nt_per_sample'].values.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_institution_distribution(data_hpc_inst, unique_values, unique_label, field, title, figsize=(30,7), fontsize_labels=22, fontsize_legend=20, show_max_min=False):\n",
    "    def colors_from_values(values, palette_name, normalize=False):\n",
    "        # normalize the values to range [0, 1]\n",
    "        if values.max() >1:\n",
    "            normalized = (values - min(values)) / (max(values) - min(values))\n",
    "        else:\n",
    "            normalized = values\n",
    "        # convert to indices\n",
    "        indices = np.round(normalized * (len(values) - 1)).astype(np.int32)\n",
    "        # use the indices to get the colors\n",
    "        palette = sns.color_palette(palette_name, int(1.5*len(values)))\n",
    "        return np.array(palette).take(indices, axis=0)\n",
    "\n",
    "    fig   = plt.figure(figsize=figsize)\n",
    "\n",
    "    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=figsize, gridspec_kw={'width_ratios': [25, 1]})\n",
    "\n",
    "    # pal  = sns.color_palette(\"Greens_d\")\n",
    "    # rank = data_hpc_inst[field].argsort().argsort()\n",
    "    # sns.barplot(data=data_hpc_inst, x='HPC', y=field, palette=np.array(pal[::-1])[rank], ax=ax)\n",
    "    y = data_hpc_inst[field].values\n",
    "    y_color = np.array([100] + y.tolist())\n",
    "    max_color = colors_from_values(y_color, \"Greens_d\")[0]\n",
    "    color_palette = colors_from_values(y_color, \"Greens_d\")[1:]\n",
    "    \n",
    "    sns.barplot(data=data_hpc_inst, x='HPC', y=field, palette=color_palette, ax=ax0)\n",
    "\n",
    "    ax0.tick_params(axis='x', rotation=90)\n",
    "    ax0.set_ylim([0,105])\n",
    "    yticks = (np.array(range(0,110,10))).tolist()\n",
    "    ax0.set_yticks(yticks, yticks)\n",
    "\n",
    "    ax0.set_title(title,  fontsize=fontsize_labels*1.3, fontweight='bold')\n",
    "    ax0.set_xlabel('\\nHistomorphological Phenotype Cluster (HPC)', fontsize=fontsize_labels,     fontweight='bold')\n",
    "    ax0.set_ylabel(' ', fontsize=fontsize_labels, fontweight='bold')\n",
    "    if show_max_min:\n",
    "        max_val = np.max(data_hpc_inst[field].values)\n",
    "        min_val = np.min(data_hpc_inst[field].values)\n",
    "        ax0.axhline(max_val, linestyle='--')\n",
    "        ax0.axhline(min_val, linestyle='--')\n",
    "    ax0.axhline(50, linestyle='--', color='black')\n",
    "    ax0.axhline(25, linestyle='--', color='black')\n",
    "\n",
    "    sns.barplot(y=[unique_values], palette='Blues_r', ax=ax1)\n",
    "    ax1.set_xlabel(unique_label, fontsize=fontsize_labels,     fontweight='bold')\n",
    "    yticks = ax1.get_yticks().tolist()\n",
    "    yticks = np.array(yticks).astype(int)\n",
    "    ax1.set_yticks(yticks, yticks)\n",
    "\n",
    "    for ax in [ax0, ax1]:\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_labels)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_labels)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Threshold minimum contribution for patient or institution. \n",
    "threshold = 0.005\n",
    "\n",
    "# Threshold out patients with not enough contribution at least 0.5%.\n",
    "hpc_pat_th = hpc_pat[hpc_pat.nt_per_sample_hpc_norm >= threshold]\n",
    "hpc_pat_th = hpc_pat_th.groupby([groupby]).count()['samples']/len(np.unique(hpc_pat[matching_field]))*100\n",
    "hpc_pat_th = hpc_pat_th.reset_index()\n",
    "hpc_pat_th = hpc_pat_th.rename(columns={groupby:'HPC'})\n",
    "\n",
    "# Threshold out institution with not enough contribution at least 0.5%.\n",
    "tiles_df = pd.concat([dataframes[0], dataframes[1], dataframes[2]])\n",
    "tiles_df['TSS Code'] = tiles_df['samples'].apply(lambda x: x.split('-')[1]).values.astype(str)\n",
    "tss_hpc = tiles_df[['TSS Code', 'tiles']].groupby('TSS Code').count()\n",
    "tss_hpc = tss_hpc.reset_index()\n",
    "tss_hpc = tss_hpc.rename(columns={'tiles':'total_tiles'})\n",
    "\n",
    "data_hpc_inst = list()\n",
    "for hpc in np.unique(tiles_df[groupby]):\n",
    "    hpc_df    = tiles_df[tiles_df[groupby]==hpc]\n",
    "    hpc_df    = hpc_df.groupby('TSS Code').count()\n",
    "    hpc_df    = hpc_df.reset_index()[['TSS Code', 'tiles']]\n",
    "    hpc_df    = hpc_df.merge(tss_hpc, on='TSS Code', how='inner')\n",
    "    hpc_df.insert(len(hpc_df.columns), 'tiles_norm', np.divide(hpc_df['tiles'].values,hpc_df['total_tiles'].values))\n",
    "    hpc_df    = hpc_df[hpc_df['tiles_norm']>=threshold]\n",
    "    data_hpc_inst.append((hpc, hpc_df.shape[0]/tss_hpc.shape[0]*100))\n",
    "data_hpc_inst = pd.DataFrame(data_hpc_inst, columns=['HPC', 'Percentage of Institutions in HPC'])\n",
    "\n",
    "plot_institution_distribution(data_hpc_inst, unique_values=tiles_df['TSS Code'].unique().shape[0], unique_label='Total\\nInstitutions', \n",
    "                              field='Percentage of Institutions in HPC', title='Percentage of TCGA institutions\\npresent in the HPC', \n",
    "                              figsize=(30,10), fontsize_labels=35, fontsize_legend=32)\n",
    "plot_institution_distribution(hpc_pat_th,    unique_values=tiles_df['samples'].unique().shape[0], unique_label='Total\\nPatients', \n",
    "                              field='samples', title='Percentage of TCGA patients\\npresent in the HPC',\n",
    "                              figsize=(30,10), fontsize_labels=35, fontsize_legend=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Figure - HPC Summary Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_set_images(leiden_clusters_order, hpc_index_map, data_dicts, groupby, fontsize_title, fontsize_label, batches=1, ncols=10, nrows=5, figsize=(30, 18), annotations=None, width=None, main_cluster_path=None):\n",
    "    import textwrap\n",
    "\n",
    "    for batch in range(batches):\n",
    "        fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize)\n",
    "        axes_list = list(axs.flatten())\n",
    "\n",
    "        for ax, cluster_id in zip(axes_list, leiden_clusters_order):            \n",
    "            # indexes       = frame[(frame[groupby]==cluster_id)]['indexes'].values.tolist()\n",
    "            # original_sets = frame[(frame[groupby]==cluster_id)]['original_set'].values.tolist()\n",
    "            # combined      = list(zip(indexes, original_sets))\n",
    "            # random.shuffle(combined)\n",
    "            # combined_plot = sorted(combined[:100*batches])\n",
    "            # index = indexes[0]\n",
    "            # original_set = original_sets[0]\n",
    "            index        = hpc_index_map[cluster_id]['index'] \n",
    "            original_set = hpc_index_map[cluster_id]['original_set'] \n",
    "            ax.imshow(data_dicts[original_set][int(index)]/255.)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_yticks([])\n",
    "            for axis in ['top','bottom','left','right']:\n",
    "                ax.spines[axis].set_linewidth(4)\n",
    "            title = 'HPC %s' % cluster_id\n",
    "            text  = []\n",
    "            if annotations is not None:\n",
    "                lines = textwrap.wrap(annotations.loc[cluster_id,'Summary'], width, break_long_words=False)\n",
    "                text.extend(['\\n%s' % s for s in lines])\n",
    "                text.append('\\n')\n",
    "                # for i in range(4-len(text)-1):\n",
    "                    # text.append('\\n')\n",
    "            ax.set_title(title, fontweight='bold', fontsize=fontsize_title)\n",
    "            ax.set_xlabel(''.join(text), fontweight='bold', fontsize=fontsize_label)\n",
    "            ax.xaxis.set_label_coords(0.5,0.075)\n",
    "\n",
    "        plt.subplots_adjust(wspace=0.05, hspace=0.2)\n",
    "        fig.tight_layout()\n",
    "        if main_cluster_path is not None:\n",
    "            plt.savefig(os.path.join(main_cluster_path, 'Tiles_annotated.png'), dpi=300)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "csv_annotations_path = '/media/adalberto/Disk2/PhD_Workspace/utilities/files/LUAD/LUAD_HPC_annotations.csv'\n",
    "csv_backtrack_path   = '/media/adalberto/Disk2/PhD_Workspace/utilities/files/LUAD/HPC_annotations/backtrack'\n",
    "annotations          = pd.read_csv(csv_annotations_path)\n",
    "annotations          = annotations.set_index('HPC')\n",
    "annotations          = annotations.replace({'other predominant tissue':'no epithelium', 'very sparse':'Very Sparse', 'severe':'Severe', 'moderate':'Moderate', 'mild':'Mild'})\n",
    "annotations          = annotations.replace({'more stroma':'More Stroma', 'more epithelium':'More Epithelium', 'no epithelium':'No Epithelium', 'roughly equal':'Roughly Equal'})\n",
    "\n",
    "annotations          = annotations.replace({'malignant epithelium':'Malignant Epithelium', 'elastosis or collagenosis':'Elastosis/Collagenosis',\n",
    "       'near-normal lung':'Near-normal Lung', 'reactive lung changes':'Reactive Lung Changes', 'necrosis':'Necrosis',\n",
    "       'other connective tissue':'Connective Tissue', 'vessels':'Vessels', 'airway':'Airway', 'cartilage':'Cartilage'})\n",
    "\n",
    "hpc_index_map = dict()\n",
    "for hpc in leiden_clusters:\n",
    "    hpc_index_map[hpc] = dict()\n",
    "    csv_path = os.path.join(csv_backtrack_path, 'set_%s_train.csv' % hpc)\n",
    "    hpc_df = pd.read_csv(csv_path)\n",
    "    x,y = annotations.loc[hpc,'Exemplar Tiles'].split(',')\n",
    "    # indexes_hpc      =  hpc_df.indexes.values.reshape((20,5))\n",
    "    # original_set_hpc =  hpc_df.original_set.values.reshape((20,5))\n",
    "    # print(hpc, x, y, indexes_hpc.shape)\n",
    "    indexes_hpc      =  hpc_df.indexes.values\n",
    "    original_set_hpc =  hpc_df.original_set.values\n",
    "    if int(y) < 5:\n",
    "        index = 20*int(y) + int(x)\n",
    "    else:\n",
    "        index = 20*int(x) + int(y)\n",
    "    selected_index = indexes_hpc[index]\n",
    "    selected_set   = original_set_hpc[index]\n",
    "    hpc_index_map[hpc]['index']        = selected_index\n",
    "    hpc_index_map[hpc]['original_set'] = selected_set\n",
    "\n",
    "fontsize_title = 24\n",
    "fontsize_label = 20\n",
    "\n",
    "leiden_clusters_order = [36, 32, 13, 3,  16, 34, 40, 31,\n",
    "                         10, 2,  4,  43, 23, 14, 22, 42,\n",
    "                         21, 0,  45, 19, 28, 15, 5,  20, \n",
    "                         8,  26, 18, 24, 37, 25, 38, 29, \n",
    "                         10, 35, 12, 27, 9,  1,  7,  27,\n",
    "                         11, 39, 6,  41, 12, 44, 17, 33,]\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "cluster_set_images(leiden_clusters_order, hpc_index_map=hpc_index_map, data_dicts=img_dicts, groupby=groupby,\n",
    "                    fontsize_title=fontsize_title, fontsize_label=fontsize_label, batches=1, ncols=8, nrows=6, figsize=(25, 27), annotations=annotations, width=17, main_cluster_path=None)\n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Figure - C-Index across resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV path to cox results.\n",
    "csv_path = '%s/results/BarlowTwins_3/TCGA_LUAD_2.016umpx_60Bkg_split4/h224_w224_n3_zdim128/v01_SOTA/OS_c_index_v01_SOTA_l1_ratio_0.0_mintiles_0.csv' % main_path\n",
    "\n",
    "# Get best mean c-index per alpha per resolution.\n",
    "results_df = pd.read_csv(csv_path)\n",
    "resolutions = results_df.resolution.unique()\n",
    "results_subset_df = results_df[results_df.alpha==1.2067926406393288]\n",
    "\n",
    "all_data = list()\n",
    "for row in results_subset_df.iterrows():\n",
    "    resolution, alpha, fold, tcga_train, tcga_test, nyu_additional = row[1].values\n",
    "    all_data.append((resolution, fold, 'TCGA Train', tcga_train))\n",
    "    all_data.append((resolution, fold, 'TCGA Test', tcga_test))\n",
    "    all_data.append((resolution, fold, 'NYU Cohort', nyu_additional))\n",
    "    \n",
    "all_data = pd.DataFrame(all_data, columns=['Resolution', 'Fold', 'Set', 'C-Index'])\n",
    "\n",
    "fontsize_labels = 14\n",
    "lw = 3\n",
    "l_box_w = 3\n",
    "\n",
    "for x_label in [ 'Resolution']:\n",
    "    sns.set_theme(style='darkgrid')\n",
    "    fig, ax = plt.subplots(figsize=(20, 7), nrows=1, ncols=1)\n",
    "    sns.pointplot(x=x_label, hue='Set', y='C-Index', data=all_data, ax=ax, dodge=.3, join=False, capsize=.00, markers='o', errorbar=('ci', 95))\n",
    "    ax.set_ylim([0.4, 0.8])\n",
    "    ax.set_title('LUAD Overall Survival', fontweight='bold', fontsize=18)\n",
    "    ax.legend(loc='upper left')\n",
    "    start, end = ax.get_ylim()\n",
    "    ax.yaxis.set_ticks(np.arange(start, end, 0.05))\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "    ax.set_ylabel('Concordance Index', fontweight='bold', size=fontsize_labels+2)\n",
    "    if x_label == 'Number HPCs':\n",
    "        ax.set_xlabel('Number of HPCs', fontweight='bold', size=fontsize_labels+2)\n",
    "    else:\n",
    "        ax.set_xlabel('Leiden Resolution Parameter', fontweight='bold', size=fontsize_labels+2)\n",
    "\n",
    "\n",
    "    legend = ax.legend_\n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(lw)\n",
    "    legend.get_frame().set_linewidth(l_box_w)\n",
    "    for i in range(len(legend.get_texts())):\n",
    "        legend.get_texts()[i].set_fontweight('bold')\n",
    "        legend.get_texts()[i].set_fontsize(fontsize_labels)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Figure - HPC Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace path.\n",
    "main_path = '/media/adalberto/Disk2/PhD_Workspace'\n",
    "\n",
    "dataset            = 'TCGAFFPE_LUADLUSC_5x_60pc'\n",
    "additional_dataset = 'NYUFFPE_survival_5x_60pc'\n",
    "\n",
    "data = Data(dataset=dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path=main_path, load=True)\n",
    "img_dicts = dict()\n",
    "img_dicts['train'] = data.training.images\n",
    "img_dicts['valid'] = data.validation.images\n",
    "img_dicts['test'] = data.test.images\n",
    "\n",
    "additional_data = Data(dataset=additional_dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path=main_path, load=True)\n",
    "additional_img_dicts = dict()\n",
    "additional_img_dicts['train'] = additional_data.training.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = load_existing_split(folds_pickle)\n",
    "dataframes, complete_df, leiden_clusters = read_csvs(adatas_path, matching_field, groupby, fold_number, folds[fold_number], h5_complete_path, h5_additional_path)\n",
    "train_df, valid_df, test_df, additional_df = dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_set_images(review_clusters, frame, data_dicts, groupby, batches=1, ncols=20, nrows=4, annotated=False, figures_path=None):\n",
    "\n",
    "    if figures_path is not None:\n",
    "        figures_path = os.path.join(figures_path, 'hpc_tile_samples')\n",
    "        if not os.path.isdir(figures_path):\n",
    "            os.makedirs(figures_path)\n",
    "\n",
    "    for cluster_id in review_clusters:\n",
    "        indexes       = frame[(frame[groupby]==cluster_id)]['indexes'].values.tolist()\n",
    "        original_sets = frame[(frame[groupby]==cluster_id)]['original_set'].values.tolist()\n",
    "        combined      = list(zip(indexes, original_sets))\n",
    "        random.shuffle(combined)\n",
    "        combined_plot = sorted(combined[:100*batches])\n",
    "\n",
    "        csv_information = list()\n",
    "        images_cluster = list()\n",
    "        for index, original_set in combined_plot:\n",
    "            images_cluster.append(data_dicts[original_set][int(index)]/255.)\n",
    "            entry_dict = frame[(frame.indexes==index)&(frame.original_set==original_set)].to_dict('index')\n",
    "            for key in entry_dict:\n",
    "                csv_information.append(entry_dict[key])\n",
    "\n",
    "        for batch in range(batches):\n",
    "            fig, axs = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "            fig.set_figheight(8)\n",
    "            fig.set_figwidth(8*(ncols/4)*0.8)\n",
    "            if annotated:\n",
    "                fig.suptitle('HPC %s - TCGA' % (cluster_id), ha='center', fontweight='bold', fontsize=65)\n",
    "            else:\n",
    "                fig.suptitle('HPC %s' % (cluster_id), ha='center', fontweight='bold', fontsize=65)\n",
    "            gs = axs[0, -4].get_gridspec()\n",
    "            # remove the underlying axes\n",
    "            for i in range(ncols-4,ncols):\n",
    "                for ax in axs[0:, i]:\n",
    "                    ax.remove()\n",
    "            axbig = fig.add_subplot(gs[0:, -4:])\n",
    "            axbig.set_xticks([])\n",
    "            axbig.set_yticks([])\n",
    "            axbig.set_yticks([])\n",
    "            axes_list = list(axs.flatten())\n",
    "            axes_list.append(axbig)\n",
    "            for ax, im in zip(axes_list, images_cluster[batch*100:(batch+1)*100]):\n",
    "                ax.imshow(im)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.set_yticks([])\n",
    "                for axis in ['top','bottom','left','right']:\n",
    "                    ax.spines[axis].set_linewidth(4)\n",
    "            plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "            fig.tight_layout()\n",
    "            if figures_path is None:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(figures_path, 'HPC_%s_TCGA_batch_%s.jpg' % (cluster_id, batch)))\n",
    "                plt.close()\n",
    "\n",
    "annotated       = True\n",
    "sns.set_theme(style='white')\n",
    "cluster_set_images(leiden_clusters, frame=train_df, data_dicts=img_dicts, groupby=groupby, batches=1, annotated=annotated, figures_path=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crosscheck_frame(hdf5_path, original_set='train'):\n",
    "    with h5py.File(hdf5_path, 'r') as content:\n",
    "        for key in content.keys():\n",
    "            if 'slides' in key:\n",
    "                slides_key = key\n",
    "            elif 'tiles' in key:\n",
    "                tiles_key = key\n",
    "        tiles  = content[tiles_key][:].astype('U13')\n",
    "        slides = content[slides_key][:].astype('U13')\n",
    "        indexes = list(range(tiles.shape[0]))\n",
    "    frame_cc = pd.DataFrame(indexes, columns=['indexes'])\n",
    "    frame_cc['tiles']  = tiles\n",
    "    frame_cc['slides'] = slides\n",
    "    frame_cc['original_set'] = original_set\n",
    "    return frame_cc\n",
    "\n",
    "def cross_check_dfs(additional_df, frame_cc, matching_fields=['slides', 'tiles']):\n",
    "    additional_df['slides'] = additional_df['slides'].astype(str)\n",
    "    additional_df['tiles']  = additional_df['tiles'].astype(str)\n",
    "    frame_cc['slides']      = frame_cc['slides'].astype(str)\n",
    "    frame_cc['tiles']       = frame_cc['tiles'].astype(str)\n",
    "    cross_checked_df = frame_cc.merge(additional_df, how='inner', left_on=matching_fields, right_on=matching_fields)\n",
    "    return cross_checked_df\n",
    "\n",
    "def cluster_set_images_add(review_clusters, frame, hdf5_path, groupby, add_cohort, img_key='img', batches=1, ncols=20, nrows=4, figures_path=None):\n",
    "\n",
    "    if figures_path is not None:\n",
    "        figures_path = os.path.join(figures_path, 'hpc_tile_samples')\n",
    "        if not os.path.isdir(figures_path):\n",
    "            os.makedirs(figures_path)\n",
    "\n",
    "    with h5py.File(hdf5_path, 'r') as content:\n",
    "\n",
    "        for key in content.keys():\n",
    "            if 'img' in key or 'images' in key:\n",
    "                img_key = key\n",
    "                break\n",
    "\n",
    "        for cluster_id in review_clusters:\n",
    "            indexes       = frame[(frame[groupby]==cluster_id)]['indexes'].values.tolist()\n",
    "            original_sets = frame[(frame[groupby]==cluster_id)]['original_set'].values.tolist()\n",
    "            combined      = list(zip(indexes, original_sets))\n",
    "            random.shuffle(combined)\n",
    "            combined_plot = sorted(combined[:100*batches])\n",
    "\n",
    "            csv_information = list()\n",
    "            images_cluster = list()\n",
    "            for index, original_set in combined_plot:\n",
    "                images_cluster.append(content[img_key][int(index)]/255.)\n",
    "                entry_dict = frame[(frame.indexes==index)&(frame.original_set==original_set)].to_dict('index')\n",
    "                for key in entry_dict:\n",
    "                    csv_information.append(entry_dict[key])\n",
    "\n",
    "\n",
    "            for batch in range(batches):\n",
    "                fig, axs = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "                fig.set_figheight(8)\n",
    "                fig.set_figwidth(8*(ncols/4)*0.8)\n",
    "                fig.suptitle('HPC %s - %s' % (cluster_id, add_cohort), ha='center', fontweight='bold', fontsize=65)\n",
    "                gs = axs[0, -4].get_gridspec()\n",
    "                # remove the underlying axes\n",
    "                for i in range(ncols-4,ncols):\n",
    "                    for ax in axs[0:, i]:\n",
    "                        ax.remove()\n",
    "                axbig = fig.add_subplot(gs[0:, -4:])\n",
    "                axbig.set_xticks([])\n",
    "                axbig.set_yticks([])\n",
    "                axbig.set_yticks([])\n",
    "                axes_list = list(axs.flatten())\n",
    "                axes_list.insert(0, axbig)\n",
    "                j = 0\n",
    "                for ax, im in zip(axes_list, images_cluster[batch*100:(batch+1)*100]):\n",
    "                    ax.imshow(im)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    for axis in ['top','bottom','left','right']:\n",
    "                        ax.spines[axis].set_linewidth(4)\n",
    "                    j += 1\n",
    "                if j != len(axes_list):\n",
    "                    for i, ax in enumerate(axes_list[j:]):\n",
    "                        ax.imshow(np.ones((224,224,3)))\n",
    "                        ax.set_xticks([])\n",
    "                        ax.set_yticks([])\n",
    "                        ax.set_yticks([])\n",
    "                        for axis in ['top','bottom','left','right']:\n",
    "                            ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "                plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "                fig.tight_layout()\n",
    "                if figures_path is None:\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    plt.savefig(os.path.join(figures_path, 'HPC_%s_%s_batch_%s.jpg' % (cluster_id, add_cohort, batch)))\n",
    "                    plt.close()\n",
    "                if j != len(axes_list): break\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "hdf5_path = '%s/datasets/NYUFFPE_survival_5x_60pc/he/patches_h224_w224/hdf5_NYUFFPE_survival_5x_60pc_he_train.h5' % main_path\n",
    "\n",
    "frame_cc       = get_crosscheck_frame(hdf5_path, original_set='additional')\n",
    "cross_check_df = cross_check_dfs(additional_df, frame_cc, matching_fields=['slides', 'tiles'])\n",
    "\n",
    "cluster_set_images_add(leiden_clusters, frame=cross_check_df, hdf5_path=hdf5_path, groupby=groupby, add_cohort='NYU', img_key='img', batches=3, figures_path=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
