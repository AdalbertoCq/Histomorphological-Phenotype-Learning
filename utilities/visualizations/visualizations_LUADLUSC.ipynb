{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from matplotlib.colors       import LinearSegmentedColormap\n",
    "from matplotlib.colors       import TwoSlopeNorm\n",
    "from skimage.transform       import resize\n",
    "from plottify                import autosize\n",
    "from sklearn                 import metrics\n",
    "from PIL                     import Image\n",
    "from adjustText              import adjust_text\n",
    "from scipy.cluster           import hierarchy\n",
    "from sklearn.metrics         import f1_score, roc_curve\n",
    "import statsmodels.api       as sm\n",
    "import matplotlib.pyplot     as plt\n",
    "import numpy                 as np\n",
    "import seaborn               as sns\n",
    "import pandas                as pd\n",
    "import scanpy                as sc\n",
    "import matplotlib\n",
    "import anndata\n",
    "import random\n",
    "import fastcluster\n",
    "import copy\n",
    "import umap\n",
    "import h5py\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Variables for data selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workspace path.\n",
    "main_path = '/media/adalberto/Disk2/PhD_Workspace'\n",
    "sys.path.append(main_path)\n",
    "from models.clustering.cox_proportional_hazard_regression_leiden_clusters import *\n",
    "from models.evaluation.folds import load_existing_split\n",
    "from models.visualization.attention_maps import *\n",
    "from models.clustering.data_processing import *\n",
    "from data_manipulation.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Image dataset variables.\n",
    "dataset            = 'TCGAFFPE_LUADLUSC_5x_60pc'\n",
    "additional_dataset = 'NYUFFPE_survival_5x_60pc'\n",
    "\n",
    "\n",
    "############# Lungsubtype\n",
    "meta_field     = 'luad'\n",
    "matching_field = 'slides'\n",
    "resolution     = 2.0\n",
    "fold_number    = 4\n",
    "groupby        = 'leiden_%s' % resolution\n",
    "meta_folder    = 'lungsubtype_nn250'\n",
    "folds_pickle   = '%s/utilities/files/LUADLUSC/lungsubtype_Institutions.pkl' % main_path\n",
    "\n",
    "# Institutions.\n",
    "inst_csv   = '%s/utilities/files/TCGA/TCGA_Institutions.csv' % main_path\n",
    "inst_frame = pd.read_csv(inst_csv)\n",
    "inst_frame = inst_frame[inst_frame['Study Name'].isin(['Lung adenocarcinoma', 'Lung squamous cell carcinoma'])]\n",
    "\n",
    "# Representations.\n",
    "h5_complete_path = '%s/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/hdf5_TCGAFFPE_LUADLUSC_5x_60pc_he_complete_lungsubtype_survival_filtered.h5' % main_path\n",
    "h5_additional_path = '%s/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/NYUFFPE_LUADLUSC_5x_60pc/h224_w224_n3_zdim128/hdf5_NYUFFPE_LUADLUSC_5x_60pc_he_combined_filtered.h5' % main_path\n",
    "\n",
    "# File name and directories.\n",
    "file_name = h5_complete_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s' % (groupby.replace('.', 'p'), fold_number)\n",
    "if h5_additional_path is not None: file_additional = h5_additional_path.split('/hdf5_')[1].split('.h5')[0] + '_%s__fold%s' % (groupby.replace('.', 'p'), fold_number)\n",
    "\n",
    "# Setup folder.\n",
    "main_cluster_path = h5_complete_path.split('hdf5_')[0]\n",
    "main_cluster_path = os.path.join(main_cluster_path, meta_folder)\n",
    "adatas_path       = os.path.join(main_cluster_path, 'adatas')\n",
    "figures_path      = os.path.join(main_cluster_path, 'figures')\n",
    "os.makedirs(figures_path, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = Data(dataset=dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path=main_path, load=True)\n",
    "img_dicts = dict()\n",
    "img_dicts['train'] = data.training.images\n",
    "img_dicts['valid'] = data.validation.images\n",
    "img_dicts['test'] = data.test.images\n",
    "\n",
    "additional_data = Data(dataset=additional_dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path=main_path, load=True)\n",
    "additional_img_dicts = dict()\n",
    "additional_img_dicts['train'] = additional_data.training.images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - Latent Space and Cluster Network - LUAD vs LUSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adata_train, h5ad_path = read_h5ad_reference(h5_complete_path, meta_folder, groupby, fold_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check if we have run PAGA to get the cluster network\n",
    "done = False\n",
    "if os.path.isfile(h5ad_path.replace('.h5ad', '_paga.h5ad')):\n",
    "    done=True\n",
    "    print('Reading PAGA H5AD')\n",
    "    adata_train = anndata.read_h5ad(h5ad_path.replace('.h5ad', '_paga.h5ad'))\n",
    "else:\n",
    "    print('Running PAGA')\n",
    "    sc.tl.paga(adata_train, groups=groupby, neighbors_key='nn_leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPC network visualization\n",
    "layout           = 'fa'  # ‘fa’, ‘fr’, ‘rt’, ‘rt_circular’, ‘drl’, ‘eq_tree’\n",
    "random_state     = 0\n",
    "threshold        = 0.29\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 25\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .05\n",
    "fontsize    = 10\n",
    "fontoutline = 2\n",
    "meta_field   = 'luad'\n",
    "\n",
    "if not done:\n",
    "    fig = plt.figure(figsize=(100,10))\n",
    "    ax  = fig.add_subplot(1, 3, 1)\n",
    "    sc.pl.paga(adata_train, layout=layout, random_state=random_state, color=meta_field, threshold=threshold, node_size_scale=node_size_scale, node_size_power=node_size_power,\n",
    "            edge_width_scale=edge_width_scale, fontsize=fontsize, fontoutline=fontoutline, frameon=False, show=False, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run UMAP based on cluster network if we have not already done so\n",
    "if not done:\n",
    "    sc.tl.umap(adata_train, init_pos=\"paga\", neighbors_key='nn_leiden')\n",
    "    adata_train.write(h5ad_path.replace('.h5ad', '_paga.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Representations and Cluster Network.\n",
    "def show_umap_leiden(adata, meta_field, layout, random_state, threshold, node_size_scale, node_size_power, edge_width_scale, directory, file_name,\n",
    "                     fontsize=10, fontoutline=2, marker_size=2, ax_size=16, l_size=12, l_t_size=14, l_box_w=1, l_markerscale=1, palette='tab20', figsize=(30,10),\n",
    "                     leiden_name=False):\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    leiden_clusters = np.unique(adata.obs[groupby].astype(int))\n",
    "    colors = sns.color_palette(palette, len(leiden_clusters))\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax  = fig.add_subplot(1, 3, 1)\n",
    "\n",
    "\n",
    "    ax = sc.pl.umap(adata, ax=ax, color=meta_field, size=marker_size, show=False, frameon=False, na_color='black')\n",
    "    if meta_field == 'luad':\n",
    "        legend_c = ax.legend(loc='best', markerscale=l_markerscale, title='Lung Type', prop={'size': l_size})\n",
    "        legend_c.get_title().set_fontsize(l_t_size)\n",
    "        legend_c.get_frame().set_linewidth(l_box_w)\n",
    "        legend_c.get_texts()[0].set_text('LUSC')\n",
    "        legend_c.get_texts()[1].set_text('LUAD')\n",
    "    ax.set_title('Tile Vector\\nRepresentations', fontsize=ax_size, fontweight='bold')\n",
    "\n",
    "    ax  = fig.add_subplot(1, 3, 2)\n",
    "    sc.pl.umap(adata, ax=ax, color=groupby, size=marker_size, show=False, legend_loc='on data', legend_fontsize=fontsize, legend_fontoutline=fontoutline, frameon=False, palette=colors)\n",
    "    if leiden_name:\n",
    "        ax.set_title('Leiden Clusters', fontsize=ax_size, fontweight='bold')\n",
    "    else:\n",
    "        ax.set_title('Histomorphological Phenotype\\nClusters', fontsize=ax_size, fontweight='bold')\n",
    "\n",
    "    adjust_text(ax.texts)\n",
    "\n",
    "    ax  = fig.add_subplot(1, 3, 3)\n",
    "    names_lines  = ['LUSC', 'LUAD']\n",
    "    sc.pl.paga(adata, layout=layout, random_state=random_state, color=meta_field, threshold=threshold, node_size_scale=node_size_scale, node_size_power=node_size_power, edge_width_scale=edge_width_scale, fontsize=fontsize, fontoutline=fontoutline, frameon=False, show=False, ax=ax)\n",
    "    if meta_field == 'luad':\n",
    "        legend = ax.legend(legend_c.legendHandles, names_lines, title='Lung Type', loc='upper left', prop={'size': l_size})\n",
    "        legend.get_title().set_fontsize(l_t_size)\n",
    "        legend.get_frame().set_linewidth(l_box_w)\n",
    "    if leiden_name:\n",
    "        ax.set_title('Leiden Cluster Network', fontsize=ax_size, fontweight='bold')\n",
    "    else:\n",
    "        ax.set_title('Histomorphological Phenotype\\nCluster Network', fontsize=ax_size, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(directory,file_name))\n",
    "    plt.show()\n",
    "\n",
    "def plot_umaps(data_df, x, y, hue, scatter_size, palette, figsize, fontsize_labels, fontsize_legend, l_box_w):\n",
    "    fig   = plt.figure(figsize=figsize)\n",
    "    ax    = fig.add_subplot(1, 1, 1)\n",
    "    plot = sns.scatterplot(data=data_df, x=x, y=y, hue=hue, s=scatter_size, ax=ax, palette=palette)\n",
    "\n",
    "    h,l = plot.get_legend_handles_labels()\n",
    "    plot.legend_.remove()\n",
    "    legend = fig.legend(h,l, ncol=2, bbox_to_anchor=(1.17, 0.9), title=r'$\\bf{TCGA\\ Institution\\ Code}$', prop={'weight':'bold'})\n",
    "\n",
    "    legend.get_title().set_fontsize(fontsize_legend)\n",
    "    legend.get_frame().set_linewidth(l_box_w)\n",
    "\n",
    "    ax.set_xlabel('UMAP Dim. 0', fontsize=fontsize_labels, fontweight='bold')\n",
    "    ax.set_ylabel('UMAP Dim. 1', fontsize=fontsize_labels, fontweight='bold')\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(4)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Graph visualization related\n",
    "layout           = 'fa'  # ‘fa’, ‘fr’, ‘rt’, ‘rt_circular’, ‘drl’, ‘eq_tree’\n",
    "random_state     = 0\n",
    "threshold        = 0.29\n",
    "\n",
    "# Figure related\n",
    "node_size_scale  = 25\n",
    "node_size_power  = 0.5\n",
    "edge_width_scale = .05\n",
    "\n",
    "meta_field = 'luad'\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "show_umap_leiden(adata_train, meta_field, layout, random_state, threshold, node_size_scale, node_size_power, edge_width_scale, directory=figures_path,\n",
    "                 file_name=file_name + '_clusternetwork_all_anno.jpg', fontsize=25, fontoutline=10, marker_size=5, ax_size=62, l_size=50, l_t_size=55, l_box_w=4,\n",
    "                 l_markerscale=6, palette='tab20', figsize=(50,20))\n",
    "\n",
    "meta_field = None\n",
    "show_umap_leiden(adata_train, meta_field, layout, random_state, threshold, node_size_scale, node_size_power, edge_width_scale, directory=figures_path,\n",
    "                 file_name=file_name + '_clusternetwork_all_anno.jpg', fontsize=25, fontoutline=10, marker_size=5, ax_size=62, l_size=50, l_t_size=55, l_box_w=4,\n",
    "                 l_markerscale=6, palette='tab20', figsize=(50,20))\n",
    "show_umap_leiden(adata_train, meta_field, layout, random_state, threshold, node_size_scale, node_size_power, edge_width_scale, directory=figures_path,\n",
    "                 file_name=file_name + '_clusternetwork_all_anno.jpg', fontsize=25, fontoutline=10, marker_size=5, ax_size=62, l_size=50, l_t_size=55, l_box_w=4,\n",
    "                 l_markerscale=6, palette='tab20', figsize=(50,20), leiden_name=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - Clustermap Slides vs Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frames = build_cohort_representations(meta_folder, meta_field, matching_field, groupby, fold_number, folds_pickle, h5_complete_path, h5_additional_path, 'percent', 100)\n",
    "complete_df, additional_complete_df, frame_clusters, frame_samples, features = frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clustermap_representations(features, complete_df, frame_clusters, method_slides, metric_slides, figsize, fontsize_labels, fontsize_ticks, dendrogram_ratio):\n",
    "    slide_rep_df = complete_df.iloc[1:].copy(deep=True)\n",
    "\n",
    "    # Row and Columns colors\n",
    "    row_lut = dict(zip(np.unique(slide_rep_df[meta_field]), ['blue', 'orange']))\n",
    "    row_colors = pd.Series(slide_rep_df[meta_field].map(row_lut), name='LUSC/LUAD\\nWSI\\n')\n",
    "\n",
    "    purity_color_map = LinearSegmentedColormap.from_list('cluster_purity', ['blue','orange'])\n",
    "    purities = [purity if flag else 100-purity for purity, flag in zip(frame_clusters['Subtype Purity(%)'], frame_clusters[meta_field])]\n",
    "    col_colors = pd.Series([matplotlib.colors.to_hex(purity_color_map(perc/100)) for perc in purities], name='HPC\\nLUSC/LUAD\\nPurity\\n')\n",
    "\n",
    "    g = sns.clustermap(slide_rep_df[features].astype(float)*100, vmin=0, vmax=100, row_colors=row_colors, col_colors=col_colors, col_linkage=None, row_linkage=None, method=method_slides, metric=metric_slides, cmap='rocket_r', figsize=figsize, dendrogram_ratio=dendrogram_ratio, tree_kws=dict(linewidths=3.0))\n",
    "\n",
    "    # X ticks and labels\n",
    "    g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xmajorticklabels(), fontsize=fontsize_ticks)\n",
    "    g.ax_heatmap.set_xlabel('HPC', fontsize=fontsize_labels)\n",
    "    # Y ticks and labels\n",
    "    g.ax_heatmap.set_ylabel('Whole Slide Image (WSI)',   fontsize=fontsize_labels)\n",
    "    g.ax_heatmap.set_yticks([])\n",
    "    # Row color labels\n",
    "    g.ax_row_colors.tick_params(axis='both', length=0)\n",
    "    g.ax_row_colors.tick_params(axis='x', which='major', labelsize=fontsize_labels)\n",
    "    # Column color labels\n",
    "    g.ax_col_colors.tick_params(axis='both', length=0)\n",
    "    g.ax_col_colors.tick_params(axis='y', which='major', labelsize=fontsize_labels)\n",
    "    g.ax_cbar.tick_params(labelsize=fontsize_ticks)\n",
    "\n",
    "    [label.set_fontweight('bold') for label in g.ax_col_colors.get_yticklabels()]\n",
    "    [label.set_fontweight('bold') for label in g.ax_row_colors.get_xticklabels()]\n",
    "    [label.set_fontweight('bold') for label in g.ax_cbar.get_yticklabels()]\n",
    "\n",
    "    for sel_ax in [g.ax_heatmap]:\n",
    "        for ticks in [sel_ax.xaxis.get_major_ticks(), sel_ax.yaxis.get_major_ticks()]:\n",
    "            for tick in ticks:\n",
    "                tick.label1.set_fontsize(fontsize_ticks)\n",
    "                tick.label1.set_fontweight('bold')\n",
    "\n",
    "    g.ax_heatmap.set_xlabel('Histomorphological Phenotype Cluster (HPC)', fontsize=fontsize_labels, fontweight='bold')\n",
    "    g.ax_heatmap.set_ylabel('Whole Slide Image (WSI)',   fontsize=fontsize_labels, fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "method_slides = 'ward'\n",
    "metric_slides = 'correlation'\n",
    "sns.set_theme(style='white')\n",
    "clustermap_representations(features, complete_df, frame_clusters, method_slides, metric_slides, figsize=(35,25), fontsize_labels=50, fontsize_ticks=27, dendrogram_ratio=(0.1,0.2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - Slide representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_data = build_cohort_representations(meta_folder, meta_field, matching_field, groupby, fold_number, folds_pickle, h5_complete_path, None,\n",
    "                                        type_composition='percent', min_tiles=100, use_conn=False, use_ratio=False, top_variance_feat=0, reduction=2)\n",
    "\n",
    "complete_df, additional_complete_df, frame_clusters, frame_samples, features = all_data\n",
    "\n",
    "fontsize_title = 25\n",
    "fontsize_y     = 20\n",
    "fontsize       = 13\n",
    "\n",
    "slides_heatmap = ['TCGA-33-4532-01Z-00-DX2', 'TCGA-33-4532-01Z-00-DX3'] + complete_df.slides.values.tolist()[130:139]\n",
    "heatmap_df = complete_df[complete_df.slides.isin(slides_heatmap)][['slides']+features]\n",
    "heatmap_df = heatmap_df.set_index('slides')\n",
    "heatmap_df = heatmap_df*100\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "fig, ax_dict = plt.subplots(11,1, figsize=(20,10))\n",
    "flag = True\n",
    "for i, slide in enumerate(heatmap_df.index):\n",
    "    if i==10:\n",
    "        flag = False\n",
    "    elif i==9:\n",
    "        ax = sns.heatmap(heatmap_df.loc[slide].values.astype(int).reshape(1,-1), vmin=0, vmax=100, linecolor='black', annot=False, linewidths=1, cmap='rocket_r', ax=ax_dict[i], cbar_ax=ax_dict[i+1], cbar_kws={\"orientation\": \"horizontal\"})\n",
    "    else:\n",
    "        ax = sns.heatmap(heatmap_df.loc[slide].values.astype(int).reshape(1,-1), vmin=0, vmax=100, linecolor='black', annot=False, linewidths=1, cmap='rocket_r', ax=ax_dict[i], cbar=False)\n",
    "\n",
    "    if flag:\n",
    "        if i==0:\n",
    "            ax_dict[i].set_title('WSI HPC % Contribution', fontsize=fontsize_title, fontweight='bold', y=1.5)\n",
    "            ax_dict[i].xaxis.set_tick_params(labeltop='on', labelbottom=False)\n",
    "            ax_dict[i].tick_params('both', length=0, width=0, which='major')\n",
    "            labels = [item.get_text() for item in ax_dict[i].get_xticklabels()]\n",
    "            ax_dict[i].set_xticklabels(labels, fontsize=fontsize, fontweight='bold')\n",
    "            slide += ' '\n",
    "        else:\n",
    "            ax_dict[i].set_xticks([])\n",
    "        ax_dict[i].set_yticklabels([slide], fontsize=fontsize_y, fontweight='bold', rotation=0, ha='right')\n",
    "\n",
    "    for tick in ax_dict[i].xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax_dict[i].yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_y)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax_dict[i].spines[axis].set_linewidth(4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - UMAP WSI vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frames = build_cohort_representations(meta_folder, meta_field, matching_field, groupby, fold_number, folds_pickle, h5_complete_path, h5_additional_path, 'clr', 100)\n",
    "complete_df, additional_complete_df, frame_clusters, frame_samples, features = frames\n",
    "\n",
    "labels = complete_df.to_numpy()[1:,-1]\n",
    "data   = complete_df.to_numpy()[1:,2:-1]\n",
    "\n",
    "labels_add = additional_complete_df.to_numpy()[1:,-1]\n",
    "data_add   = additional_complete_df.to_numpy()[1:,2:-1]\n",
    "\n",
    "columns = [col for col in complete_df.columns if col != 'luad' and col != 'samples' and col != 'slides']\n",
    "\n",
    "labels = complete_df.to_numpy()[1:,-1]\n",
    "data   = complete_df.to_numpy()[1:,2:-1]\n",
    "df     = pd.DataFrame(data, columns=columns)\n",
    "df['Lung Type'] = labels\n",
    "df['Cohort']       = 'TCGA'\n",
    "\n",
    "labels_add = additional_complete_df.to_numpy()[1:,-1]\n",
    "data_add   = additional_complete_df.to_numpy()[1:,1:-1]\n",
    "df_add     = pd.DataFrame(data_add, columns=columns)\n",
    "df_add['Lung Type'] = labels_add\n",
    "df_add['Cohort']       = 'NYU'\n",
    "\n",
    "df_all = pd.concat([df, df_add], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scatter_size    = 300\n",
    "\n",
    "figsize         = (50,20)\n",
    "fontsize_labels = 60\n",
    "fontsize_legend = 60\n",
    "l_markerscale   = 10\n",
    "l_box_w         = 3\n",
    "lw              = 5\n",
    "\n",
    "min_dist     = 0.0\n",
    "n_components = 2\n",
    "n_neighbors  = 25\n",
    "metric       = 'euclidean'\n",
    "\n",
    "print(metric, n_neighbors)\n",
    "# UMAP\n",
    "fit = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, metric=metric)\n",
    "u   = fit.fit_transform(df_all[columns])\n",
    "df_all['UMAP Dim. 0'] = u[:, 0]\n",
    "df_all['UMAP Dim. 1'] = u[:, 1]\n",
    "\n",
    "fig   = plt.figure(figsize=figsize)\n",
    "ax    = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "# Scatter plot.\n",
    "sns.scatterplot(data=df_all[df_all.Cohort=='TCGA'], x='UMAP Dim. 0', y='UMAP Dim. 1', hue='Lung Type', s=scatter_size, ax=ax)\n",
    "ax.set_xlabel('UMAP Dim. 0', fontsize=fontsize_labels)\n",
    "ax.set_ylabel('UMAP Dim. 1', fontsize=fontsize_labels)\n",
    "ax.set_title('TCGA Cohort',  fontsize=fontsize_labels, fontweight='bold')\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize_labels-25)\n",
    "legend = ax.legend(loc='lower right', title='Lung Type', markerscale=l_markerscale, prop={'size': fontsize_legend-5})\n",
    "legend.get_title().set_fontsize(fontsize_legend)\n",
    "legend.get_texts()[0].set_text('LUSC')\n",
    "legend.get_texts()[1].set_text('LUAD')\n",
    "legend.get_frame().set_linewidth(l_box_w)\n",
    "\n",
    "ax    = fig.add_subplot(1, 2, 2)\n",
    "sns.scatterplot(data=df_all[df_all.Cohort=='TCGA'], x='UMAP Dim. 0', y='UMAP Dim. 1', color='grey',    s=scatter_size/4, ax=ax)\n",
    "sns.scatterplot(data=df_all[df_all.Cohort=='NYU'],  x='UMAP Dim. 0', y='UMAP Dim. 1', hue='Lung Type', s=scatter_size,   ax=ax)\n",
    "ax.set_xlabel('UMAP Dim. 0', fontsize=fontsize_labels)\n",
    "ax.set_ylabel('UMAP Dim. 1', fontsize=fontsize_labels)\n",
    "ax.set_title('NYU Cohort',  fontsize=fontsize_labels, fontweight='bold')\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize_labels-25)\n",
    "legend = ax.legend(loc='lower right', title='Lung Type', markerscale=l_markerscale, prop={'size': fontsize_legend-5})\n",
    "legend.get_title().set_fontsize(fontsize_legend)\n",
    "legend.get_texts()[0].set_text('LUSC')\n",
    "legend.get_texts()[1].set_text('LUAD')\n",
    "legend.get_frame().set_linewidth(l_box_w)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scatter_size    = 2000\n",
    "\n",
    "figsize         = (20,20)\n",
    "fontsize_labels = 60\n",
    "fontsize_legend = 60\n",
    "l_markerscale   = 10\n",
    "l_box_w         = 3\n",
    "lw              = 5\n",
    "\n",
    "min_dist     = 0.0\n",
    "n_components = 2\n",
    "n_neighbors  = 25\n",
    "metric       = 'euclidean'\n",
    "\n",
    "print(metric, n_neighbors)\n",
    "# UMAP\n",
    "fit = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, metric=metric)\n",
    "u   = fit.fit_transform(df_all[columns])\n",
    "df_all['UMAP Dim. 0'] = u[:, 0]\n",
    "df_all['UMAP Dim. 1'] = u[:, 1]\n",
    "\n",
    "fig   = plt.figure(figsize=figsize)\n",
    "ax    = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# Scatter plot.\n",
    "sns.scatterplot(data=df_all, x='UMAP Dim. 0', y='UMAP Dim. 1', hue='Lung Type', style='Cohort', markers={'TCGA':'v', 'NYU':'s'}, s=scatter_size, ax=ax)\n",
    "ax.set_xlabel('UMAP Dim. 0', fontsize=fontsize_labels)\n",
    "ax.set_ylabel('UMAP Dim. 1', fontsize=fontsize_labels)\n",
    "ax.set_title('Whole Slide Image\\nVector Representations',  fontsize=fontsize_labels, fontweight='bold')\n",
    "ax.tick_params(axis='both', which='major', labelsize=fontsize_labels)\n",
    "legend = ax.legend(loc='upper left', markerscale=l_markerscale, prop={'size': fontsize_legend-5}, ncol=2)\n",
    "legend.get_texts()[1].set_text('LUSC')\n",
    "legend.get_texts()[2].set_text('LUAD')\n",
    "legend.get_texts()[0].set_size(fontsize_legend)\n",
    "legend.get_texts()[3].set_size(fontsize_legend)\n",
    "legend.get_frame().set_linewidth(l_box_w)\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "\n",
    "ax.set_xlabel('UMAP Dim. 0', fontsize=fontsize_labels, fontweight='bold')\n",
    "ax.set_ylabel('UMAP Dim. 1', fontsize=fontsize_labels, fontweight='bold')\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - ROC curve - Institutions & Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Label & LR penalty.\n",
    "label = 1\n",
    "alpha = 10.0\n",
    "\n",
    "# Institutions.\n",
    "replace_dict = {'Ontario Institute for Cancer Research (OICR)':'Ontario Institute for Cancer Research',\n",
    "                'Ontario Institute for Cancer Research (OICR)/Ottawa':'Ontario Institute for Cancer Research',\n",
    "                'St Joseph\\'s Medical Center (MD)': 'St. Joseph\\'s Medical Center (MD)',\n",
    "                'Fox Chase':'Fox Chase Cancer Center'}\n",
    "\n",
    "inst_csv   = '%s/utilities/files/TCGA/TCGA_Institutions.csv' % main_path\n",
    "inst_frame = pd.read_csv(inst_csv)\n",
    "inst_frame = inst_frame[inst_frame['Study Name'].isin(['Lung adenocarcinoma', 'Lung squamous cell carcinoma'])][['TSS Code', 'Source Site']]\n",
    "inst_frame['Source Site'] = inst_frame['Source Site'].replace(replace_dict)\n",
    "inst_frame['TSS Code']    = inst_frame['TSS Code'].replace({'1':'01','2':'02','3':'03','4':'04','5':'05', '6':'06','7':'07','8':'08','9':'09'})\n",
    "\n",
    "folds_pickle = '/media/adalberto/Disk2/PhD_Workspace/utilities/files/LUADLUSC/lungsubtype_Institutions.pkl'\n",
    "h5_complete_path = '/media/adalberto/Disk2/PhD_Workspace/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/hdf5_TCGAFFPE_LUADLUSC_5x_60pc_he_complete_lungsubtype_survival_filtered.h5'\n",
    "h5_additional_path = '/media/adalberto/Disk2/PhD_Workspace/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/NYUFFPE_LUADLUSC_5x_60pc/h224_w224_n3_zdim128/hdf5_NYUFFPE_LUADLUSC_5x_60pc_he_combined_filtered.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get folds from existing split.\n",
    "folds = load_existing_split(folds_pickle)\n",
    "\n",
    "# Path for alpha Logistic Regression results.\n",
    "main_cluster_path = h5_complete_path.split('hdf5_')[0]\n",
    "main_cluster_path = os.path.join(main_cluster_path, meta_folder)\n",
    "adatas_path       = os.path.join(main_cluster_path, 'adatas')\n",
    "\n",
    "data_res_folds = dict()\n",
    "data_res_folds[resolution] = dict()\n",
    "for i, fold in enumerate(folds):\n",
    "    # Read CSV files for train, validation, test, and additional sets.\n",
    "    dataframes, complete_df, leiden_clusters = read_csvs(adatas_path, matching_field, groupby, i, fold, h5_complete_path, h5_additional_path, additional_as_fold=False, force_fold=fold_number)\n",
    "    train_df, valid_df, test_df, additional_df = dataframes\n",
    "\n",
    "    # Check clusters and diversity within.\n",
    "    frame_clusters, frame_samples = create_frames(train_df, groupby, meta_field, diversity_key=matching_field, reduction=2)\n",
    "\n",
    "    # Create representations per sample: cluster % of total sample.\n",
    "    data, data_df, features = prepare_data_classes(dataframes, matching_field, meta_field, groupby, leiden_clusters, 'clr', 100, use_conn=False, use_ratio=False, top_variance_feat=0)\n",
    "\n",
    "    # Insert institutions.\n",
    "    data_dfs = list()\n",
    "    for dataframe in data_df:\n",
    "        sample_slide = dataframe['slides'].values[0]\n",
    "        if dataframe is not None and 'TCGA' in str(sample_slide):\n",
    "            dataframe.insert(0, 'TSS Code', dataframe['slides'].apply(lambda x: x.split('-')[1]))\n",
    "            dataframe = pd.merge(dataframe, inst_frame, on='TSS Code', how='left')\n",
    "        data_dfs.append(dataframe)\n",
    "\n",
    "    # Include features that are not the regular leiden clusters.\n",
    "    frame_clusters = include_features_frame_clusters(frame_clusters, leiden_clusters, features, groupby)\n",
    "\n",
    "    # Store representations.\n",
    "    data_res_folds[resolution][i] = {'data':data, 'data_df':data_dfs, 'complete_df':complete_df, 'features':features, 'frame_clusters':frame_clusters, 'leiden_clusters':leiden_clusters}\n",
    "\n",
    "    # Information.\n",
    "    print('\\t\\tFold', i, 'Features:', len(features), 'Clusters:', len(leiden_clusters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folds_roc = dict()\n",
    "folds_roc['test'] = dict()\n",
    "if h5_additional_path is not None:\n",
    "    folds_roc['additional'] = dict()\n",
    "for i, fold in enumerate(folds):\n",
    "    # Load data for classification.\n",
    "    data            = data_res_folds[resolution][i]['data']\n",
    "    data_df         = data_res_folds[resolution][i]['data_df']\n",
    "    features        = data_res_folds[resolution][i]['features']\n",
    "    frame_clusters  = data_res_folds[resolution][i]['frame_clusters']\n",
    "    leiden_clusters = data_res_folds[resolution][i]['leiden_clusters']\n",
    "\n",
    "    train,    valid,    test,    additional    = data\n",
    "    train_df, valid_df, test_df, additional_df = data_df\n",
    "    train_data, train_labels = train\n",
    "\n",
    "    # One-vs-rest for Logistic Regression.\n",
    "    model = sm.Logit(endog=train_labels[:,label], exog=train_data).fit_regularized(method='l1', alpha=alpha, disp=0)\n",
    "\n",
    "    train, valid, test, additional = data\n",
    "    train_data, train_labels = train\n",
    "    valid_data, valid_labels = valid\n",
    "    test_data,  test_labels  = test\n",
    "    if additional is not None:\n",
    "        additional_data, additional_labels = additional\n",
    "\n",
    "    # Predictions.\n",
    "    train_pred = model.predict(exog=train_data)\n",
    "    valid_pred = model.predict(exog=valid_data)\n",
    "    test_pred  = model.predict(exog=test_data)\n",
    "    train_df['predictions'] = train_pred\n",
    "    valid_df['predictions'] = valid_pred\n",
    "    test_df['predictions']  = test_pred\n",
    "\n",
    "    if additional is not None:\n",
    "        additional_pred = model.predict(exog=additional_data)\n",
    "        additional_df['predictions']  = additional_pred\n",
    "    data_res_folds[resolution][i]['data_df'] = [train_df, valid_df, test_df, additional_df]\n",
    "\n",
    "    folds_roc['test'][i] = dict()\n",
    "    fpr, tpr, thresholds = roc_curve(list(test_labels[:,label]), list(test_pred))\n",
    "    f1_score_            = f1_score(list(test_labels[:,label]), list(test_pred>0.5), average='weighted')\n",
    "    folds_roc['test'][i]['fpr'] = fpr\n",
    "    folds_roc['test'][i]['tpr'] = tpr\n",
    "    folds_roc['test'][i]['f1_score'] = f1_score_\n",
    "\n",
    "    if additional is not None:\n",
    "        folds_roc['additional'][i] = dict()\n",
    "        fpr, tpr, thresholds = roc_curve(list(additional_labels[:,label]), list(additional_pred))\n",
    "        f1_score_            = f1_score(list(additional_labels[:,label]), list(additional_pred>0.5), average='weighted')\n",
    "        folds_roc['additional'][i]['fpr'] = fpr\n",
    "        folds_roc['additional'][i]['tpr'] = tpr\n",
    "        folds_roc['additional'][i]['f1_score'] = f1_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if 'TSS Code' not in complete_df.columns:\n",
    "    complete_df.insert(0, 'TSS Code', complete_df['slides'].apply(lambda x: x.split('-')[1]))\n",
    "    complete_df = pd.merge(complete_df, inst_frame, on='TSS Code', how='left')\n",
    "complete_df['Source Site'] = complete_df['Source Site'].replace({'Mary Bird Perkins Cancer Center - Our Lady of the Lake':'Mary Bird Perkins Cancer Center', 'Thoraxklinik at University Hospital Heidelberg':'University Hospital Heidelberg'})\n",
    "a, frame_samples = cluster_diversity(complete_df, frame_clusters, groupby, diversity_key='Source Site')\n",
    "frame_samples    = frame_samples[[groupby, 'Source Site', 'Purity (%)', 'Counts']]\n",
    "frame_samples['Purity (%)'] = frame_samples['Purity (%)']/100\n",
    "frame_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Figure - ROCAUC/F1-Score Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auc(ax, fold, title, lw, fontsize_labels, fontsize_legend, l_box_w, f1_score=False):\n",
    "    aucs = list()\n",
    "    for i in range(5):\n",
    "        if f1_score:\n",
    "            metric = fold[i]['f1_score']\n",
    "            label = \" Fold %s F1-Score = %0.3f\" % (i, metric)\n",
    "            fig_title = '%s\\nF1-Score ' % title\n",
    "        else:\n",
    "            metric = auc(fold[i]['fpr'], fold[i]['tpr'])\n",
    "            label = \" Fold %s AUC = %0.3f\" % (i, metric)\n",
    "            fig_title = '%s\\nAUC ' % title\n",
    "        aucs.append(metric)\n",
    "        ax.plot(fold[i]['fpr'], fold[i]['tpr'], lw=lw, label=label)\n",
    "\n",
    "    mean, minus, plus = mean_confidence_interval(aucs, confidence=0.95)\n",
    "    legend = ax.legend(loc='lower right', title='Mean (CI): %s (%s-%s)' % ( np.round(mean, 3), np.round(minus, 3), np.round(plus, 3)), prop={'size': fontsize_legend-4, 'weight':'bold'})\n",
    "    legend.get_title().set_fontsize(fontsize_legend)\n",
    "    legend.get_title().set_fontweight('bold')\n",
    "    # set the linewidth of each legend object\n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(lw)\n",
    "    legend.get_frame().set_linewidth(l_box_w)\n",
    "\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "\n",
    "    ax.set_title(fig_title,  fontsize=fontsize_labels*1.2, fontweight='bold')\n",
    "    ax.set_ylabel('True Positive Rate',  fontsize=fontsize_labels, fontweight='bold')\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=fontsize_labels, fontweight='bold')\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "\n",
    "figsize    = (20,20)\n",
    "fontsize_labels = 60\n",
    "fontsize_legend = 60\n",
    "l_box_w         = 3\n",
    "lw              = 5\n",
    "\n",
    "for flag in [True, False]:\n",
    "    fig   = plt.figure(figsize=figsize)\n",
    "    ax    = fig.add_subplot(1, 1, 1)\n",
    "    title = 'TCGA Cohort'\n",
    "    plot_auc(ax, folds_roc['test'], title, lw, fontsize_labels, fontsize_legend, l_box_w, f1_score=flag)\n",
    "    plt.show()\n",
    "\n",
    "    fig   = plt.figure(figsize=figsize)\n",
    "    ax    = fig.add_subplot(1, 1, 1)\n",
    "    title = 'NYU Cohort'\n",
    "    plot_auc(ax, folds_roc['additional'], title, lw, fontsize_labels, fontsize_legend, l_box_w, f1_score=flag)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_replacements = {'Mary Bird Perkins Cancer Center - Our Lady of the Lake':'Mary Bird Perkins Cancer Center', 'Thoraxklinik at University Hospital Heidelberg':'University Hospital Heidelberg'}\n",
    "\n",
    "data = list()\n",
    "institutions_roc = dict()\n",
    "for i, fold in enumerate(folds):\n",
    "    train_df, valid_df, test_df, additional_df = data_res_folds[resolution][i]['data_df']\n",
    "    test_df['Source Site'] = test_df['Source Site'].replace(naming_replacements)\n",
    "    for institution in np.unique(test_df['Source Site']):\n",
    "        test_inst_df = test_df[test_df['Source Site']==institution].copy(deep=True)\n",
    "\n",
    "        test_labels = test_inst_df[meta_field].values.tolist()\n",
    "        test_pred   = test_inst_df['predictions'].values.tolist()\n",
    "\n",
    "        samples = len(test_labels)\n",
    "\n",
    "        fpr = None\n",
    "        tpr = None\n",
    "        thresholds = None\n",
    "        roc_auc = None\n",
    "\n",
    "        if len(np.unique(test_labels)) != 1:\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(test_labels, test_pred)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        institutions_roc[institution] = [fpr, tpr, thresholds, roc_auc, samples]\n",
    "        data.append((institution, roc_auc, samples, i))\n",
    "\n",
    "data = pd.DataFrame(data, columns=['Institution', 'AUC', 'Sample Size', 'Fold'])\n",
    "data = data.sort_values(by='Sample Size', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Paper Figure - Insitutions per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "work_df = complete_df.copy(deep=True)\n",
    "work_df['Weight'] = 1\n",
    "site_distribution           = work_df[['Weight', 'Source Site']].groupby('Source Site').count()\n",
    "site_distribution['Weight'] = site_distribution['Weight']/site_distribution['Weight'].sum()\n",
    "site_distribution['Group'] = 'All Institutions'\n",
    "site_distribution = site_distribution.reset_index()\n",
    "site_distribution = site_distribution.sort_values(by='Source Site', ascending=False)\n",
    "\n",
    "\n",
    "figsize = (50, 20)\n",
    "fontsize_labels = 38\n",
    "fontsize_ticks  = 33\n",
    "rotation        = 45\n",
    "\n",
    "subsampled = sorted(np.random.choice(leiden_clusters, size=12, replace=False))\n",
    "\n",
    "plotted = 0\n",
    "while plotted < len(subsampled):\n",
    "    f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, sharey=True, sharex=True, figsize=figsize)\n",
    "\n",
    "    frame_samples = frame_samples.sort_values(by='Source Site')\n",
    "    for i, ax in  enumerate((ax2, ax3, ax4, ax5)):\n",
    "        if plotted >= len(leiden_clusters.tolist()):\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['bottom'].set_visible(False)\n",
    "            ax.spines['left'].set_visible(False)\n",
    "            ax.yaxis.label.set_visible(False)\n",
    "            ax.xaxis.label.set_visible(False)\n",
    "            ax.get_xaxis().set_ticks([])\n",
    "        else:\n",
    "            ratio = complete_df[complete_df[groupby]==subsampled[plotted]].shape[0]/complete_df.shape[0]*100\n",
    "            ax.set_title('HPC %s\\n%s%s of entire\\npopulation' % (subsampled[plotted],np.round(ratio,1), '%'),  fontsize=fontsize_labels*1.2, fontweight='bold')\n",
    "            work_samples_df = frame_samples[frame_samples[groupby]==subsampled[plotted]]\n",
    "            sns.barplot(y='Source Site', x='Purity (%)', data=work_samples_df, ax=ax, palette='tab20')\n",
    "            ax.yaxis.label.set_visible(False)\n",
    "            plotted += 1\n",
    "\n",
    "    for ax in (ax1, ax2, ax3, ax4, ax5):\n",
    "        ax.set_xlim([0.0, frame_samples['Purity (%)'].max()+0.05])\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_ticks)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "            tick.label1.set_rotation(rotation)\n",
    "        for tick in ax1.yaxis.get_major_ticks():\n",
    "            tick.label1.set_fontsize(fontsize_ticks)\n",
    "            tick.label1.set_fontweight('bold')\n",
    "\n",
    "        ax.set_ylabel('Institution',            fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "        ax.set_xlabel('Institution percentage', fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "    sns.barplot(y='Source Site', x='Weight', data=site_distribution, ax=ax1, palette='tab20')\n",
    "    ax1.set_title('Entire\\npopulation',      fontsize=fontsize_labels*1.2, fontweight='bold')\n",
    "    ax1.set_ylabel('Institution',            fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "    ax1.set_xlabel('Institution percentage', fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Paper Figure - ROC Insitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "naming_replacements = {'Mary Bird Perkins Cancer Center - Our Lady of the Lake':'Mary Bird Perkins Cancer Center', 'Thoraxklinik at University Hospital Heidelberg':'University Hospital Heidelberg'}\n",
    "\n",
    "data = list()\n",
    "data_f = list()\n",
    "institutions_roc = dict()\n",
    "for i, fold in enumerate(folds):\n",
    "    train_df, valid_df, test_df, additional_df = data_res_folds[resolution][i]['data_df']\n",
    "    test_df['Source Site'] = test_df['Source Site'].replace(naming_replacements)\n",
    "    for institution in np.unique(test_df['Source Site']):\n",
    "        test_inst_df = test_df[test_df['Source Site']==institution].copy(deep=True)\n",
    "\n",
    "        test_labels = test_inst_df[meta_field].values.tolist()\n",
    "        test_pred   = test_inst_df['predictions'].values.tolist()\n",
    "\n",
    "        samples = len(test_labels)\n",
    "        values, counts = np.unique(test_inst_df[meta_field], return_counts=True)\n",
    "        luad_samples = 0\n",
    "        lusc_samples = 0\n",
    "        for j, value in enumerate(values):\n",
    "            if value == 0:\n",
    "                lusc_samples = counts[j]\n",
    "            else:\n",
    "                luad_samples = counts[j]\n",
    "        \n",
    "        fpr = None\n",
    "        tpr = None\n",
    "        thresholds = None\n",
    "        roc_auc = None\n",
    "\n",
    "        if len(np.unique(test_labels)) != 1:\n",
    "            fpr, tpr, thresholds = roc_curve(test_labels, test_pred)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        institutions_roc[institution] = [fpr, tpr, thresholds, roc_auc, samples]\n",
    "        data.append((institution, roc_auc, samples, lusc_samples, luad_samples, i))\n",
    "        data_f.append((institution, roc_auc, lusc_samples, 'LUSC', i))\n",
    "        data_f.append((institution, roc_auc, luad_samples, 'LUAD', i))\n",
    "        \n",
    "data = pd.DataFrame(data, columns=['Institution', 'AUC', 'Sample Size', 'Sample Size LUSC', 'Sample Size LUAD', 'Fold'])\n",
    "data = data.sort_values(by='Sample Size', ascending=False)\n",
    "\n",
    "data_f = pd.DataFrame(data_f, columns=['Institution', 'AUC', 'Sample Size', 'Subtype', 'Fold'])\n",
    "data_f = data_f.sort_values(by='AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['Institution'] = data['Institution'].replace(naming_replacements)\n",
    "data = data.sort_values(by='AUC', ascending=False)\n",
    "# data = data[~data['AUC'].isna()]\n",
    "figsize = (70, 27)\n",
    "fontsize_labels = 45\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True, figsize=figsize)\n",
    "sns.barplot(y='Institution', x='AUC', data=data, ax=ax1, palette='tab20')\n",
    "ax1.xaxis.set_ticks(np.arange(0, 1.05, 0.05))\n",
    "ax1.set_xlim([0.0, 1.005])\n",
    "ax1.axvline(0.93, linestyle='--', color='black')\n",
    "for tick in ax1.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "    tick.label1.set_rotation(90)\n",
    "for tick in ax1.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "\n",
    "ax1.set_ylabel('Institution',  fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "ax1.set_xlabel('AUC', fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax1.spines[axis].set_linewidth(4)\n",
    "\n",
    "\n",
    "sns.barplot(y='Institution', x='Sample Size', data=data, ax=ax2, palette='tab20')\n",
    "ax2.set_xlabel('Sample Size', fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "xlim = ax2.get_xlim()\n",
    "\n",
    "sns.barplot(y='Institution', x='Sample Size LUAD', data=data, ax=ax3, palette='tab20')\n",
    "ax3.set_xlabel('Sample Size LUAD', fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "ax3.set_xlim(xlim)\n",
    "\n",
    "sns.barplot(y='Institution', x='Sample Size LUSC', data=data, ax=ax4, palette='tab20')\n",
    "ax4.set_xlabel('Sample Size LUSC', fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "ax4.set_xlim(xlim)\n",
    "\n",
    "for ax_rem in [ax2, ax3, ax4]:\n",
    "    for tick in ax_rem.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax_rem.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "\n",
    "    ax_rem.yaxis.label.set_visible(False)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax_rem.spines[axis].set_linewidth(4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize_labels = 45\n",
    "f, ax = plt.subplots(1, 1, sharey=True, figsize=(70, 27))\n",
    "sns.barplot(x='Institution', y='Sample Size', hue='Subtype', ax=ax, data=data_f, palette=['royalblue', 'darkorange'])\n",
    "\n",
    "for tick in ax1.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "    tick.label1.set_rotation(90)\n",
    "for tick in ax1.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "\n",
    "ax.set_xlabel('Institution',  fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "    tick.label1.set_rotation(90)\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "\n",
    "ax.yaxis.label.set_visible(False)\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "ax.legend(prop={'size': fontsize_labels-2, 'weight':'bold'})\n",
    "\n",
    "ax.set_ylabel('Sample Size',  fontsize=fontsize_labels*1.1, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figsize    = (40,20)\n",
    "fontsize_labels = 40\n",
    "fontsize_legend = 32\n",
    "l_box_w         = 3\n",
    "lw              = 5\n",
    "\n",
    "fig   = plt.figure(figsize=figsize)\n",
    "ax    = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "data = data.sort_values(by='Sample Size', ascending=False)\n",
    "for institution in data['Institution'].values:\n",
    "\n",
    "    fpr, tpr, thresholds, roc_auc, samples = institutions_roc[institution]\n",
    "    if roc_auc is None: continue\n",
    "    ax.plot(fpr, tpr, lw=lw, label=\"%s (%s) = %0.2f\" % (institution, samples, roc_auc))\n",
    "\n",
    "\n",
    "legend = ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., title=r'$\\bf{Per\\ Institution\\ AUC\\ and\\ Sample\\ Size}$', prop={'size': fontsize_legend-4, 'weight':'bold'})\n",
    "legend.get_title().set_fontsize(fontsize_legend)\n",
    "# set the linewidth of each legend object\n",
    "for line in legend.get_lines():\n",
    "    line.set_linewidth(lw)\n",
    "legend.get_frame().set_linewidth(l_box_w)\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(fontsize_labels)\n",
    "    tick.label1.set_fontweight('bold')\n",
    "\n",
    "ax.set_title('TCGA Cohort',  fontsize=fontsize_labels*1.2, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate',  fontsize=fontsize_labels, fontweight='bold')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=fontsize_labels, fontweight='bold')\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Figure - AUC across resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to LR results CSV.\n",
    "lr_dir   = '%s/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/lungsubtype_nn250_fold4/alpha_5p0_mintiles_100' % main_path\n",
    "csv_path = '%s/luad_auc_results_mintiles_100.csv' % lr_dir\n",
    "results_df = pd.read_csv(csv_path)\n",
    "resolutions_u = results_df['Leiden Resolution'].unique()\n",
    "res_hpc = dict()\n",
    "for res in resolutions_u:\n",
    "    res_ = res.split('_')[1]\n",
    "    folds = list()\n",
    "    for i in range(5):\n",
    "        # Read ROCAUC for each resolution.\n",
    "        csv_path = '%s/%s_fold%s_clusters.csv' % (lr_dir, res.replace('.','p'), i)\n",
    "        fold_df = pd.read_csv(csv_path)\n",
    "        folds.append(len(fold_df[res].unique()))\n",
    "    res_hpc[res] = int(np.mean(folds))\n",
    "    \n",
    "all_data = list()\n",
    "for row in results_df.iterrows():\n",
    "    resolution, fold, tcga_train, tcga_valid, tcga_test, nyu_additional = row[1].values\n",
    "    n_hpc = res_hpc[str(resolution)]\n",
    "    resolution = resolution.split('leiden_')[1]\n",
    "    all_data.append((resolution, n_hpc, fold, 'TCGA Train', tcga_train))\n",
    "    all_data.append((resolution, n_hpc, fold, 'TCGA Validation', tcga_valid))\n",
    "    all_data.append((resolution, n_hpc, fold, 'TCGA Test', tcga_test))\n",
    "    all_data.append((resolution, n_hpc, fold, 'NYU Cohort', nyu_additional))\n",
    "    \n",
    "all_data = pd.DataFrame(all_data, columns=['Resolution', 'Number HPCs', 'Fold', 'Set', 'ROC AUC'])\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize_labels = 14\n",
    "lw = 3\n",
    "l_box_w = 3\n",
    "\n",
    "for x_label in [ 'Number HPCs', 'Resolution']:\n",
    "    sns.set_theme(style='darkgrid')\n",
    "    fig, ax = plt.subplots(figsize=(20, 7), nrows=1, ncols=1)\n",
    "    sns.pointplot(x=x_label, hue='Set', y='ROC AUC', data=all_data, ax=ax, dodge=.3, join=False, capsize=.00, markers='o', errorbar=('ci', 95))\n",
    "    ax.set_ylim([0.85, 1.05])\n",
    "    ax.set_title('LUAD vs LUSC\\nROC AUC', fontweight='bold', fontsize=18)\n",
    "    ax.legend(loc='upper left')\n",
    "    start, end = ax.get_ylim()\n",
    "    ax.yaxis.set_ticks(np.arange(start, end, 0.05))\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontsize(fontsize_labels)\n",
    "        tick.label1.set_fontweight('bold')\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "    ax.set_ylabel('ROC AUC', fontweight='bold', size=fontsize_labels+2)\n",
    "    if x_label == 'Number HPCs':\n",
    "        ax.set_xlabel('Number of HPCs', fontweight='bold', size=fontsize_labels+2)\n",
    "    else:\n",
    "        ax.set_xlabel('Leiden Resolution Parameter', fontweight='bold', size=fontsize_labels+2)\n",
    "\n",
    "    legend = ax.legend_\n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(lw)\n",
    "    legend.get_frame().set_linewidth(l_box_w)\n",
    "    for i in range(len(legend.get_texts())):\n",
    "        legend.get_texts()[i].set_fontweight('bold')\n",
    "        legend.get_texts()[i].set_fontsize(fontsize_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - Forest plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Path to CSV where we have the LR coef. \n",
    "coeff_csv = '%s/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/lungsubtype_nn250_fold4/alpha_10p0_mintiles_100/leiden_2p0_fold4_clusters.csv' % main_path\n",
    "coeff_frame = pd.read_csv(coeff_csv)\n",
    "\n",
    "# Use dominant subtype instead of purity. The CSV contains the HPC assignations on the train set.\n",
    "train_csv = '%s/results/BarlowTwins_3/TCGAFFPE_LUADLUSC_5x_60pc_250K/h224_w224_n3_zdim128_filtered/lungsubtype_nn250_fold4/adatas/TCGAFFPE_LUADLUSC_5x_60pc_he_complete_lungsubtype_survival_filtered_leiden_2p0__fold4.csv' % main_path\n",
    "train_frame = pd.read_csv(train_csv)\n",
    "x,y = 'leiden_2.0', 'luad'\n",
    "frame_clusters = train_frame.groupby(x)[y].value_counts(normalize=True).mul(100).rename('Subtype Purity(%)').reset_index()\n",
    "frame_clusters = frame_clusters[frame_clusters['Subtype Purity(%)']>50.0]\n",
    "frame_clusters = frame_clusters.replace({'luad':{0:'LUSC', 1:'LUAD'}})\n",
    "coeff_frame['Subtype'] = frame_clusters[y].values\n",
    "coeff_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Forest Plot for Logistic Regression coefficients.\n",
    "class EffectMeasurePlot_LR:\n",
    "    \"\"\"Used to generate effect measure plots. effectmeasure plot accepts four list type objects.\n",
    "    effectmeasure_plot is initialized with the associated names for each line, the point estimate,\n",
    "    the lower confidence limit, and the upper confidence limit.\n",
    "    Plots will resemble the following form:\n",
    "        _____________________________________________      Measure     % CI\n",
    "        |                                           |\n",
    "    1   |        --------o-------                   |       x        n, 2n\n",
    "        |                                           |\n",
    "    2   |                   ----o----               |       w        m, 2m\n",
    "        |                                           |\n",
    "        |___________________________________________|\n",
    "        #           #           #           #\n",
    "    The following functions (and their purposes) live within effectmeasure_plot\n",
    "    labels(**kwargs)\n",
    "        Used to change the labels in the plot, as well as the center and scale. Inputs are\n",
    "        keyword arguments\n",
    "        KEYWORDS:\n",
    "            -effectmeasure  + changes the effect measure label\n",
    "            -conf_int       + changes the confidence interval label\n",
    "            -scale          + changes the scale to either log or linear\n",
    "            -center         + changes the reference line for the center\n",
    "    colors(**kwargs)\n",
    "        Used to change the color of points and lines. Also can change the shape of points.\n",
    "        Valid colors and shapes for matplotlib are required. Inputs are keyword arguments\n",
    "        KEYWORDS:\n",
    "            -errorbarcolor  + changes the error bar colors\n",
    "            -linecolor      + changes the color of the reference line\n",
    "            -pointcolor     + changes the color of the points\n",
    "            -pointshape     + changes the shape of points\n",
    "    plot(t_adjuster=0.01,decimal=3,size=3)\n",
    "        Generates the effect measure plot of the input lists according to the pre-specified\n",
    "        colors, shapes, and labels of the class object\n",
    "        Arguments:\n",
    "            -t_adjuster     + used to refine alignment of the table with the line graphs.\n",
    "                              When generate plots, trial and error for this value are usually\n",
    "                              necessary\n",
    "            -decimal        + number of decimal places to display in the table\n",
    "            -size           + size of the plot to generate\n",
    "    Example)\n",
    "    >>>lab = ['One','Two'] #generating lists of data to plot\n",
    "    >>>emm = [1.01,1.31]\n",
    "    >>>lcl = ['0.90',1.01]\n",
    "    >>>ucl = [1.11,1.53]\n",
    "    >>>\n",
    "    >>>x = zepid.graphics.effectmeasure_plot(lab,emm,lcl,ucl) #initializing effectmeasure_plot with the above lists\n",
    "    >>>x.labels(effectmeasure='RR') #changing the table label to 'RR'\n",
    "    >>>x.colors(pointcolor='r') #changing the point colors to red\n",
    "    >>>x.plot(t_adjuster=0.13) #generating the effect measure plot\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label, effect_measure, lcl, ucl, pvalues, subtypes, purities, counts, mean_tp, max_tp, perc_pat, center=0):\n",
    "        \"\"\"Initializes effectmeasure_plot with desired data to plot. All lists should be the same\n",
    "        length. If a blank space is desired in the plot, add an empty character object (' ') to\n",
    "        each list at the desired point.\n",
    "        Inputs:\n",
    "        label\n",
    "            -list of labels to use for y-axis\n",
    "        effect_measure\n",
    "            -list of numbers for point estimates to plot. If point estimate has trailing zeroes,\n",
    "             input as a character object rather than a float\n",
    "        lcl\n",
    "            -list of numbers for upper confidence limits to plot. If point estimate has trailing\n",
    "             zeroes, input as a character object rather than a float\n",
    "        ucl\n",
    "            -list of numbers for upper confidence limits to plot. If point estimate has\n",
    "             trailing zeroes, input as a character object rather than a float\n",
    "        \"\"\"\n",
    "        self.df = pd.DataFrame()\n",
    "        self.df['study'] = label\n",
    "        self.df['OR']    = effect_measure\n",
    "        self.df['LCL']   = lcl\n",
    "        self.df['UCL']   = ucl\n",
    "        self.df['P']     = pvalues\n",
    "        self.df['S']     = subtypes\n",
    "        self.df['Pu']    = purities\n",
    "        self.df['C']     = counts\n",
    "        self.df['M']     = mean_tp\n",
    "        self.df['Ma']    = max_tp\n",
    "        self.df['Pp']    = perc_pat\n",
    "        self.df['OR2']   = self.df['OR'].astype(str).astype(float)\n",
    "        if (all(isinstance(item, float) for item in lcl)) & (all(isinstance(item, float) for item in effect_measure)):\n",
    "            self.df['LCL_dif'] = self.df['OR'] - self.df['LCL']\n",
    "        else:\n",
    "            self.df['LCL_dif'] = (pd.to_numeric(self.df['OR'])) - (pd.to_numeric(self.df['LCL']))\n",
    "        if (all(isinstance(item, float) for item in ucl)) & (all(isinstance(item, float) for item in effect_measure)):\n",
    "            self.df['UCL_dif'] = self.df['UCL'] - self.df['OR']\n",
    "        else:\n",
    "            self.df['UCL_dif'] = (pd.to_numeric(self.df['UCL'])) - (pd.to_numeric(self.df['OR']))\n",
    "        self.em       = 'OR'\n",
    "        self.ci       = '95% CI'\n",
    "        self.p        = 'P-Value'\n",
    "        self.subtype  = 'Predominant\\nLung Type'\n",
    "        self.purity   = 'Purity\\n%'\n",
    "        self.counts   = 'Tile Counts'\n",
    "        self.mean_tp  = 'Mean Tiles\\nPer Pat.'\n",
    "        self.max_tp   = 'Max Tiles\\nPer Pat.'\n",
    "        self.perc_pat = 'Patients\\n%'\n",
    "        self.scale    = 'linear'\n",
    "        self.center   = center\n",
    "        self.errc     = 'dimgrey'\n",
    "        self.shape    = 'o'\n",
    "        self.pc       = 'k'\n",
    "        self.linec    = 'gray'\n",
    "\n",
    "    def labels(self, **kwargs):\n",
    "        \"\"\"Function to change the labels of the outputted table. Additionally, the scale and reference\n",
    "        value can be changed.\n",
    "        Accepts the following keyword arguments:\n",
    "        effectmeasure\n",
    "            -changes the effect measure label\n",
    "        conf_int\n",
    "            -changes the confidence interval label\n",
    "        scale\n",
    "            -changes the scale to either log or linear\n",
    "        center\n",
    "            -changes the reference line for the center\n",
    "        \"\"\"\n",
    "        if 'effectmeasure' in kwargs:\n",
    "            self.em = kwargs['effectmeasure']\n",
    "        if 'ci' in kwargs:\n",
    "            self.ci = kwargs['conf_int']\n",
    "        if 'scale' in kwargs:\n",
    "            self.scale = kwargs['scale']\n",
    "        if 'center' in kwargs:\n",
    "            self.center = kwargs['center']\n",
    "\n",
    "    def colors(self, **kwargs):\n",
    "        \"\"\"Function to change colors and shapes.\n",
    "        Accepts the following keyword arguments:\n",
    "        errorbarcolor\n",
    "            -changes the error bar colors\n",
    "        linecolor\n",
    "            -changes the color of the reference line\n",
    "        pointcolor\n",
    "            -changes the color of the points\n",
    "        pointshape\n",
    "            -changes the shape of points\n",
    "        \"\"\"\n",
    "        if 'errorbarcolor' in kwargs:\n",
    "            self.errc = kwargs['errorbarcolor']\n",
    "        if 'pointshape' in kwargs:\n",
    "            self.shape = kwargs['pointshape']\n",
    "        if 'linecolor' in kwargs:\n",
    "            self.linec = kwargs['linecolor']\n",
    "        if 'pointcolor' in kwargs:\n",
    "            self.pc = kwargs['pointcolor']\n",
    "\n",
    "    def plot(self, bbox, figsize=(3, 3), t_adjuster=0.01, decimal=3, size=3, max_value=None, min_value=None, fontsize=12, p_th=0.05):\n",
    "        \"\"\"Generates the matplotlib effect measure plot with the default or specified attributes.\n",
    "        The following variables can be used to further fine-tune the effect measure plot\n",
    "        t_adjuster\n",
    "            -used to refine alignment of the table with the line graphs. When generate plots, trial\n",
    "             and error for this value are usually necessary. I haven't come up with an algorithm to\n",
    "             determine this yet...\n",
    "        decimal\n",
    "            -number of decimal places to display in the table\n",
    "        size\n",
    "            -size of the plot to generate\n",
    "        max_value\n",
    "            -maximum value of x-axis scale. Default is None, which automatically determines max value\n",
    "        min_value\n",
    "            -minimum value of x-axis scale. Default is None, which automatically determines min value\n",
    "        \"\"\"\n",
    "        tval = []\n",
    "        ytick = []\n",
    "        for i in range(len(self.df)):\n",
    "            if (np.isnan(self.df['OR2'][i]) == False):\n",
    "                if ((isinstance(self.df['OR'][i], float)) & (isinstance(self.df['LCL'][i], float)) & (isinstance(self.df['UCL'][i], float))):\n",
    "                    list_val = [round(self.df['OR2'][i], decimal), ('(' + str(round(self.df['LCL'][i], decimal)) + ', ' + str(round(self.df['UCL'][i], decimal)) + ')'), str(self.df['P'][i]),\n",
    "                                self.df['S'][i], self.df['Pu'][i], self.df['C'][i], self.df['M'][i], self.df['Ma'][i], self.df['Pp'][i]]\n",
    "                    tval.append(list_val)\n",
    "                else:\n",
    "                    list_val = [self.df['OR'][i], ('(' + str(self.df['LCL'][i]) + ', ' + str(self.df['UCL'][i]) + ')'), self.df['P'][i], self.df['S'][i], self.df['Pu'][i], self.df['C'][i],\n",
    "                                self.df['M'][i], self.df['Ma'][i], self.df['Pp'][i]]\n",
    "                    tval.append()\n",
    "                ytick.append(i)\n",
    "            else:\n",
    "                tval.append([' ', ' ', ' ', ' '])\n",
    "                ytick.append(i)\n",
    "        if max_value is None:\n",
    "            if pd.to_numeric(self.df['UCL']).max() < 1:\n",
    "                maxi = round(((pd.to_numeric(self.df['UCL'])).max() + 0.05),\n",
    "                             2)  # setting x-axis maximum for UCL less than 1\n",
    "            if (pd.to_numeric(self.df['UCL']).max() < 9) and (pd.to_numeric(self.df['UCL']).max() >= 1):\n",
    "                maxi = round(((pd.to_numeric(self.df['UCL'])).max() + 1),\n",
    "                             0)  # setting x-axis maximum for UCL less than 10\n",
    "            if pd.to_numeric(self.df['UCL']).max() > 9:\n",
    "                maxi = round(((pd.to_numeric(self.df['UCL'])).max() + 10),\n",
    "                             0)  # setting x-axis maximum for UCL less than 100\n",
    "        else:\n",
    "            maxi = max_value\n",
    "        if min_value is None:\n",
    "            if pd.to_numeric(self.df['LCL']).min() > 0:\n",
    "                mini = round(((pd.to_numeric(self.df['LCL'])).min() - 0.1), 1)  # setting x-axis minimum\n",
    "            if pd.to_numeric(self.df['LCL']).min() < 0:\n",
    "                mini = round(((pd.to_numeric(self.df['LCL'])).min() - 0.05), 2)  # setting x-axis minimum\n",
    "        else:\n",
    "            mini = min_value\n",
    "        plt.figure(figsize=figsize)  # blank figure\n",
    "        gspec = gridspec.GridSpec(1, 6)  # sets up grid\n",
    "        plot = plt.subplot(gspec[0, 0:4])  # plot of data\n",
    "        tabl = plt.subplot(gspec[0, 4:])  # table of OR & CI\n",
    "        plot.set_ylim(-1, (len(self.df)))  # spacing out y-axis properly\n",
    "        if self.scale == 'log':\n",
    "            try:\n",
    "                plot.set_xscale('log')\n",
    "            except:\n",
    "                raise ValueError('For the log scale, all values must be positive')\n",
    "        plot.axvline(self.center, color=self.linec, zorder=1)\n",
    "        plot.errorbar(self.df.OR2, self.df.index, xerr=[self.df.LCL_dif, self.df.UCL_dif], marker='None', zorder=2, ecolor=self.errc, elinewidth=size*0.3, linewidth=0)\n",
    "        plot.scatter(self.df.OR2, self.df.index, c=self.pc, s=(size * 25), marker=self.shape, zorder=3, edgecolors='None')\n",
    "        plot.xaxis.set_ticks_position('bottom')\n",
    "        plot.yaxis.set_ticks_position('left')\n",
    "        plot.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "        plot.get_xaxis().set_minor_formatter(matplotlib.ticker.NullFormatter())\n",
    "        plot.set_yticks(ytick, fontsize=fontsize)\n",
    "        plot.set_xlim([mini, maxi])\n",
    "        plot.set_xticks([mini, self.center, maxi], fontsize=fontsize)\n",
    "        plot.set_xticklabels([mini, self.center, maxi], fontsize=fontsize, fontweight='bold')\n",
    "        plot.set_yticklabels(self.df.study, fontsize=fontsize, fontweight='bold')\n",
    "        plot.yaxis.set_ticks_position('none')\n",
    "        plot.invert_yaxis()  # invert y-axis to align values properly with table\n",
    "        # tb = tabl.table(cellText=tval, cellLoc='center', loc='right', colLabels=[self.em, self.ci, self.p, self.subtype, self.purity, self.counts, self.mean_tp, self.max_tp, self.perc_pat], bbox=[0, t_adjuster, 4.5, 1])\n",
    "        tb = tabl.table(cellText=tval, cellLoc='center', loc='right', colLabels=[self.em, self.ci, self.p, self.subtype, self.purity, self.counts, self.mean_tp, self.max_tp, self.perc_pat], bbox=bbox)\n",
    "        tabl.axis('off')\n",
    "        tb.auto_set_font_size(False)\n",
    "        tb.set_fontsize(fontsize)\n",
    "        for (row, col), cell in tb.get_celld().items():\n",
    "            c_pvalue = self.df['P'].values[row-1]\n",
    "            if c_pvalue < p_th and row !=0:\n",
    "                cell.set_text_props(fontproperties=FontProperties(size=fontsize))\n",
    "            else:\n",
    "                cell.set_text_props(fontproperties=FontProperties(weight='light', size=fontsize))\n",
    "            if (row == 0):\n",
    "                cell.set_text_props(fontproperties=FontProperties(weight='bold', size=fontsize))\n",
    "                cell.set_height(.015)\n",
    "            cell.set_linewidth(0)\n",
    "        tb.auto_set_column_width(col=list(range(len([self.em, self.ci, self.p, self.subtype, self.purity, self.counts, self.mean_tp, self.max_tp, self.perc_pat]))))\n",
    "        return plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style='white')\n",
    "\n",
    "p_th        = 0.05\n",
    "label       = 1\n",
    "\n",
    "frame_label = coeff_frame.sort_values(by='coef_%s'%label)\n",
    "frame_label = frame_label[frame_label['coef_%s'%label]!=0]\n",
    "\n",
    "groupby   = [value for value in frame_label.columns if 'leiden' in value][0]\n",
    "labs      = frame_label[groupby].values.tolist()\n",
    "measure   = np.round(frame_label['coef_%s'%label],2).values.tolist()\n",
    "lower     = np.round(frame_label['[0.025_%s'%label],2).values.tolist()\n",
    "upper     = np.round(frame_label['0.975]_%s'%label],2).values.tolist()\n",
    "pvalues   = np.round(frame_label['P>|z|_%s'%label],3).values.tolist()\n",
    "subtype   = frame_label['Subtype'].values.tolist()\n",
    "purity    = frame_label['Subtype Purity(%)'].values.astype(int).tolist()\n",
    "counts    = frame_label['Subtype Counts'].values.tolist()\n",
    "mean_tp   = frame_label['mean_tile_sample'].values.astype(int).tolist()\n",
    "max_tp    = np.round(frame_label['max_tile_sample'].values*100,1).tolist()\n",
    "perc_pat  = np.round(frame_label['percent_sample'].values*100,1).tolist()\n",
    "max_value = max(abs(max(upper)), abs(min(lower)))\n",
    "\n",
    "\n",
    "figsize    = (25,27)\n",
    "t_adjuster = 0.015\n",
    "t_adjuster = 0.016\n",
    "decimal    = 3\n",
    "size       = 10\n",
    "fontsize   = 35\n",
    "\n",
    "bbox = [0, t_adjuster, 4.5, 1.03]\n",
    "\n",
    "p = EffectMeasurePlot_LR(label=labs, effect_measure=measure, lcl=lower, ucl=upper, pvalues=pvalues, subtypes=subtype, purities=purity, counts=counts, mean_tp=mean_tp, max_tp=max_tp, perc_pat=perc_pat)\n",
    "p.labels(effectmeasure='Log Odds\\nRatio')\n",
    "p.colors(pointshape=\"o\")\n",
    "ax=p.plot(figsize=figsize, bbox=bbox, t_adjuster=t_adjuster, max_value=max_value, min_value=-max_value, fontsize=fontsize, p_th=p_th, size=size)\n",
    "plt.suptitle(\"HPC\\n \\n \",x=0.1,y=0.89, fontsize=fontsize, fontweight='bold')\n",
    "ax.set_xlabel(\"Favors LUSC               Favors LUAD\", fontsize=fontsize, x=0.5, fontweight='bold')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paper Figure - HPC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Workspace path.\n",
    "main_path = '/media/adalberto/Disk2/PhD_Workspace'\n",
    "\n",
    "dataset            = 'TCGAFFPE_LUADLUSC_5x_60pc'\n",
    "additional_dataset = 'NYUFFPE_survival_5x_60pc'\n",
    "\n",
    "data = Data(dataset=dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path=main_path, load=True)\n",
    "img_dicts = dict()\n",
    "img_dicts['train'] = data.training.images\n",
    "img_dicts['valid'] = data.validation.images\n",
    "img_dicts['test'] = data.test.images\n",
    "\n",
    "additional_data = Data(dataset=additional_dataset, marker='he', patch_h=224, patch_w=224, n_channels=3, batch_size=64, project_path=main_path, load=True)\n",
    "additional_img_dicts = dict()\n",
    "additional_img_dicts['train'] = additional_data.training.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folds = load_existing_split(folds_pickle)\n",
    "dataframes, complete_df, leiden_clusters = read_csvs(adatas_path, matching_field, groupby, fold_number, folds[fold_number], h5_complete_path, h5_additional_path)\n",
    "train_df, valid_df, test_df, additional_df = dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_set_images(review_clusters, frame, data_dicts, groupby, batches=1, ncols=20, nrows=4, annotated=False, figures_path=None):\n",
    "\n",
    "    if figures_path is not None:\n",
    "        figures_path = os.path.join(figures_path, 'hpc_tile_samples')\n",
    "        if not os.path.isdir(figures_path):\n",
    "            os.makedirs(figures_path)\n",
    "\n",
    "    for cluster_id in review_clusters:\n",
    "        indexes       = frame[(frame[groupby]==cluster_id)]['indexes'].values.tolist()\n",
    "        original_sets = frame[(frame[groupby]==cluster_id)]['original_set'].values.tolist()\n",
    "        combined      = list(zip(indexes, original_sets))\n",
    "        random.shuffle(combined)\n",
    "        combined_plot = sorted(combined[:100*batches])\n",
    "\n",
    "        csv_information = list()\n",
    "        images_cluster = list()\n",
    "        for index, original_set in combined_plot:\n",
    "            images_cluster.append(data_dicts[original_set][int(index)]/255.)\n",
    "            entry_dict = frame[(frame.indexes==index)&(frame.original_set==original_set)].to_dict('index')\n",
    "            for key in entry_dict:\n",
    "                csv_information.append(entry_dict[key])\n",
    "\n",
    "        for batch in range(batches):\n",
    "            fig, axs = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "            fig.set_figheight(8)\n",
    "            fig.set_figwidth(8*(ncols/4)*0.8)\n",
    "            if annotated:\n",
    "                fig.suptitle('HPC %s - TCGA' % (cluster_id), ha='center', fontweight='bold', fontsize=65)\n",
    "            else:\n",
    "                fig.suptitle('HPC %s' % (cluster_id), ha='center', fontweight='bold', fontsize=65)\n",
    "            gs = axs[0, -4].get_gridspec()\n",
    "            # remove the underlying axes\n",
    "            for i in range(ncols-4,ncols):\n",
    "                for ax in axs[0:, i]:\n",
    "                    ax.remove()\n",
    "            axbig = fig.add_subplot(gs[0:, -4:])\n",
    "            axbig.set_xticks([])\n",
    "            axbig.set_yticks([])\n",
    "            axbig.set_yticks([])\n",
    "            axes_list = list(axs.flatten())\n",
    "            axes_list.append(axbig)\n",
    "            for ax, im in zip(axes_list, images_cluster[batch*100:(batch+1)*100]):\n",
    "                ax.imshow(im)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.set_yticks([])\n",
    "                for axis in ['top','bottom','left','right']:\n",
    "                    ax.spines[axis].set_linewidth(4)\n",
    "            plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "            fig.tight_layout()\n",
    "            if figures_path is None:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(os.path.join(figures_path, 'HPC_%s_TCGA_batch_%s.jpg' % (cluster_id, batch)))\n",
    "                plt.close()\n",
    "\n",
    "annotated       = True\n",
    "sns.set_theme(style='white')\n",
    "cluster_set_images(leiden_clusters, frame=train_df, data_dicts=img_dicts, groupby=groupby, batches=1, annotated=annotated, figures_path=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_crosscheck_frame(hdf5_path, original_set='train'):\n",
    "    with h5py.File(hdf5_path, 'r') as content:\n",
    "        for key in content.keys():\n",
    "            if 'slides' in key:\n",
    "                slides_key = key\n",
    "            elif 'tiles' in key:\n",
    "                tiles_key = key\n",
    "        tiles  = content[tiles_key][:].astype('U13')\n",
    "        slides = content[slides_key][:].astype('U13')\n",
    "        indexes = list(range(tiles.shape[0]))\n",
    "    frame_cc = pd.DataFrame(indexes, columns=['indexes'])\n",
    "    frame_cc['tiles']  = tiles\n",
    "    frame_cc['slides'] = slides\n",
    "    frame_cc['original_set'] = original_set\n",
    "    return frame_cc\n",
    "\n",
    "def cross_check_dfs(additional_df, frame_cc, matching_fields=['slides', 'tiles']):\n",
    "    additional_df['slides'] = additional_df['slides'].astype(str)\n",
    "    additional_df['tiles']  = additional_df['tiles'].astype(str)\n",
    "    frame_cc['slides']      = frame_cc['slides'].astype(str)\n",
    "    frame_cc['tiles']       = frame_cc['tiles'].astype(str)\n",
    "    cross_checked_df = frame_cc.merge(additional_df, how='inner', left_on=matching_fields, right_on=matching_fields)\n",
    "    return cross_checked_df\n",
    "\n",
    "def cluster_set_images_add(review_clusters, frame, hdf5_path, groupby, add_cohort, img_key='img', batches=1, ncols=20, nrows=4, figures_path=None):\n",
    "\n",
    "    if figures_path is not None:\n",
    "        figures_path = os.path.join(figures_path, 'hpc_tile_samples')\n",
    "        if not os.path.isdir(figures_path):\n",
    "            os.makedirs(figures_path)\n",
    "\n",
    "    with h5py.File(hdf5_path, 'r') as content:\n",
    "\n",
    "        for key in content.keys():\n",
    "            if 'img' in key or 'images' in key:\n",
    "                img_key = key\n",
    "                break\n",
    "\n",
    "        for cluster_id in review_clusters:\n",
    "            indexes       = frame[(frame[groupby]==cluster_id)]['indexes'].values.tolist()\n",
    "            original_sets = frame[(frame[groupby]==cluster_id)]['original_set'].values.tolist()\n",
    "            combined      = list(zip(indexes, original_sets))\n",
    "            random.shuffle(combined)\n",
    "            combined_plot = sorted(combined[:100*batches])\n",
    "\n",
    "            csv_information = list()\n",
    "            images_cluster = list()\n",
    "            for index, original_set in combined_plot:\n",
    "                images_cluster.append(content[img_key][int(index)]/255.)\n",
    "                entry_dict = frame[(frame.indexes==index)&(frame.original_set==original_set)].to_dict('index')\n",
    "                for key in entry_dict:\n",
    "                    csv_information.append(entry_dict[key])\n",
    "\n",
    "\n",
    "            for batch in range(batches):\n",
    "                fig, axs = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "                fig.set_figheight(8)\n",
    "                fig.set_figwidth(8*(ncols/4)*0.8)\n",
    "                fig.suptitle('HPC %s - %s' % (cluster_id, add_cohort), ha='center', fontweight='bold', fontsize=65)\n",
    "                gs = axs[0, -4].get_gridspec()\n",
    "                # remove the underlying axes\n",
    "                for i in range(ncols-4,ncols):\n",
    "                    for ax in axs[0:, i]:\n",
    "                        ax.remove()\n",
    "                axbig = fig.add_subplot(gs[0:, -4:])\n",
    "                axbig.set_xticks([])\n",
    "                axbig.set_yticks([])\n",
    "                axbig.set_yticks([])\n",
    "                axes_list = list(axs.flatten())\n",
    "                axes_list.insert(0, axbig)\n",
    "                j = 0\n",
    "                for ax, im in zip(axes_list, images_cluster[batch*100:(batch+1)*100]):\n",
    "                    ax.imshow(im)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    for axis in ['top','bottom','left','right']:\n",
    "                        ax.spines[axis].set_linewidth(4)\n",
    "                    j += 1\n",
    "                if j != len(axes_list):\n",
    "                    for i, ax in enumerate(axes_list[j:]):\n",
    "                        ax.imshow(np.ones((224,224,3)))\n",
    "                        ax.set_xticks([])\n",
    "                        ax.set_yticks([])\n",
    "                        ax.set_yticks([])\n",
    "                        for axis in ['top','bottom','left','right']:\n",
    "                            ax.spines[axis].set_linewidth(4)\n",
    "\n",
    "                plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "                fig.tight_layout()\n",
    "                if figures_path is None:\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    plt.savefig(os.path.join(figures_path, 'HPC_%s_%s_batch_%s.jpg' % (cluster_id, add_cohort, batch)))\n",
    "                    plt.close()\n",
    "                if j != len(axes_list): break\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "hdf5_path = '%s/datasets/NYUFFPE_LUADLUSC_5x_60pc/he/patches_h224_w224/hdf5_NYUFFPE_LUADLUSC_5x_60pc_he_combined.h5' % main_path\n",
    "\n",
    "frame_cc       = get_crosscheck_frame(hdf5_path, original_set='additional')\n",
    "cross_check_df = cross_check_dfs(additional_df, frame_cc, matching_fields=['slides', 'tiles'])\n",
    "\n",
    "cluster_set_images_add(leiden_clusters, frame=cross_check_df, hdf5_path=hdf5_path, groupby=groupby, add_cohort='NYU', img_key='img', batches=3, figures_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
